{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_size(model_path):\n",
    "    \"\"\"\n",
    "    Calculate the size of the TFLite model in MB.\n",
    "    Args:\n",
    "        model_path (str): Path to the TFLite model file.\n",
    "    Returns:\n",
    "        float: Size of the model in MB.\n",
    "    \"\"\"\n",
    "    total_size = os.path.getsize(model_path)  # Directly get size of the TFLite file\n",
    "    return total_size / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "def measure_inference_time_tflite(model_path, X_test, batch_size, trials=50):\n",
    "    \"\"\"\n",
    "    Benchmark the inference time of a TFLite model.\n",
    "    Args:\n",
    "        model_path (str): Path to the TFLite model file.\n",
    "        X_test (numpy array): Test dataset (images).\n",
    "        batch_size (int): Batch size for inference.\n",
    "        trials (int): Number of trials to run.\n",
    "    Returns:\n",
    "        tuple: Average inference time and throughput (images per second).\n",
    "    \"\"\"\n",
    "    # Load TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()  # Input details for the model\n",
    "    output_details = interpreter.get_output_details()  # Output details for the model\n",
    "\n",
    "    inference_times = []\n",
    "    num_batches = len(X_test) // batch_size\n",
    "\n",
    "    # Warm-up phase (Run a few trials to initialize the model)\n",
    "    print(f\"Running {10} warm-up trials to initialize the model...\")\n",
    "    for _ in range(10):\n",
    "        for j in range(num_batches):\n",
    "            batch_start = j * batch_size\n",
    "            batch_end = (j + 1) * batch_size\n",
    "            batch_images = X_test[batch_start:batch_end]\n",
    "\n",
    "            # Preprocess the input batch to match TFLite input format\n",
    "            interpreter.set_tensor(input_details[0]['index'], batch_images)\n",
    "            interpreter.invoke()  # Run inference (no need to handle outputs here)\n",
    "\n",
    "    print(f\"Running {trials} inference trials on {len(X_test)} test images...\")\n",
    "    for i in range(trials):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Loop over the batches of X_test\n",
    "        for j in range(num_batches):\n",
    "            batch_start = j * batch_size\n",
    "            batch_end = (j + 1) * batch_size\n",
    "            batch_images = X_test[batch_start:batch_end]\n",
    "\n",
    "            # Preprocess the input batch to match TFLite input format\n",
    "            interpreter.set_tensor(input_details[0]['index'], batch_images)\n",
    "\n",
    "            # Run inference\n",
    "            interpreter.invoke()\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        inference_time = end_time - start_time\n",
    "        inference_times.append(inference_time)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            avg_inference = np.mean(inference_times)  # Average inference time per trial\n",
    "            print(f\"Step {i}: average inference time = {avg_inference:.6f} seconds\")\n",
    "\n",
    "    # Compute throughput (images per second)\n",
    "    total_time = sum(inference_times)\n",
    "    throughput = (trials * len(X_test)) / total_time\n",
    "    return np.mean(inference_times), throughput\n",
    "\n",
    "def measure_metrics_tflite(model_path, X_test, Y_test, batch_size):\n",
    "    \"\"\"\n",
    "    Measure classification metrics for a TFLite model.\n",
    "    Args:\n",
    "        model_path (str): Path to the TFLite model file.\n",
    "        X_test (numpy array): Test dataset (images).\n",
    "        Y_test (numpy array): Ground truth labels.\n",
    "        batch_size (int): Batch size for inference.\n",
    "    Returns:\n",
    "        dict: Dictionary of calculated metrics (accuracy, precision, recall, F1 score).\n",
    "    \"\"\"\n",
    "    # Load TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    num_batches = len(X_test) // batch_size\n",
    "    all_predicted_classes = []\n",
    "\n",
    "    # Loop over the test dataset in batches\n",
    "    for j in range(num_batches):\n",
    "        batch_start = j * batch_size\n",
    "        batch_end = (j + 1) * batch_size\n",
    "        batch_images = X_test[batch_start:batch_end]\n",
    "\n",
    "        # Preprocess the input batch to match TFLite input format\n",
    "        interpreter.set_tensor(input_details[0]['index'], batch_images)\n",
    "\n",
    "        # Run inference\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Extract logits and apply sigmoid for binary classification\n",
    "        prediction_logits = interpreter.get_tensor(output_details[0]['index'])\n",
    "        probabilities = tf.nn.sigmoid(prediction_logits).numpy()\n",
    "        predicted_classes = (probabilities > 0.5).astype(int)\n",
    "\n",
    "        # Collect predictions\n",
    "        all_predicted_classes.extend(predicted_classes)\n",
    "\n",
    "    # Handle any remaining images that don't fit evenly in batches\n",
    "    remaining_samples = len(X_test) % batch_size\n",
    "    if remaining_samples > 0:\n",
    "        batch_images = X_test[-remaining_samples:]\n",
    "        interpreter.set_tensor(input_details[0]['index'], batch_images)\n",
    "        interpreter.invoke()\n",
    "        prediction_logits = interpreter.get_tensor(output_details[0]['index'])\n",
    "        probabilities = tf.nn.sigmoid(prediction_logits).numpy()\n",
    "        predicted_classes = (probabilities > 0.5).astype(int)\n",
    "        all_predicted_classes.extend(predicted_classes)\n",
    "\n",
    "    # Flatten predictions and labels to ensure they are 1D arrays\n",
    "    all_predicted_classes = np.array(all_predicted_classes).flatten()\n",
    "    Y_test = np.array(Y_test).flatten()\n",
    "\n",
    "    # Ensure the number of predictions matches the number of ground truth labels\n",
    "    if len(all_predicted_classes) != len(Y_test):\n",
    "        raise ValueError(f\"Number of predicted classes ({len(all_predicted_classes)}) \"\n",
    "                         f\"does not match the number of ground truth labels ({len(Y_test)}).\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(Y_test, all_predicted_classes)\n",
    "    precision = precision_score(Y_test, all_predicted_classes, average=\"binary\")\n",
    "    recall = recall_score(Y_test, all_predicted_classes, average=\"binary\")\n",
    "    f1 = f1_score(Y_test, all_predicted_classes, average=\"binary\")\n",
    "\n",
    "    # Output metrics\n",
    "    metrics_dict = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "    print(f\"Metrics: {metrics_dict}\")\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 files belonging to 2 classes.\n",
      "Total Images: 228 \n",
      "Total Labels: 228\n"
     ]
    }
   ],
   "source": [
    "data_root = Path(\"../data/Original_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 1         # size of the batch that will be fed to model\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "test_size = 0.14\n",
    "\n",
    "# Load dataset without splitting\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,                                  # loads images from the data_root directory\n",
    "    image_size=(img_height, img_width),         # resizes all images to (224, 224) pixels\n",
    "    batch_size=batch_size,                      # set the batch size\n",
    "    shuffle=False,                                # shufle data when loaded\n",
    "    seed = 32\n",
    ")\n",
    "\n",
    "# normalization_layer = layers.Rescaling(1./255)\n",
    "# dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "image_batches, labels = [], []\n",
    "for image_batch, label_batch in dataset:\n",
    "    image_batches.append(image_batch)\n",
    "    labels.append(label_batch)\n",
    "\n",
    "image_batches = np.concatenate(image_batches) # Flatten batches to get all images\n",
    "labels = np.concatenate(labels)               # Flatten batches to get all labels  \n",
    "print(f\"Total Images: {image_batches.shape[0]} \\nTotal Labels: {labels.shape[0]}\")\n",
    "\n",
    "# Split the data into test subset for benchmarking\n",
    "_, X_test, _, Y_test = train_test_split(image_batches, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.259204864501953\n",
      "Running 10 warm-up trials to initialize the model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 32 but expected 1 for dimension 0 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# interpreter = tf.lite.Interpreter(model_path=model_path)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# # Allocate tensors (prepares the model for inference)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# input_details = interpreter.get_input_details()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# output_details = interpreter.get_output_details()\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_model_size(model_path))\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmeasure_inference_time_tflite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(measure_metrics_tflite(model_path, X_test, Y_test, batch_size))\n",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m, in \u001b[0;36mmeasure_inference_time_tflite\u001b[1;34m(model_path, X_test, batch_size, trials)\u001b[0m\n\u001b[0;32m     39\u001b[0m         batch_images \u001b[38;5;241m=\u001b[39m X_test[batch_start:batch_end]\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;66;03m# Preprocess the input batch to match TFLite input format\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m         \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m         interpreter\u001b[38;5;241m.\u001b[39minvoke()  \u001b[38;5;66;03m# Run inference (no need to handle outputs here)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inference trials on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test images...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jacob.delgado\\.conda\\envs\\capstone\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:732\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[0;32m    717\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \n\u001b[0;32m    719\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 32 but expected 1 for dimension 0 of input 0."
     ]
    }
   ],
   "source": [
    "# Load the TFLite model\n",
    "model_path = \"../converted_models/TFLITE/fp16_quantized_model.tflite\"\n",
    "# interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "# # Allocate tensors (prepares the model for inference)\n",
    "# interpreter.allocate_tensors()\n",
    "\n",
    "# # Get input and output details (to know the tensor indices and shapes)\n",
    "# input_details = interpreter.get_input_details()\n",
    "# output_details = interpreter.get_output_details()\n",
    "\n",
    "print(get_model_size(model_path))\n",
    "print(measure_inference_time_tflite(model_path, X_test, batch_size))\n",
    "print(measure_metrics_tflite(model_path, X_test, Y_test, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
