{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10249079154324963122\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with MonkeyPox Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"../data/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "batch_size = 32         # size of the batch that will be fed to model\n",
    "\n",
    "# folds = the amount of folds that will be created for cross-validation\n",
    "# fine_tune_epochs = number of epochs after which we start fine-tuning\n",
    "# fine_tune_at = layer number where we start unfreezing layers\n",
    "\n",
    "# configurations that will be used in training\n",
    "configs = [\n",
    "    {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "]\n",
    "\n",
    "# Define the base path for saving models\n",
    "save_dir = \"../saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_dataset(directory: str, batch_size: int, image_size: tuple[int, int],\n",
    "                       label_mode, shuffle: bool = True) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Loads an image dataset from the specified directory using Keras' image_dataset_from_directory.\n",
    "\n",
    "    The directory should contain one subdirectory per class.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the image data directory.\n",
    "        batch_size (int): Number of images per batch.\n",
    "        image_size (Tuple[int, int]): Target size (height, width) for the images.\n",
    "        label_mode (str): Type of label encoding ('binary', 'categorical', or 'int'). Defaults to 'binary'.\n",
    "        shuffle (bool): Whether to shuffle the data. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A dataset yielding batches of (image, label) pairs with images normalized.\n",
    "    \"\"\"\n",
    "    # Load images and labels from the directory, inferring subdirectory names as class names.\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels='inferred',\n",
    "        label_mode=\"int\",\n",
    "        batch_size=batch_size,\n",
    "        image_size=(image_size, image_size),\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    # print(dataset.class_names)\n",
    "    class_names = np.array(dataset.class_names)     # get the class names for the data\n",
    "    # num_classes = len(class_names)                  # get the number of classes in the dataset\n",
    "    # Normalize images to the [0, 1] range using a rescaling layer.\n",
    "    normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "    dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "    # Cache and prefetch data to optimize performance.\n",
    "    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset, class_names\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def create_augmentation_layer() -> tf.keras.Sequential:\n",
    "    \"\"\"\n",
    "    Creates a data augmentation pipeline using Keras layers.\n",
    "    Augmentations include:\n",
    "    - Random flipping (horizontal & vertical)\n",
    "    - Small rotations\n",
    "    - Zooming\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.RandomRotation(0.2),  # Random rotation (up to 20% of 360 degrees)\n",
    "        tf.keras.layers.RandomZoom(0.1),  # Random zoom (up to 10% zoom)\n",
    "        tf.keras.layers.RandomTranslation(0.1, 0.1),  # Random translation (up to 10% in both directions)\n",
    "        # tf.keras.layers.GaussianNoise(0.1),  # Add Gaussian noise to the images\n",
    "    ])\n",
    "\n",
    "def oversample_minority_classes(images: np.ndarray, labels: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Oversamples minority classes by duplicating their samples up to the majority class count.\n",
    "\n",
    "    Args:\n",
    "        images (np.ndarray): Numpy array of images.\n",
    "        labels (np.ndarray): Numpy array of labels.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: Balanced images and labels.\n",
    "    \"\"\"\n",
    "    unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
    "    max_samples = max(class_counts)  # Find the class with the most images\n",
    "    augmented_images, augmented_labels = [], []\n",
    "\n",
    "    augmentation_layer = create_augmentation_layer()\n",
    "\n",
    "    for class_label in unique_classes:\n",
    "        class_indices = np.where(labels == class_label)[0]\n",
    "        class_images = images[class_indices]\n",
    "        class_labels = labels[class_indices]\n",
    "\n",
    "        # Oversample minority classes\n",
    "        while len(class_images) < max_samples:\n",
    "            oversampled_images = resample(class_images, n_samples=min(max_samples - len(class_images), len(class_images)), replace=True)\n",
    "            augmented_samples = augmentation_layer(oversampled_images, training=True)  # Apply augmentation\n",
    "            class_images = np.concatenate([class_images, augmented_samples.numpy()], axis=0)\n",
    "\n",
    "        augmented_images.append(class_images)\n",
    "        augmented_labels.append(np.full(len(class_images), class_label))\n",
    "\n",
    "    return np.concatenate(augmented_images, axis=0), np.concatenate(augmented_labels, axis=0)\n",
    "\n",
    "def create_balanced_dataset(images: np.ndarray, labels: np.ndarray, batch_size: int = 32) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Creates a TensorFlow dataset from balanced images and labels, applying augmentation dynamically.\n",
    "\n",
    "    Args:\n",
    "        images (np.ndarray): Array of images.\n",
    "        labels (np.ndarray): Array of labels.\n",
    "        batch_size (int, optional): Batch size for training. Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: TensorFlow dataset.\n",
    "    \"\"\"\n",
    "    images, labels = oversample_minority_classes(images, labels)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "    dataset = dataset.shuffle(len(images))\n",
    "    # dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def callbacks_setup(checkpoint_filepath):\n",
    "    # EarlyStopping callback configuration\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',        # monitor validation loss\n",
    "        patience=6,                # number of epochs with no improvement to stop training\n",
    "        mode = 'min',              # want to minimize what it being monitored \n",
    "        restore_best_weights=False # don't restore in EarlyStopping, handled by ModelCheckpoint\n",
    "    )\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,   # path to save weights\n",
    "        save_weights_only=True,         # only save weights instead of full model\n",
    "        monitor='val_loss',             # monitor validation loss\n",
    "        mode='min',                     # want to maximize what is being monitored\n",
    "        save_best_only=True             # save the best weights\n",
    "    )            \n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',      # monitor validation loss \n",
    "        factor=0.5,              # factor by which the learning rate will be reduced \n",
    "        patience=4,              # number of epochs with no improvement to stop training \n",
    "        mode='min',              # want to minimize what it being monitored \n",
    "        min_lr=1e-6              # lower bound on the learning rate \n",
    "    )            \n",
    "\n",
    "    return early_stopping, model_checkpoint, reduce_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def save_confusion_matrix(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                          class_names: List[str], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots and saves the confusion matrix for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels.\n",
    "        class_names (List[str]): List of class names corresponding to class indices.\n",
    "        save_path (str): Path to save the confusion matrix plot.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix using sklearn\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "    # Plot with adjustments\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=12)\n",
    "    ax.set_ylabel(\"True label\", fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "    # Prevent labels from being cut off\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and close plot\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def save_loss_curve(history: Dict[str, Any], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots and saves the training and validation loss curves.\n",
    "\n",
    "    Args:\n",
    "        history (Dict[str, Any]): Dictionary containing training history (loss values).\n",
    "        save_path (str): Path to save the loss curve plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def save_roc_auc(true_labels: np.ndarray, predicted_probs: np.ndarray, class_names: list, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Plots and saves the ROC AUC curve for multi-class classification.\n",
    "    \n",
    "    Args:\n",
    "        true_labels (np.ndarray): True class labels.\n",
    "        predicted_probs (np.ndarray): Predicted class probabilities.\n",
    "        class_names (list): List of class names.\n",
    "        save_path (str, optional): Path to save the ROC curve plot. Defaults to None.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        fpr, tpr, _ = roc_curve(true_labels == i, predicted_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC AUC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def save_evaluation_metrics(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                            predicted_probs: np.ndarray, save_path: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics for multi-class classification and saves a bar chart.\n",
    "    The metrics include accuracy, precision, recall, F1 score, and ROC AUC.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels.\n",
    "        predicted_probs (np.ndarray): Array of predicted probabilities (shape: [n_samples, n_classes]).\n",
    "        save_path (str): Path to save the evaluation metrics bar chart.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary containing computed metrics.\n",
    "    \"\"\"\n",
    "    # Calculate accuracy by comparing predicted and true labels\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    # Compute macro-averaged metrics for multi-class classification\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    # For ROC AUC, first binarize the true labels to one-hot encoding\n",
    "    n_classes = predicted_probs.shape[1]\n",
    "    true_labels_binarized = label_binarize(true_labels, classes=list(range(n_classes)))\n",
    "    # Compute ROC AUC with a one-vs-rest approach and macro average\n",
    "    roc_auc = roc_auc_score(true_labels_binarized, predicted_probs, multi_class='ovr', average='macro')\n",
    "\n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Sensitivity (Recall)\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "    # Plot metrics as a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(metrics.keys(), metrics.values(), \n",
    "                   color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen', 'mediumpurple'])\n",
    "    # Annotate each bar with its value\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.4f}', ha='center', va='bottom')\n",
    "    plt.title(\"Model Evaluation Metrics\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def save_classification_report(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                               class_names: List[str], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the classification report to a text file for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels.\n",
    "        class_names (List[str]): List of class names.\n",
    "        save_path (str): Path to save the classification report.\n",
    "    \"\"\"\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "def calculate_metrics(true_labels: np.ndarray, predictions: np.ndarray) -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculates evaluation metrics for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predictions (np.ndarray): Array of predicted probabilities (shape: [n_samples, n_classes]).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, float, float]: A tuple containing accuracy, precision, recall, \n",
    "            F1 score, and ROC AUC score.\n",
    "    \"\"\"\n",
    "    # Convert predicted probabilities to predicted class labels using argmax\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    # Binarize true labels for ROC AUC calculation\n",
    "    n_classes = predictions.shape[1]\n",
    "    true_labels_binarized = label_binarize(true_labels, classes=list(range(n_classes)))\n",
    "    auc = roc_auc_score(true_labels_binarized, predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "def save_best_model_visuals(history: tf.keras.callbacks.History, model: tf.keras.Model, \n",
    "                              val_ds: tf.data.Dataset, class_names: List[str], \n",
    "                              weights_path: str, fold: int) -> None:\n",
    "    \"\"\"\n",
    "    Generates and saves evaluation visuals including confusion matrix, loss curve, evaluation \n",
    "    metrics bar chart, and classification report for the best performing model in a given fold.\n",
    "\n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): Training history object.\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        val_ds (tf.data.Dataset): Validation dataset.\n",
    "        class_names (List[str]): List of class names.\n",
    "        weights_path (str): Directory path to save visuals.\n",
    "        fold (int): Current fold number.\n",
    "    \"\"\"\n",
    "    # Generate predictions (predicted probabilities) for the validation set\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    # Convert predicted probabilities to class labels using argmax\n",
    "    val_predicted_ids = np.argmax(val_predictions, axis=1)\n",
    "    # Concatenate true labels from the validation dataset\n",
    "    true_labels = np.concatenate([y for _, y in val_ds], axis=0)\n",
    "\n",
    "    # Save the confusion matrix\n",
    "    confusion_matrix_path = os.path.join(weights_path, f\"confusion_matrix_fold{fold}.png\")\n",
    "    save_confusion_matrix(true_labels, val_predicted_ids, class_names, confusion_matrix_path)\n",
    "\n",
    "    # Save the loss curve using the training history\n",
    "    loss_curve_path = os.path.join(weights_path, f\"loss_curve_fold{fold}.png\")\n",
    "    save_loss_curve(history.history, loss_curve_path)\n",
    "\n",
    "    # Save the roc auc curve using the training history\n",
    "    roc_auc_curve_path = os.path.join(weights_path, f\"roc_auc_curve_fold{fold}.png\")\n",
    "    save_roc_auc(true_labels, val_predictions, class_names, roc_auc_curve_path)\n",
    "\n",
    "    # Save evaluation metrics bar chart (passing predicted probabilities for ROC AUC calculation)\n",
    "    metrics_bar_chart_path = os.path.join(weights_path, f\"evaluation_metrics_fold{fold}.png\")\n",
    "    save_evaluation_metrics(true_labels, val_predicted_ids, val_predictions, metrics_bar_chart_path)\n",
    "\n",
    "    # Save the classification report as a text file\n",
    "    classification_report_path = os.path.join(weights_path, f\"classification_report_fold{fold}.txt\")\n",
    "    save_classification_report(true_labels, val_predicted_ids, class_names, classification_report_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion_matrix_binary(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                          save_path: str, mpox_index: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Converts multi-class labels to binary (Mpox vs Other) and plots/saves the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels (multi-class integers).\n",
    "        save_path (str): Path to save the confusion matrix plot.\n",
    "        mpox_index (int): The index corresponding to Mpox. All other labels are considered \"Other\".\n",
    "    \"\"\"\n",
    "    # Convert multi-class labels to binary: 1 if label equals mpox_index, else 0.\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels == mpox_index).astype(int)\n",
    "    cm = confusion_matrix(binary_true, binary_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Other\", \"Mpox\"])\n",
    "    \n",
    "    # Plot with adjustments\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=12)\n",
    "    ax.set_ylabel(\"True label\", fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "    # Prevent labels from being cut off\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and close plot\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def save_loss_curve_binary(history: Dict[str, Any], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots and saves the training and validation loss curves.\n",
    "\n",
    "    Args:\n",
    "        history (Dict[str, Any]): Dictionary containing training history (loss values).\n",
    "        save_path (str): Path to save the loss curve plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def save_evaluation_metrics_binary(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                            predicted_probs: np.ndarray, save_path: str, \n",
    "                            mpox_index: int = 0) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes and plots evaluation metrics for binary classification (Mpox vs Other).\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels (multi-class integers).\n",
    "        predicted_probs (np.ndarray): Array of predicted probabilities for each class \n",
    "                                      (shape: [n_samples, n_classes]).\n",
    "        save_path (str): Path to save the evaluation metrics bar chart.\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary containing computed metrics.\n",
    "    \"\"\"\n",
    "    # Convert to binary labels\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels == mpox_index).astype(int)\n",
    "    # Use the probability for the Mpox class as the positive probability.\n",
    "    mpox_probs = predicted_probs[:, mpox_index]\n",
    "\n",
    "    accuracy = np.mean(binary_true == binary_pred)\n",
    "    precision = precision_score(binary_true, binary_pred)\n",
    "    recall = recall_score(binary_true, binary_pred)\n",
    "    f1 = f1_score(binary_true, binary_pred)\n",
    "    roc_auc = roc_auc_score(binary_true, mpox_probs)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Sensitivity (Recall)\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "    # Plot metrics as a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(metrics.keys(), metrics.values(), \n",
    "                   color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen', 'mediumpurple'])\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.4f}', ha='center', va='bottom')\n",
    "    plt.title(\"Evaluation Metrics (Mpox vs Other)\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def save_classification_report_binary(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                               save_path: str, mpox_index: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Saves the classification report for binary classification (Mpox vs Other).\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels (multi-class integers).\n",
    "        save_path (str): Path to save the classification report.\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "    \"\"\"\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels == mpox_index).astype(int)\n",
    "    report = classification_report(binary_true, binary_pred, target_names=[\"Other\", \"Mpox\"], digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "def calculate_metrics_binary(true_labels: np.ndarray, predictions: np.ndarray, \n",
    "                      mpox_index: int = 0) -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculates binary evaluation metrics for Mpox vs Other.\n",
    "    The multi-class predictions are converted into binary predictions where the positive class \n",
    "    is Mpox (identified by mpox_index) and all other classes are negative.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predictions (np.ndarray): Array of predicted probabilities (shape: [n_samples, n_classes]).\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, float, float]:\n",
    "            Accuracy, Precision, Recall, F1 Score, and ROC AUC.\n",
    "    \"\"\"\n",
    "    # Convert multi-class predictions to class indices\n",
    "    predicted_labels_multi = np.argmax(predictions, axis=1)\n",
    "    # Convert to binary: 1 if Mpox, 0 otherwise.\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels_multi == mpox_index).astype(int)\n",
    "    mpox_probs = predictions[:, mpox_index]\n",
    "\n",
    "    accuracy = np.mean(binary_true == binary_pred)\n",
    "    precision = precision_score(binary_true, binary_pred)\n",
    "    recall = recall_score(binary_true, binary_pred)\n",
    "    f1 = f1_score(binary_true, binary_pred)\n",
    "    auc = roc_auc_score(binary_true, mpox_probs)\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "def save_best_model_visuals_binary(history: tf.keras.callbacks.History, model: tf.keras.Model, \n",
    "                              val_ds: tf.data.Dataset, weights_path: str, \n",
    "                              fold: int, mpox_index: int = 1) -> None:\n",
    "    \"\"\"\n",
    "    Generates and saves evaluation visuals (confusion matrix, loss curve, metrics bar chart,\n",
    "    and classification report) for binary classification (Mpox vs Other) for the best performing model.\n",
    "\n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): Training history object.\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        val_ds (tf.data.Dataset): Validation dataset.\n",
    "        weights_path (str): Directory path to save visuals.\n",
    "        fold (int): Current fold number.\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "    \"\"\"\n",
    "    # Generate predictions for the validation set\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    predicted_ids_multi = np.argmax(val_predictions, axis=1)\n",
    "    true_labels = np.concatenate([y for _, y in val_ds], axis=0)\n",
    "    \n",
    "    # Save the confusion matrix\n",
    "    confusion_matrix_path = os.path.join(weights_path, f\"confusion_matrix_binary_fold{fold}.png\")\n",
    "    save_confusion_matrix_binary(true_labels, predicted_ids_multi, confusion_matrix_path, mpox_index)\n",
    "    \n",
    "    # Save the loss curve\n",
    "    loss_curve_path = os.path.join(weights_path, f\"loss_curve_binary_fold{fold}.png\")\n",
    "    save_loss_curve_binary(history.history, loss_curve_path)\n",
    "    \n",
    "    # Save evaluation metrics bar chart\n",
    "    metrics_bar_chart_path = os.path.join(weights_path, f\"evaluation_metrics_binary_fold{fold}.png\")\n",
    "    save_evaluation_metrics_binary(true_labels, predicted_ids_multi, val_predictions, metrics_bar_chart_path, mpox_index)\n",
    "    \n",
    "    # Save the classification report\n",
    "    classification_report_path = os.path.join(weights_path, f\"classification_report_binary_fold{fold}.txt\")\n",
    "    save_classification_report_binary(true_labels, predicted_ids_multi, classification_report_path, mpox_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation and fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and compile the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "def create_model(num_classes: int, config: dict, fine_tune: bool = False) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Creates a MobileNetV2-based model for multi-class classification.\n",
    "\n",
    "    The model uses a pre-trained MobileNetV2 as a feature extractor (with ImageNet weights) \n",
    "    and adds a global average pooling layer followed by a dense layer that outputs logits \n",
    "    for each class. The model is compiled using SparseCategoricalCrossentropy (from_logits=True)\n",
    "    which is appropriate for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of classes for classification.\n",
    "        config (dict): Configuration dictionary containing:\n",
    "            - \"image_size\": Tuple[int, int] representing the target (height, width) for images.\n",
    "            - \"optimizer\": Optimizer name (\"adam\" or \"sgd\").\n",
    "            - \"learning_rate\": Learning rate for the optimizer.\n",
    "        fine_tune (bool, optional): If True, the base model will be set as trainable for fine-tuning.\n",
    "                                    Otherwise, the base model is frozen. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The compiled Keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate the MobileNetV2 base model with pre-trained ImageNet weights.\n",
    "    # Exclude the top layer to allow for transfer learning.\n",
    "\n",
    "    model_name = config[\"model_name\"]\n",
    "\n",
    "    if model_name == \"mobilenet\":\n",
    "        base_model = tf.keras.applications.MobileNetV2\n",
    "    elif model_name == \"efficientnet\":\n",
    "        base_model = tf.keras.applications.EfficientNetB3\n",
    "    elif model_name == \"densenet\":\n",
    "        base_model = tf.keras.applications.DenseNet121\n",
    "    elif model_name == \"inceptionv3\":\n",
    "        base_model = tf.keras.applications.InceptionV3\n",
    "    elif model_name == \"resnet50\":\n",
    "        base_model = tf.keras.applications.ResNet50\n",
    "    elif model_name == \"vgg16\":\n",
    "        base_model = tf.keras.applications.VGG16\n",
    "    elif model_name == \"xception\":\n",
    "        base_model = tf.keras.applications.Xception\n",
    "    else:\n",
    "        raise ValueError(f\"Model name '{model_name}' is not supported.\")\n",
    "\n",
    "\n",
    "    base_model = base_model(\n",
    "        input_shape=(config[\"image_size\"], config[\"image_size\"], 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Set the trainability of the base model based on the fine_tune flag.\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # data_augmentation = tf.keras.Sequential([\n",
    "    #     layers.RandomFlip(\"horizontal\"),\n",
    "    #     layers.RandomRotation(0.1),\n",
    "    #     layers.RandomZoom(0.1)\n",
    "    # ])\n",
    "\n",
    "    # Build the model using the Keras Sequential API.\n",
    "    # For multi-class classification, the final Dense layer outputs 'num_classes' logits.\n",
    "    model = Sequential([\n",
    "        # data_augmentation,\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        # Dropout layer to randomly drop 50% of the neurons during training\n",
    "        # layers.Dropout(0.25),\n",
    "        # Dense layer with L2 regularization\n",
    "        # layers.Dense(num_classes, kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
    "        layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    # Select the optimizer based on configuration.\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
    "\n",
    "    # Compile the model with SparseCategoricalCrossentropy loss which expects logits.\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# fine tune model by unfreezing the layers after the first fine_tune_at layers\n",
    "def fine_tune_model(base_model, fine_tune_at):\n",
    "    # Unfreeze the layers starting from fine_tune_at index\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "\n",
    "def train_fold(fold: int, config: dict, best_f1_score: float, best_f1_dir: str, model_subdir: str) -> float:\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model for one fold of the dataset using images from the specified folders.\n",
    "    \n",
    "    Training images are loaded from 'Augmented Images/Fold{fold}/train',\n",
    "    validation images from 'Original Images/Fold{fold}/val', and test images from 'Original Images/Fold{fold}/test'.\n",
    "    \n",
    "    Args:\n",
    "        fold (int): The fold number to process.\n",
    "        config (dict): Configuration parameters including hyperparameters and paths.\n",
    "        best_f1_score (float): The best F1 score recorded so far.\n",
    "        best_f1_dir (str): Directory where the best model is saved.\n",
    "        model_subdir (str): Subdirectory for saving additional visuals and metrics.\n",
    "    \n",
    "    Returns:\n",
    "        float: The updated best F1 score after processing the current fold.\n",
    "    \"\"\"\n",
    "    # Define directory paths for the current fold\n",
    "    # augmented_train_dir = os.path.join(\"../data\", \"archive\", \"Augmented Images\", \"Augmented Images\", \"FOLDS_AUG\", f\"fold{fold}_AUG\", \"Train\")\n",
    "    augmented_train_dir = os.path.join(\"../data\", \"archive\", \"Original Images\", \"Original Images\", \"FOLDS\", f\"fold{fold}\", \"Train\")\n",
    "    original_val_dir = os.path.join(\"../data\", \"archive\", \"Original Images\", \"Original Images\", \"FOLDS\", f\"fold{fold}\", \"Valid\")\n",
    "    original_test_dir = os.path.join(\"../data\", \"archive\", \"Original Images\", \"Original Images\", \"FOLDS\", f\"fold{fold}\", \"Test\")\n",
    "\n",
    "    print(f\"\\nProcessing Fold {fold}...\")\n",
    "\n",
    "    # Load the training, validation, and test datasets\n",
    "    train_ds, class_names = load_image_dataset(augmented_train_dir, config['batch_size'],\n",
    "                                  config['image_size'], label_mode=config.get('label_mode', 'int'), shuffle=True)\n",
    "    val_ds, _ = load_image_dataset(original_val_dir, config['batch_size'],\n",
    "                                config['image_size'], label_mode=config.get('label_mode', 'int'), shuffle=False)\n",
    "    test_ds, _ = load_image_dataset(original_test_dir, config['batch_size'],\n",
    "                                 config['image_size'], label_mode=config.get('label_mode', 'int'), shuffle=False)\n",
    "    \n",
    "    # --- Compute class weights using sklearn ---\n",
    "    # Extract the labels from the training dataset.\n",
    "    # Note: train_ds is a tf.data.Dataset yielding (images, labels)\n",
    "    train_labels = np.concatenate([y.numpy() for _, y in train_ds], axis=0)\n",
    "    # Compute the class weights\n",
    "    classes = np.unique(train_labels)\n",
    "    computed_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n",
    "    # Create a dictionary mapping each class index to its weight.\n",
    "    class_weight_dict = {int(cls): weight for cls, weight in zip(classes, computed_weights)}\n",
    "    print(\"Class Weight Dictionary:\", class_weight_dict)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    # Iterate over the dataset\n",
    "    for batch_images, batch_labels in train_ds:\n",
    "        for img, lbl in zip(batch_images, batch_labels):  # Extract each image-label pair\n",
    "            images.append(img)\n",
    "            labels.append(lbl)\n",
    "\n",
    "    # Ensure all images are stacked correctly\n",
    "    images = np.array(tf.stack(images))  # Now all images should have the same shape\n",
    "    labels = np.array(labels)  # Convert labels to a NumPy array\n",
    "\n",
    "    train_ds = create_balanced_dataset(images, labels)\n",
    "\n",
    "    # Initialize dictionary to count samples per class\n",
    "    class_counts = Counter()\n",
    "\n",
    "    # Iterate through dataset and update class counts\n",
    "    for _, labels in train_ds:\n",
    "        class_counts.update(labels.numpy())  # Convert tensor to NumPy array and count occurrences\n",
    "\n",
    "    # Print the class distribution\n",
    "    print(\"Sample count per class in balanced dataset:\")\n",
    "    for class_label, count in sorted(class_counts.items()):\n",
    "        print(f\"Class {class_label}: {count} samples\")\n",
    "\n",
    "    print(\"______________________________________________\")\n",
    "\n",
    "\n",
    "    # Set up a filepath for model checkpointing for this fold\n",
    "    checkpoint_filepath = os.path.join(config['checkpoint_folder'], f'checkpoint_fold{fold}.weights.h5')\n",
    "\n",
    "    # -------------------- Step 1: Train with Frozen Base Layers --------------------\n",
    "    print(f\"Training with frozen base layers for {config['epochs']} epochs on Fold {fold}...\")\n",
    "\n",
    "    # Create the model for this fold (replace create_model with your actual model creation function)\n",
    "    model = create_model(len(class_names), config, fine_tune=False)\n",
    "    \n",
    "    # Setup callbacks (replace callbacks_setup with your callback setup function)\n",
    "    early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "    \n",
    "    # Train the model using the training and validation datasets, including class weights\n",
    "    history_frozen = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=config['epochs'],\n",
    "        callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Load the best weights saved during training\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # -------------------- Step 2: Fine-Tuning (Optional) --------------------\n",
    "    if config.get(\"fine_tune\", False):\n",
    "        print(f\"Unfreezing layers starting from layer {config['fine_tune_at']} for fine-tuning on Fold {fold}...\")\n",
    "        fine_tune_model(model.layers[0], config['fine_tune_at'])\n",
    "        # Set a lower learning rate for fine-tuning\n",
    "        fine_tune_lr = config['learning_rate'] * 0.01\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(f\"Fine-tuning for {config['fine_tune_epochs']} epochs on Fold {fold}...\")\n",
    "        early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "        history_fine_tune = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=config['fine_tune_epochs'],\n",
    "            callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        # Load the best weights after fine-tuning\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # -------------------- Evaluation on Validation Dataset --------------------\n",
    "    # Get predictions and compute metrics on the validation dataset\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    avg_val_loss = model.evaluate(val_ds, verbose=0)[0]\n",
    "    avg_val_accuracy, avg_val_precision, avg_val_recall, avg_val_f1, avg_val_auc = calculate_metrics(\n",
    "        np.concatenate([y for _, y in val_ds]),  # combine labels from val_ds\n",
    "        val_predictions\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFold {fold} Validation Metrics:\")\n",
    "    print(f\"  Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {avg_val_accuracy:.4f}\")\n",
    "    print(f\"  Precision: {avg_val_precision:.4f}\")\n",
    "    print(f\"  Recall: {avg_val_recall:.4f}\")\n",
    "    print(f\"  F1 Score: {avg_val_f1:.4f}\")\n",
    "    print(f\"  ROC AUC Score: {avg_val_auc:.4f}\")\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=1)\n",
    "    print(f\"Fold {fold} Test Metrics: Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # -------------------- Optional: Evaluation on Test Dataset --------------------\n",
    "    # If this fold produces the best F1 score so far, save the model and visuals\n",
    "    if avg_val_f1 > best_f1_score:\n",
    "        best_f1_score = avg_val_f1\n",
    "        # Save the best model (using model.export for TensorFlow SavedModel format)\n",
    "        model.export(best_f1_dir)\n",
    "        print(f\"Best model updated at Fold {fold} with F1 Score: {best_f1_score:.4f}\")\n",
    "        if config.get('save_metrics', False):\n",
    "            save_best_model_visuals(history_frozen, model, test_ds, class_names, model_subdir, fold)\n",
    "            save_best_model_visuals_binary(history_frozen, model, test_ds, model_subdir, fold, 5)\n",
    "    return best_f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_training_loop(config: dict, best_f1_dir: str, model_subdir: str) -> None:\n",
    "    \"\"\"\n",
    "    Main loop that iterates over each fold, training and evaluating the model.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration parameters including hyperparameters and training settings.\n",
    "        num_classes (int): Number of classes in the classification task.\n",
    "        best_f1_dir (str): Directory to save the best performing model.\n",
    "        model_subdir (str): Subdirectory for saving additional metrics and visuals.\n",
    "        class_names (List[str]): List of class names.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    best_val_f1score = 0.0\n",
    "    total_folds = config.get('folds', 5)  # default to 5 folds if not specified\n",
    "\n",
    "    # Iterate through each fold and update the best F1 score if improved.\n",
    "    for fold in range(1, total_folds + 1):\n",
    "        best_val_f1score = train_fold(fold, config, best_val_f1score,\n",
    "                                      best_f1_dir, model_subdir)\n",
    "    print(f\"\\nTraining complete. Best Validation F1 Score: {best_val_f1score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Fold 1...\n",
      "Found 537 files belonging to 6 classes.\n",
      "Found 144 files belonging to 6 classes.\n",
      "Found 74 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.79, 1: 1.8265306122448979, 2: 0.771551724137931, 3: 1.0783132530120483, 4: 2.418918918918919, 5: 0.4430693069306931}\n",
      "Sample count per class in balanced dataset:\n",
      "Class 0: 202 samples\n",
      "Class 1: 202 samples\n",
      "Class 2: 202 samples\n",
      "Class 3: 202 samples\n",
      "Class 4: 202 samples\n",
      "Class 5: 202 samples\n",
      "______________________________________________\n",
      "Training with frozen base layers for 50 epochs on Fold 1...\n",
      "Epoch 1/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 250ms/step - accuracy: 0.2912 - loss: 2.2469 - val_accuracy: 0.4028 - val_loss: 1.6695 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.6723 - loss: 0.9160 - val_accuracy: 0.5069 - val_loss: 1.3059 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.7684 - loss: 0.6302 - val_accuracy: 0.5000 - val_loss: 1.2645 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.8262 - loss: 0.5005 - val_accuracy: 0.5486 - val_loss: 1.1170 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - accuracy: 0.8611 - loss: 0.4161 - val_accuracy: 0.6181 - val_loss: 1.0322 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8921 - loss: 0.3421 - val_accuracy: 0.6389 - val_loss: 1.0139 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 208ms/step - accuracy: 0.9061 - loss: 0.2886 - val_accuracy: 0.6528 - val_loss: 0.9453 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.9093 - loss: 0.2672 - val_accuracy: 0.6389 - val_loss: 1.0192 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.9329 - loss: 0.2197 - val_accuracy: 0.6597 - val_loss: 0.8883 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.9451 - loss: 0.1991 - val_accuracy: 0.6597 - val_loss: 0.9409 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.9383 - loss: 0.1843 - val_accuracy: 0.6667 - val_loss: 0.8555 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.9372 - loss: 0.1817 - val_accuracy: 0.6597 - val_loss: 0.9706 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.9517 - loss: 0.1511 - val_accuracy: 0.6667 - val_loss: 0.8622 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.9613 - loss: 0.1463 - val_accuracy: 0.6667 - val_loss: 0.8910 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.9670 - loss: 0.1231 - val_accuracy: 0.6667 - val_loss: 0.9364 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.9528 - loss: 0.1209 - val_accuracy: 0.6806 - val_loss: 0.8795 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.9590 - loss: 0.1150 - val_accuracy: 0.6736 - val_loss: 0.8652 - learning_rate: 5.0000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step \n",
      "\n",
      "Fold 1 Validation Metrics:\n",
      "  Loss: 0.8555\n",
      "  Accuracy: 0.6667\n",
      "  Precision: 0.6675\n",
      "  Recall: 0.6905\n",
      "  F1 Score: 0.6702\n",
      "  ROC AUC Score: 0.9045\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.7427 - loss: 0.5985\n",
      "Fold 1 Test Metrics: Loss: 0.5933, Accuracy: 0.7432\n",
      "INFO:tensorflow:Assets written to: ../saved_models\\model1\\best_f1score_fold\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models\\model1\\best_f1score_fold\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_models\\model1\\best_f1score_fold'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_7718')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1538272137424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272136080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272136464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272135696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272137040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272135888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272148368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272145680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272135312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272138192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272610064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272611984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272612368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272611600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272608528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272613136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272609104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272609488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272608720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272613904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272610256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272612944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272613328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272612560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272611024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272614096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272616208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272616400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272616016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272615248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272616784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272618128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272618320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272617936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272617168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272618704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272620048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272620240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272619856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272619088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272620624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272621968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272622160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272621776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272621008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272622544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272623888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272624080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272623696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272622928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272621392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272789712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272788944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272789520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272789904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272790288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272791632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272791824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272791440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272790672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272792208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272793552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272793744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272793360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272792592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272794128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272795472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272795664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272795280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272794512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272796048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272797392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272797584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272797200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272796432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272797968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272799312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272799504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272799120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272798352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272799888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272801232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272801424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272801040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272800272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272801808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272803152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272803344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272802960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272802192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272803728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272804112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273231504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272788560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272802576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272147792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272146064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273231312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272146256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272148560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273231120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273233424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273233616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273233232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273230928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273234000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273235344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273235536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273235152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273234384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273235920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273237264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273237456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273237072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273236304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273237840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273239184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273239376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273238992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273238224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273239760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273241104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273241296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273240912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273240144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273241680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273243024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273243216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273242832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273242064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273243600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273244944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273245136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273244752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273243984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273245520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273246864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273244368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273246672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273245904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220038352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273543568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273543760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273543376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273542416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273544144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273545488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273545680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273545296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273544528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273546064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273547408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273547600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273547216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273546448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273547984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273549328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273549520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273549136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273548368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273549904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273551248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273551440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273551056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273550288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273551824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273553168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273553360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273552976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273552208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273553744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273555088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273555280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273554896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273554128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273555664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273557008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273557200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273556816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273556048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273557584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273935824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273936400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273542992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273557968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273936208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273937744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273937936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273937552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273936784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273938320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273939664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273939856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273939472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273938704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273940240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273941584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273941776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273941392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273940624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273942160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273943504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273943696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273943312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273942544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273944080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273945424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273945616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273945232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273944464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273946000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273947344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273947536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273947152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273946384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273947920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273949264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273949456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273949072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273948304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273949840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273951184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273948688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273950992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273950224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538273951376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274329616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274328848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274329808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274329040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274330576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274331920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274332112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274331728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274330960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274332496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274333840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274334032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274333648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274332880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274334416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274335760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274335952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274335568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274334800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274336336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274337680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274337872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274337488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274336720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274338256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274339600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274339792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274339408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274338640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274340176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274341520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274341712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274341328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274340560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274342096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274343440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Best model updated at Fold 1 with F1 Score: 0.6702\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step\n",
      "\n",
      "Processing Fold 2...\n",
      "Found 509 files belonging to 6 classes.\n",
      "Found 164 files belonging to 6 classes.\n",
      "Found 82 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.6633986928104576, 1: 1.8049645390070923, 2: 0.7782874617737003, 3: 1.0604166666666666, 4: 2.120833333333333, 5: 0.4661172161172161}\n",
      "Sample count per class in balanced dataset:\n",
      "Class 0: 182 samples\n",
      "Class 1: 182 samples\n",
      "Class 2: 182 samples\n",
      "Class 3: 182 samples\n",
      "Class 4: 182 samples\n",
      "Class 5: 182 samples\n",
      "______________________________________________\n",
      "Training with frozen base layers for 50 epochs on Fold 2...\n",
      "Epoch 1/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 268ms/step - accuracy: 0.3810 - loss: 1.9326 - val_accuracy: 0.4390 - val_loss: 1.5072 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.6953 - loss: 0.8988 - val_accuracy: 0.5671 - val_loss: 1.1132 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.7944 - loss: 0.6253 - val_accuracy: 0.6037 - val_loss: 0.9849 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 235ms/step - accuracy: 0.8284 - loss: 0.5234 - val_accuracy: 0.6098 - val_loss: 1.0110 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 232ms/step - accuracy: 0.8537 - loss: 0.4244 - val_accuracy: 0.6037 - val_loss: 1.0411 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.8793 - loss: 0.3584 - val_accuracy: 0.6220 - val_loss: 0.8999 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9086 - loss: 0.2932 - val_accuracy: 0.6768 - val_loss: 0.7739 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9270 - loss: 0.2713 - val_accuracy: 0.6463 - val_loss: 0.8810 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 234ms/step - accuracy: 0.9293 - loss: 0.2190 - val_accuracy: 0.6768 - val_loss: 0.7943 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 238ms/step - accuracy: 0.9560 - loss: 0.2018 - val_accuracy: 0.6524 - val_loss: 0.8441 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 243ms/step - accuracy: 0.9449 - loss: 0.1825 - val_accuracy: 0.6707 - val_loss: 0.7755 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 241ms/step - accuracy: 0.9500 - loss: 0.1545 - val_accuracy: 0.6707 - val_loss: 0.8117 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 242ms/step - accuracy: 0.9544 - loss: 0.1598 - val_accuracy: 0.6768 - val_loss: 0.7802 - learning_rate: 5.0000e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 353ms/step\n",
      "\n",
      "Fold 2 Validation Metrics:\n",
      "  Loss: 0.7739\n",
      "  Accuracy: 0.6768\n",
      "  Precision: 0.6780\n",
      "  Recall: 0.7658\n",
      "  F1 Score: 0.6904\n",
      "  ROC AUC Score: 0.9266\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.6943 - loss: 0.8256\n",
      "Fold 2 Test Metrics: Loss: 0.9122, Accuracy: 0.6463\n",
      "INFO:tensorflow:Assets written to: ../saved_models\\model1\\best_f1score_fold\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models\\model1\\best_f1score_fold\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_models\\model1\\best_f1score_fold'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_7881')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1535100368848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100366544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100370000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100368080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100356752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272614864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100367696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220037200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100363856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100365776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220034512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220030672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220032784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220034320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220032592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220033936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220030480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220028944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220031632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220032400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220030096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220026640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220025104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220027792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220028560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220026256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220037008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220036432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220037584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220024720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220035472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220033360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220033168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220032976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220034128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220030288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220029520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220029328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220029136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220031440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220026448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220025680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220025488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220025296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220027600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535220029904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961318032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961331856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961318800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961320144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961328976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961319376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961318224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961320528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961329168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961330320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964893392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964891088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535961331088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964889936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964903568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964901072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964899536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964899920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964904912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964898768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964893008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964894160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964889360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964897232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964889552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964895888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964900688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964901456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964899728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964891472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964740880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964740112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964899152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964892048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964735120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964736656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964725904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964728208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964738576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964737040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964741456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964734928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964736848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964730896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964734736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964728976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964729360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964728592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964735888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964732816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964737808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078676240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964726480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535964734352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078678544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078684880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078683920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078678160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078681808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078685840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078678352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078679888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078691600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078687568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078677776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078685264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078687952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078684112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078680080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078689872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1534903942992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078685648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1532337157520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1532329212432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1534901863824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077984208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077971920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1532336780880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536078683344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077972496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077974608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077979408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077975568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077984400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077981328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077987664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077986320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077983248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077982096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077985936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077975952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077978640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077974800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077974032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077980560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077983632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077982480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077977872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536077980368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245457424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245453584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245458384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245459152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245462992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245456848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245451472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245449168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245453008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245455312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245461456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245460304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245457616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245455504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245461072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245457232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245452624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245459344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245449360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245456464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245449936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536079053840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245675408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536079053456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536079054608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245676560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245665616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245670416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245671184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245669456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245668880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245662736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245677328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245663504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245662160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245676944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245672336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245669648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245667536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245676176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245669264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245664656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245674640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245661968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245668496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126429648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126428880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126429264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126426576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126427152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126429840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126427344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126427536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126426000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126424848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126428496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126425040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274344016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126428112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126426384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274343248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272138000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272143376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126425808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538126419856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272143760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272140688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272140496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272141072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272142992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272139536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272147600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272147984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272148752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272138384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272133392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272143184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272142800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272143568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272144912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272142416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272139728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272139152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272139920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272141456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272138960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272134736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272140880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272149136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538272145104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172249680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172261008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172255248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172257360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172253520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172251600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172245264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172247568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172246800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172247760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172247952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172253328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172259280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172254864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172260240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172257168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172249872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172247184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172251024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172255632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172259088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535959394704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535959393744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172258704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535959385872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535959387408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535959395856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Best model updated at Fold 2 with F1 Score: 0.6904\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step\n",
      "\n",
      "Processing Fold 3...\n",
      "Found 538 files belonging to 6 classes.\n",
      "Found 153 files belonging to 6 classes.\n",
      "Found 64 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.7581699346405228, 1: 1.9078014184397163, 2: 0.7865497076023392, 3: 1.1955555555555555, 4: 2.490740740740741, 5: 0.4170542635658915}\n",
      "Sample count per class in balanced dataset:\n",
      "Class 0: 215 samples\n",
      "Class 1: 215 samples\n",
      "Class 2: 215 samples\n",
      "Class 3: 215 samples\n",
      "Class 4: 215 samples\n",
      "Class 5: 215 samples\n",
      "______________________________________________\n",
      "Training with frozen base layers for 50 epochs on Fold 3...\n",
      "Epoch 1/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 246ms/step - accuracy: 0.3434 - loss: 2.2393 - val_accuracy: 0.4379 - val_loss: 1.4686 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.7266 - loss: 0.7821 - val_accuracy: 0.5425 - val_loss: 1.2953 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.7933 - loss: 0.5720 - val_accuracy: 0.5686 - val_loss: 1.2569 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.8432 - loss: 0.4504 - val_accuracy: 0.6405 - val_loss: 1.1212 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.8791 - loss: 0.3605 - val_accuracy: 0.6340 - val_loss: 1.0380 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.8965 - loss: 0.3098 - val_accuracy: 0.6144 - val_loss: 1.1274 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.8952 - loss: 0.2815 - val_accuracy: 0.6471 - val_loss: 1.0423 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.9351 - loss: 0.2414 - val_accuracy: 0.6405 - val_loss: 1.0540 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - accuracy: 0.9346 - loss: 0.2157 - val_accuracy: 0.6797 - val_loss: 0.9823 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 310ms/step - accuracy: 0.9331 - loss: 0.1958 - val_accuracy: 0.6536 - val_loss: 1.0059 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 395ms/step - accuracy: 0.9547 - loss: 0.1649 - val_accuracy: 0.6471 - val_loss: 1.0509 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 383ms/step - accuracy: 0.9457 - loss: 0.1587 - val_accuracy: 0.6601 - val_loss: 1.0440 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 377ms/step - accuracy: 0.9676 - loss: 0.1382 - val_accuracy: 0.6797 - val_loss: 1.0093 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 439ms/step - accuracy: 0.9690 - loss: 0.1307 - val_accuracy: 0.6928 - val_loss: 1.0331 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 438ms/step - accuracy: 0.9681 - loss: 0.1318 - val_accuracy: 0.6732 - val_loss: 1.0555 - learning_rate: 5.0000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step  \n",
      "\n",
      "Fold 3 Validation Metrics:\n",
      "  Loss: 0.9823\n",
      "  Accuracy: 0.6797\n",
      "  Precision: 0.6693\n",
      "  Recall: 0.6928\n",
      "  F1 Score: 0.6779\n",
      "  ROC AUC Score: 0.8857\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.7188 - loss: 0.6025\n",
      "Fold 3 Test Metrics: Loss: 0.6752, Accuracy: 0.6875\n",
      "\n",
      "Processing Fold 4...\n",
      "Found 524 files belonging to 6 classes.\n",
      "Found 150 files belonging to 6 classes.\n",
      "Found 81 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.6794871794871795, 1: 1.9848484848484849, 2: 0.7594202898550725, 3: 1.0522088353413654, 4: 2.425925925925926, 5: 0.45017182130584193}\n",
      "Sample count per class in balanced dataset:\n",
      "Class 0: 194 samples\n",
      "Class 1: 194 samples\n",
      "Class 2: 194 samples\n",
      "Class 3: 194 samples\n",
      "Class 4: 194 samples\n",
      "Class 5: 194 samples\n",
      "______________________________________________\n",
      "Training with frozen base layers for 50 epochs on Fold 4...\n",
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 540ms/step - accuracy: 0.3480 - loss: 2.1541 - val_accuracy: 0.3200 - val_loss: 1.8008 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.6818 - loss: 0.9281 - val_accuracy: 0.4333 - val_loss: 1.4043 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 408ms/step - accuracy: 0.7547 - loss: 0.6916 - val_accuracy: 0.4867 - val_loss: 1.2355 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 0.8181 - loss: 0.5038 - val_accuracy: 0.5533 - val_loss: 1.1191 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 480ms/step - accuracy: 0.8687 - loss: 0.4411 - val_accuracy: 0.5267 - val_loss: 1.1540 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 423ms/step - accuracy: 0.8594 - loss: 0.3689 - val_accuracy: 0.5600 - val_loss: 1.1259 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 415ms/step - accuracy: 0.8841 - loss: 0.3459 - val_accuracy: 0.5933 - val_loss: 1.0415 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 494ms/step - accuracy: 0.9153 - loss: 0.2775 - val_accuracy: 0.5800 - val_loss: 1.0083 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 457ms/step - accuracy: 0.9270 - loss: 0.2507 - val_accuracy: 0.5667 - val_loss: 1.0620 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 452ms/step - accuracy: 0.9293 - loss: 0.2407 - val_accuracy: 0.5800 - val_loss: 1.0989 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 475ms/step - accuracy: 0.9314 - loss: 0.2041 - val_accuracy: 0.5800 - val_loss: 1.0129 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 512ms/step - accuracy: 0.9479 - loss: 0.1803 - val_accuracy: 0.6133 - val_loss: 0.9965 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 474ms/step - accuracy: 0.9540 - loss: 0.1705 - val_accuracy: 0.5933 - val_loss: 1.0009 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 493ms/step - accuracy: 0.9593 - loss: 0.1533 - val_accuracy: 0.6333 - val_loss: 0.9773 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 534ms/step - accuracy: 0.9693 - loss: 0.1386 - val_accuracy: 0.6400 - val_loss: 0.9441 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 512ms/step - accuracy: 0.9592 - loss: 0.1374 - val_accuracy: 0.6267 - val_loss: 0.9728 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 459ms/step - accuracy: 0.9731 - loss: 0.1236 - val_accuracy: 0.6400 - val_loss: 0.9478 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 428ms/step - accuracy: 0.9629 - loss: 0.1296 - val_accuracy: 0.6533 - val_loss: 0.9259 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 481ms/step - accuracy: 0.9709 - loss: 0.1144 - val_accuracy: 0.6333 - val_loss: 0.9811 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 461ms/step - accuracy: 0.9739 - loss: 0.0980 - val_accuracy: 0.6600 - val_loss: 0.9045 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 476ms/step - accuracy: 0.9813 - loss: 0.0976 - val_accuracy: 0.6467 - val_loss: 0.9732 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 483ms/step - accuracy: 0.9786 - loss: 0.0872 - val_accuracy: 0.6467 - val_loss: 0.9414 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 456ms/step - accuracy: 0.9849 - loss: 0.0850 - val_accuracy: 0.6533 - val_loss: 0.9337 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 424ms/step - accuracy: 0.9854 - loss: 0.0801 - val_accuracy: 0.6400 - val_loss: 0.9772 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 469ms/step - accuracy: 0.9805 - loss: 0.0777 - val_accuracy: 0.6533 - val_loss: 0.9354 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 477ms/step - accuracy: 0.9847 - loss: 0.0784 - val_accuracy: 0.6533 - val_loss: 0.9452 - learning_rate: 5.0000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step  \n",
      "\n",
      "Fold 4 Validation Metrics:\n",
      "  Loss: 0.9045\n",
      "  Accuracy: 0.6600\n",
      "  Precision: 0.6283\n",
      "  Recall: 0.6860\n",
      "  F1 Score: 0.6429\n",
      "  ROC AUC Score: 0.8952\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step - accuracy: 0.7415 - loss: 0.7228\n",
      "Fold 4 Test Metrics: Loss: 0.7312, Accuracy: 0.7407\n",
      "\n",
      "Processing Fold 5...\n",
      "Found 538 files belonging to 6 classes.\n",
      "Found 154 files belonging to 6 classes.\n",
      "Found 63 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.6918238993710693, 1: 2.0852713178294575, 2: 0.8226299694189603, 3: 1.0803212851405624, 4: 2.3596491228070176, 5: 0.4229559748427673}\n",
      "Sample count per class in balanced dataset:\n",
      "Class 0: 212 samples\n",
      "Class 1: 212 samples\n",
      "Class 2: 212 samples\n",
      "Class 3: 212 samples\n",
      "Class 4: 212 samples\n",
      "Class 5: 212 samples\n",
      "______________________________________________\n",
      "Training with frozen base layers for 50 epochs on Fold 5...\n",
      "Epoch 1/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 551ms/step - accuracy: 0.3396 - loss: 2.0913 - val_accuracy: 0.5714 - val_loss: 1.2010 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 502ms/step - accuracy: 0.7066 - loss: 0.8627 - val_accuracy: 0.6169 - val_loss: 1.2009 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 509ms/step - accuracy: 0.8089 - loss: 0.5937 - val_accuracy: 0.6623 - val_loss: 0.9974 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 502ms/step - accuracy: 0.8386 - loss: 0.4833 - val_accuracy: 0.6883 - val_loss: 0.9072 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 419ms/step - accuracy: 0.8722 - loss: 0.3858 - val_accuracy: 0.6883 - val_loss: 0.9314 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 291ms/step - accuracy: 0.8855 - loss: 0.3473 - val_accuracy: 0.7078 - val_loss: 0.9068 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 374ms/step - accuracy: 0.9134 - loss: 0.2789 - val_accuracy: 0.7143 - val_loss: 0.8440 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 399ms/step - accuracy: 0.9232 - loss: 0.2551 - val_accuracy: 0.7273 - val_loss: 0.7818 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 456ms/step - accuracy: 0.9367 - loss: 0.2141 - val_accuracy: 0.7468 - val_loss: 0.8202 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 397ms/step - accuracy: 0.9398 - loss: 0.2094 - val_accuracy: 0.7338 - val_loss: 0.8118 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 458ms/step - accuracy: 0.9460 - loss: 0.1763 - val_accuracy: 0.7338 - val_loss: 0.8427 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 396ms/step - accuracy: 0.9389 - loss: 0.1724 - val_accuracy: 0.7403 - val_loss: 0.8609 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 435ms/step - accuracy: 0.9519 - loss: 0.1462 - val_accuracy: 0.7403 - val_loss: 0.7567 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 370ms/step - accuracy: 0.9506 - loss: 0.1571 - val_accuracy: 0.7273 - val_loss: 0.7759 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 387ms/step - accuracy: 0.9690 - loss: 0.1306 - val_accuracy: 0.7338 - val_loss: 0.7750 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 421ms/step - accuracy: 0.9649 - loss: 0.1311 - val_accuracy: 0.7338 - val_loss: 0.8244 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 420ms/step - accuracy: 0.9631 - loss: 0.1337 - val_accuracy: 0.7338 - val_loss: 0.7893 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 465ms/step - accuracy: 0.9679 - loss: 0.1174 - val_accuracy: 0.7338 - val_loss: 0.7931 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 435ms/step - accuracy: 0.9714 - loss: 0.1124 - val_accuracy: 0.7468 - val_loss: 0.7843 - learning_rate: 2.5000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step  \n",
      "\n",
      "Fold 5 Validation Metrics:\n",
      "  Loss: 0.7567\n",
      "  Accuracy: 0.7403\n",
      "  Precision: 0.7219\n",
      "  Recall: 0.7923\n",
      "  F1 Score: 0.7468\n",
      "  ROC AUC Score: 0.9243\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470ms/step - accuracy: 0.8001 - loss: 0.5521\n",
      "Fold 5 Test Metrics: Loss: 0.5664, Accuracy: 0.8095\n",
      "INFO:tensorflow:Assets written to: ../saved_models\\model1\\best_f1score_fold\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models\\model1\\best_f1score_fold\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_models\\model1\\best_f1score_fold'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_8370')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1531702070352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536241581712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536241579984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100360400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536241578640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440497936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536241566928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536241571920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536241580560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536172194512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440864912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440872592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440862992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440871440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440858384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440864144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440868752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440873744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440866064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440864720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440860304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440862800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440872208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440864528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440869520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440874320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440858576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440867600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440860688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440865680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440863760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274848080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274851536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1537440870480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274850384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274851920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274847696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183534800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274850000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1538274849616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183535184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183537872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183538256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183537488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183535952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183539024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183541712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183542096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183541328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183539792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183542864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183545552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183533840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183545168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183543632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183534608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183537296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183537680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183536912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183535376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183538448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183541136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183541520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183540752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183539216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183542288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183544976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183545360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183544592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183543056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183546320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183547664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183547856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183547472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183546704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1535100364048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183549008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183548624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183549392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183548240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536183549584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184091664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184090896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184091856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184091088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184092624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184093968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184094160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184093776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184093008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184094544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184095888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184096080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184095696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184094928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184096464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184097808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184098000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184097616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184096848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184098384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184099728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184099920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184099536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184098768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184100304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184101648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184101840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184101456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184100688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184102224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184103568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184103760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184103376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184102608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184104144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184105488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184105680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184105296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184104528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184106064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245743888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245744656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184092240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536184106448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245744464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245746000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245746192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245745808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245745040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245746576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245747920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245748112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245747728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245746960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245748496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245749840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245750032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245749648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245748880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245750416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245751760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245751952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245751568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245750800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245752336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245753680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245753872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245753488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245752720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245754256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245755600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245755792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245755408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245754640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245756176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245757520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245757712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245757328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245756560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245758096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245759440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245756944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245759248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245758480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536245759632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246171024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246171216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246170832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246169680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246171600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246172944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246173136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246172752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246171984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246173520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246174864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246175056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246174672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246173904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246175440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246176784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246176976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246176592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246175824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246177360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246178704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246178896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246178512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246177744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246179280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246180624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246180816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246180432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246179664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246181200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246182544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246182736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246182352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246181584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246183120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246184464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246184656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246184272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246183504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246185040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246514128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246514704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246170448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246185424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246514512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246516048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246516240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246515856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246515088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246516624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246517968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246518160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246517776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246517008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246518544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246519888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246520080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246519696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246518928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246520464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246521808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246522000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246521616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246520848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246522384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246523728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246523920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246523536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246522768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246524304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246525648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246525840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246525456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246524688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246526224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246527568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246527760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246527376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246526608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246528144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246529488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246526992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246529296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246528528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246529680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246891536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246890768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246891728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246890960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246892496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246893840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246894032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246893648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246892880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246894416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1536246895760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Best model updated at Fold 5 with F1 Score: 0.7468\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
      "\n",
      "Training complete. Best Validation F1 Score: 0.7468\n"
     ]
    }
   ],
   "source": [
    "for i, config in enumerate(configs):\n",
    "    # Define the base path for saving models\n",
    "    model_subdir = os.path.join(save_dir, f'model{i + 1}')\n",
    "    os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving cthe model with the best f1-score\n",
    "    best_f1_dir = os.path.join(model_subdir, 'best_f1score_fold')\n",
    "    os.makedirs(best_f1_dir, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving checkpoints for model\n",
    "    checkpoint_folder = os.path.join(model_subdir, 'checkpoints')\n",
    "    os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "    \n",
    "    config['checkpoint_folder'] = checkpoint_folder\n",
    "\n",
    "    main_training_loop(configs[i], best_f1_dir, model_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 537 files belonging to 6 classes.\n",
      "Fold 1 - Train Set Class Distribution:\n",
      "Class 0: 50 samples\n",
      "Class 1: 49 samples\n",
      "Class 2: 116 samples\n",
      "Class 3: 83 samples\n",
      "Class 4: 37 samples\n",
      "Class 5: 202 samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 files belonging to 6 classes.\n",
      "Fold 1 - Valid Set Class Distribution:\n",
      "Class 0: 16 samples\n",
      "Class 1: 10 samples\n",
      "Class 2: 29 samples\n",
      "Class 3: 22 samples\n",
      "Class 4: 12 samples\n",
      "Class 5: 55 samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8SklEQVR4nO3deVxVdeL/8fcFAZXVhUVHBHFHQydMZVxTlHBJk35Tjk5qWk3hilbSlEpp2GZmqTllLjNjliblMmlmJmWuEKZlbmlaCrgBigkK5/dHD++3G4tcBC/HXs/H4z4e3s8595z3PaL3zdmuxTAMQwAAACbk5OgAAAAA5UWRAQAApkWRAQAApkWRAQAApkWRAQAApkWRAQAApkWRAQAApkWRAQAApkWRAQAApkWRwS1l8eLFslgsOnbs2HXnDQ4O1vDhwys9kyN1795d3bt3tz4/duyYLBaLFi9efN3XDh8+XMHBwZWWzVF+v03Myp6f9Rv1+5+Faz9HL7/8cqWvW5KmTZsmi8VyU9YF86HIwOGu/Ydc3GPy5MmOjqf33ntPQ4cOVdOmTWWxWCrlQ3DVqlWyWCx6++23S5xn48aNslgsmjNnToWv/0YUFhZq6dKl6tChg2rXri1PT081a9ZMDzzwgLZv32738i5duqRp06bp888/t+t1GRkZmjRpklq0aKGaNWvK3d1d4eHhmj59urKysuzOcTN9/vnnNj/3bm5u8vf3V/fu3fX888/r9OnTFbKe8m7bm6EqZ0PVVs3RAYBrnn32WTVq1MhmrHXr1g5K83/mz5+vlJQU3XHHHTp79mylrKNv377y9vbWsmXLNGrUqGLnWbZsmZydnXX//feXez1BQUH65Zdf5OLiUu5l/N7YsWM1d+5cDRgwQEOGDFG1atV04MABffzxxwoJCVHHjh3tWt6lS5eUkJAgSWUujbt27VKfPn108eJFDR06VOHh4ZKk3bt3a+bMmUpOTtYnn3xiVw5HGDt2rO644w4VFBTo9OnT+uqrrzR16lTNmjVL77//vnr06GGd9+9//7vuv/9+ubm5lXn55dm2kvTWW2+psLCwzPOXR2nZnn766SrxSw2qJooMqozo6Gi1a9fO0TGK+Pe//60//elPcnJyqrRi5ebmpnvvvVeLFi3SyZMnVb9+fZvply9fVlJSknr16iU/P79yr8disah69eo3GtcqIyND8+bN00MPPaR//etfNtNmz55dYXsSSpOVlaV77rlHzs7O+vrrr9WiRQub6TNmzNBbb71V6TkqQpcuXXTvvffajO3Zs0e9e/dWTEyMvvvuO9WrV0+S5OzsLGdn50rNk5ubK3d39wotvuVRrVo1VavGxxWKx6ElmMZnn32mLl26yN3dXT4+PhowYID2799/3dcZhqHp06erQYMGqlmzpu688059++23ZV5vYGCgnJwq/5/K0KFDVVhYqOXLlxeZtm7dOmVnZ2vIkCGSpEWLFqlHjx7y8/OTm5ubQkNDNX/+/Ouuo6RzZD788EO1bt1a1atXV+vWrZWUlFSmzEePHpVhGOrUqVORaRaLpUjpysrK0vjx4xUYGCg3Nzc1adJEL7zwgvW3/WPHjsnX11eSlJCQYD3UMm3atBIzLFiwQD///LNmzZpVpMRIkr+/v55++ukSX5+fn68pU6YoPDxc3t7ecnd3V5cuXbR58+Yi8y5fvlzh4eHy9PSUl5eXbrvtNr322mvW6VeuXFFCQoKaNm2q6tWrq06dOurcubM2btxY4vqvp02bNpo9e7aysrL0xhtvWMeLO0dm9+7dioqKUt26dVWjRg01atRIDz74oKTrb9vhw4fLw8NDR44cUZ8+feTp6Wn9eSvtfKlXX31VQUFBqlGjhrp166Z9+/bZTC/pnKTfLvN62Yo7R+bq1at67rnn1LhxY7m5uSk4OFhPPfWU8vLybOYLDg5Wv3799OWXX6p9+/aqXr26QkJCtHTp0uI3OEyHiosqIzs7W2fOnLEZq1u3riTp008/VXR0tEJCQjRt2jT98ssvev3119WpUyelpqaWelLqlClTNH36dPXp00d9+vRRamqqevfurfz8/Mp8O3br2rWrGjRooGXLlikuLs5m2rJly1SzZk0NHDhQ0q+Hu1q1aqW7775b1apV05o1a/TYY4+psLBQsbGxdq33k08+UUxMjEJDQ5WYmKizZ89qxIgRatCgwXVfGxQUJElasWKF/t//+3+qWbNmifNeunRJ3bp1088//6xHHnlEDRs21FdffaX4+HidOnVKs2fPlq+vr+bPn69HH31U99xzjwYNGiRJCgsLK3G5q1evVo0aNYrsySirnJwcvf322xo8eLAeeughXbhwQQsXLlRUVJR27typtm3bSvr1HKXBgwerZ8+eeuGFFyRJ+/fv19atWzVu3DhJv37gJiYmatSoUWrfvr1ycnK0e/dupaamqlevXuXKJ0n33nuvRo4cqU8++UQzZswodp7MzEz17t1bvr6+mjx5snx8fHTs2DGtWrVKksq0ba9evaqoqCh17txZL7/8cql/n5K0dOlSXbhwQbGxsbp8+bJee+019ejRQ3v37pW/v3+Z3195/t5HjRqlJUuW6N5779XEiRO1Y8cOJSYmav/+/UWK+OHDh63bcNiwYXrnnXc0fPhwhYeHq1WrVmXOiSrKABxs0aJFhqRiH9e0bdvW8PPzM86ePWsd27Nnj+Hk5GQ88MADRZZ19OhRwzAMIzMz03B1dTX69u1rFBYWWud76qmnDEnGsGHD7MraqlUro1u3buV6n2Xx+OOPG5KMAwcOWMeys7ON6tWrG4MHD7aOXbp0qchro6KijJCQEJuxbt262eQ9evSoIclYtGiRdaxt27ZGvXr1jKysLOvYJ598YkgygoKCrpv5gQceMCQZtWrVMu655x7j5ZdfNvbv319kvueee85wd3c3Dh48aDM+efJkw9nZ2Th+/LhhGIZx+vRpQ5IxderU667bMAyjVq1aRps2bco0r2EU3SZXr1418vLybOY5f/684e/vbzz44IPWsXHjxhleXl7G1atXS1x2mzZtjL59+5Y5yzWbN282JBkrVqwoddm1atWyPv/9z3pSUpIhydi1a1eJyyht2w4bNsyQZEyePLnYab/9Wbj2c1SjRg3jp59+so7v2LHDkGRMmDDBOvb77V3SMkvLNnXqVJv/D9LS0gxJxqhRo2zmmzRpkiHJ+Oyzz6xjQUFBhiQjOTnZOpaZmWm4ubkZEydOLLIumA+HllBlzJ07Vxs3brR5SNKpU6eUlpam4cOHq3bt2tb5w8LC1KtXL/3vf/8rcZmffvqp8vPzNWbMGJtd0+PHj6+093Ejhg4dKunXPTDXfPDBB7p8+bJ1N78k1ahRw/rna3uyunXrph9++EHZ2dllXt+1bTts2DB5e3tbx3v16qXQ0NAyLWPRokV644031KhRIyUlJWnSpElq2bKlevbsqZ9//tk634oVK9SlSxfVqlVLZ86csT4iIyNVUFCg5OTkMuf+rZycHHl6epbrtdKv55q4urpK+vUKrHPnzunq1atq166dUlNTrfP5+PgoNze31MNEPj4++vbbb3Xo0KFy5ymJh4eHLly4UOq6JWnt2rW6cuVKudfz6KOPlnnegQMH6k9/+pP1efv27dWhQ4dS/01WhGvL//2ey4kTJ0r69VDsb4WGhqpLly7W576+vmrevLl++OGHSs2Jm4Migyqjffv2ioyMtHlI0o8//ihJat68eZHXtGzZUmfOnFFubm6xy7z22qZNm9qM+/r6qlatWhUZv1jp6ek2j19++aXU+cPCwtS6dWu9++671rFly5apbt26ioqKso5t3bpVkZGR1vOFfH199dRTT0mSXUWmpO0jFb+9i+Pk5KTY2FilpKTozJkz+uijjxQdHa3PPvvM5gqrQ4cOaf369fL19bV5XPt7zszMLHPu3/Ly8ir1A74slixZorCwMOt5Lb6+vtbzkq557LHH1KxZM0VHR6tBgwZ68MEHtX79epvlPPvss8rKylKzZs1022236fHHH9c333xzQ9muuXjxYqmFrVu3boqJiVFCQoLq1q2rAQMGaNGiRUXOGSlNtWrVynRI8Zrifm6aNWtW6fe2+fHHH+Xk5KQmTZrYjAcEBMjHx8f6c31Nw4YNiyyjVq1aOn/+fKXmxM1BkQEqUb169Wwe77333nVfM3ToUB08eFC7d+9Wenq6Nm/erL/+9a/WqzaOHDminj176syZM5o1a5bWrVunjRs3asKECZJU6ZfJlqZOnTq6++679b///U/dunXTl19+af1QKSwsVK9evYrsdbv2iImJKdc6W7RooYMHD5b7nKf//Oc/Gj58uBo3bqyFCxdq/fr12rhxo3r06GGzLf38/JSWlqbVq1fr7rvv1ubNmxUdHa1hw4ZZ5+natauOHDmid955R61bt9bbb7+t22+/vdT7A5XFlStXdPDgwSIf3L9lsVi0cuVKbdu2TaNHj9bPP/+sBx98UOHh4bp48WKZ1uPm5lbhJ7aXdCO7goKCSlv275V0dZdhGDecAY7Hyb6o8q6dUHrgwIEi077//nvVrVtX7u7upb720KFDCgkJsY6fPn36pvw29vvDEGU5sXDw4MGKj4/XsmXLFBQUpIKCApvDSmvWrFFeXp5Wr15t85tmcVfZXM9vt8/vFbe97dGuXTtt2bJFp06dUlBQkBo3bqyLFy9a98CUxN47uPbv31/btm3TBx98oMGDB9udc+XKlQoJCbHelPCaqVOnFpnX1dVV/fv3V//+/VVYWKjHHntMCxYs0DPPPGMtGbVr19aIESM0YsQIXbx4UV27dtW0adNKvD9QWTP+8ssvNnvlStKxY0d17NhRM2bM0LJlyzRkyBAtX75co0aNqvC74xb3c3Pw4EGbk+9r1apV7CGc3+81sSdbUFCQCgsLdejQIbVs2dI6npGRoaysLOvPNf4Y2CODKq9evXpq27atlixZYnOH1n379umTTz5Rnz59SnxtZGSkXFxc9Prrr9v89jV79uxKTGy7/t8+rt0DpDQNGzZUly5d9N577+k///mPGjVqpL/85S/W6dd+u/zt+8nOztaiRYvszvfbbfvbwygbN27Ud999d93Xp6enFztffn6+Nm3aZLP7/69//au2bdumDRs2FJk/KytLV69elSTrlTJlvRvvP/7xD9WrV08TJ07UwYMHi0zPzMzU9OnTS3x9cdtzx44d2rZtm818v78ZopOTk/WqmmuHb34/j4eHh5o0aWLX4Z3f27Nnj8aPH69atWqVekXa+fPni+xhuHbF1bX127ttr+fDDz+0OQ9q586d2rFjh6Kjo61jjRs31vfff29zT6E9e/Zo69atNsuyJ9u1f/O//3c8a9YsSb/eYBJ/HOyRgSm89NJLio6OVkREhEaOHGm9/Nrb27vUe4z4+vpq0qRJSkxMVL9+/dSnTx99/fXX+vjjj62Xdl9PcnKy9UTU06dPKzc31/rB2LVrV3Xt2vWG39/vDR06VA8//LBOnjypf/7znzbTevfubd0z8Mgjj+jixYt666235Ofnp1OnTtm9rsTERPXt21edO3fWgw8+qHPnzun1119Xq1atrntI4qefflL79u3Vo0cP9ezZUwEBAcrMzNS7775r/QC+tp0ff/xxrV69Wv369bNe+pqbm6u9e/dq5cqVOnbsmPX+J6GhoXrvvffUrFkz1a5dW61bty7xZoS1atVSUlKS+vTpo7Zt29rc2Tc1NVXvvvuuIiIiSnwP/fr106pVq3TPPfeob9++Onr0qN58802FhobavP9Ro0bp3Llz6tGjhxo0aKAff/xRr7/+utq2bWvdKxAaGqru3bsrPDxctWvX1u7du7Vy5UqNHj26TH8XX3zxhS5fvqyCggKdPXtWW7du1erVq+Xt7a2kpCQFBASU+NolS5Zo3rx5uueee9S4cWNduHBBb731lry8vKwf/PZu2+tp0qSJOnfurEcffVR5eXmaPXu26tSpoyeeeMI6z4MPPqhZs2YpKipKI0eOVGZmpt588021atVKOTk51vnsydamTRsNGzZM//rXv5SVlaVu3bpp586dWrJkiQYOHKg777yzXO8HJuXQa6YA4/8uIy3tslHDMIxPP/3U6NSpk1GjRg3Dy8vL6N+/v/Hdd98Vu6xrl6QahmEUFBQYCQkJRr169YwaNWoY3bt3N/bt22cEBQWV6fLra5d+Fvco6yXC9jp37pzh5uZmSCryHg3DMFavXm2EhYUZ1atXN4KDg40XXnjBeOedd4q897Jcfm0YhvHBBx8YLVu2NNzc3IzQ0FBj1apVRS6PLU5OTo7x2muvGVFRUUaDBg0MFxcXw9PT04iIiDDeeustm0veDcMwLly4YMTHxxtNmjQxXF1djbp16xp/+ctfjJdfftnIz8+3zvfVV18Z4eHhhqura5m388mTJ40JEyYYzZo1M6pXr27UrFnTCA8PN2bMmGFkZ2eXuE0KCwuN559/3ggKCjLc3NyMP//5z8batWuLvP+VK1cavXv3Nvz8/AxXV1ejYcOGxiOPPGKcOnXKOs/06dON9u3bGz4+PkaNGjWMFi1aGDNmzLB5b8W5dvn1tYeLi4vh6+trdO3a1ZgxY4aRmZlZ5DW//1lPTU01Bg8ebDRs2NBwc3Mz/Pz8jH79+hm7d++2eV1J23bYsGGGu7t7sflKuvz6pZdeMl555RUjMDDQcHNzM7p06WLs2bOnyOv/85//GCEhIYarq6vRtm1bY8OGDcX+fJWU7feXXxuGYVy5csVISEgwGjVqZLi4uBiBgYFGfHy8cfnyZZv5goKCir0kvqTLwmE+FsPgbCcAAGBOnCMDAABMiyIDAABMiyIDAABMiyIDAABMiyIDAABMiyIDAABM65a/IV5hYaFOnjwpT0/PCr89NwAAqByGYejChQuqX79+qd8BdssXmZMnTyowMNDRMQAAQDmcOHGi1G9lv+WLzLWvvT9x4oS8vLwcnAYAAJRFTk6OAgMDrZ/jJbnli8y1w0leXl4UGQAATOZ6p4Vwsi8AADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADAtigwAADCtao4OAADArSB48jpHR3CIYzP7OnT97JEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACmRZEBAACm5dAiM23aNFksFptHixYtrNMvX76s2NhY1alTRx4eHoqJiVFGRoYDEwMAgKrE4XtkWrVqpVOnTlkfX375pXXahAkTtGbNGq1YsUJbtmzRyZMnNWjQIAemBQAAVUk1hweoVk0BAQFFxrOzs7Vw4UItW7ZMPXr0kCQtWrRILVu21Pbt29WxY8ebHRUAAFQxDt8jc+jQIdWvX18hISEaMmSIjh8/LklKSUnRlStXFBkZaZ23RYsWatiwobZt2+aouAAAoApx6B6ZDh06aPHixWrevLlOnTqlhIQEdenSRfv27VN6erpcXV3l4+Nj8xp/f3+lp6eXuMy8vDzl5eVZn+fk5FRWfAAA4GAOLTLR0dHWP4eFhalDhw4KCgrS+++/rxo1apRrmYmJiUpISKioiAAAoApz+KGl3/Lx8VGzZs10+PBhBQQEKD8/X1lZWTbzZGRkFHtOzTXx8fHKzs62Pk6cOFHJqQEAgKNUqSJz8eJFHTlyRPXq1VN4eLhcXFy0adMm6/QDBw7o+PHjioiIKHEZbm5u8vLysnkAAIBbk0MPLU2aNEn9+/dXUFCQTp48qalTp8rZ2VmDBw+Wt7e3Ro4cqbi4ONWuXVteXl4aM2aMIiIiuGIJAABIcnCR+emnnzR48GCdPXtWvr6+6ty5s7Zv3y5fX19J0quvvionJyfFxMQoLy9PUVFRmjdvniMjAwCAKsRiGIbh6BCVKScnR97e3srOzuYwEwCg0gRPXufoCA5xbGbfSlluWT+/q9Q5MgAAAPagyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOiyAAAANOqMkVm5syZslgsGj9+vHXs8uXLio2NVZ06deTh4aGYmBhlZGQ4LiQAAKhSqkSR2bVrlxYsWKCwsDCb8QkTJmjNmjVasWKFtmzZopMnT2rQoEEOSgkAAKoahxeZixcvasiQIXrrrbdUq1Yt63h2drYWLlyoWbNmqUePHgoPD9eiRYv01Vdfafv27Q5MDAAAqgqHF5nY2Fj17dtXkZGRNuMpKSm6cuWKzXiLFi3UsGFDbdu27WbHBAAAVVA1R658+fLlSk1N1a5du4pMS09Pl6urq3x8fGzG/f39lZ6eXuIy8/LylJeXZ32ek5NTYXkBAEDV4rA9MidOnNC4ceP03//+V9WrV6+w5SYmJsrb29v6CAwMrLBlAwCAqsVhRSYlJUWZmZm6/fbbVa1aNVWrVk1btmzRnDlzVK1aNfn7+ys/P19ZWVk2r8vIyFBAQECJy42Pj1d2drb1ceLEiUp+JwAAwFEcdmipZ8+e2rt3r83YiBEj1KJFCz355JMKDAyUi4uLNm3apJiYGEnSgQMHdPz4cUVERJS4XDc3N7m5uVVqdgAAUDU4rMh4enqqdevWNmPu7u6qU6eOdXzkyJGKi4tT7dq15eXlpTFjxigiIkIdO3Z0RGQAAFDF2F1kTpw4IYvFogYNGkiSdu7cqWXLlik0NFQPP/xwhYZ79dVX5eTkpJiYGOXl5SkqKkrz5s2r0HUAAADzshiGYdjzgi5duujhhx/W3//+d6Wnp6t58+Zq1aqVDh06pDFjxmjKlCmVlbVccnJy5O3trezsbHl5eTk6DgDgFhU8eZ2jIzjEsZl9K2W5Zf38tvtk33379ql9+/aSpPfff1+tW7fWV199pf/+979avHhxuQMDAADYy+4ic+XKFevJtJ9++qnuvvtuSb/erO7UqVMVmw4AAKAUdheZVq1a6c0339QXX3yhjRs36q677pIknTx5UnXq1KnwgAAAACWxu8i88MILWrBggbp3767BgwerTZs2kqTVq1dbDzkBAADcDHZftdS9e3edOXNGOTk5Nl/y+PDDD6tmzZoVGg4AAKA05bqzr2EYSklJ0YIFC3ThwgVJkqurK0UGAADcVHbvkfnxxx9111136fjx48rLy1OvXr3k6empF154QXl5eXrzzTcrIycAAEARdu+RGTdunNq1a6fz58+rRo0a1vF77rlHmzZtqtBwAAAApbF7j8wXX3yhr776Sq6urjbjwcHB+vnnnyssGAAAwPXYvUemsLBQBQUFRcZ/+ukneXp6VkgoAACAsrC7yPTu3VuzZ8+2PrdYLLp48aKmTp2qPn36VGQ2AACAUtl9aOmVV15RVFSUQkNDdfnyZf3tb3/ToUOHVLduXb377ruVkREAAKBYdheZBg0aaM+ePVq+fLm++eYbXbx4USNHjtSQIUNsTv4FAACobHYXGUmqVq2ahg4dWtFZAAAA7FKmIrN69eoyL/Dal0gCAABUtjIVmYEDB5ZpYRaLpdgrmgAAACpDmYpMYWFhZecAAACwW7m+awkAAKAqKFeR2bRpk/r166fGjRurcePG6tevnz799NOKzgYAAFAqu4vMvHnzdNddd8nT01Pjxo3TuHHj5OXlpT59+mju3LmVkREAAKBYdl9+/fzzz+vVV1/V6NGjrWNjx45Vp06d9Pzzzys2NrZCAwIAAJTE7j0yWVlZuuuuu4qM9+7dW9nZ2RUSCgAAoCzsLjJ33323kpKSiox/9NFH6tevX4WEAgAAKAu7Dy2FhoZqxowZ+vzzzxURESFJ2r59u7Zu3aqJEydqzpw51nnHjh1bcUkBAAB+x2IYhmHPCxo1alS2BVss+uGHH8oVqiLl5OTI29tb2dnZ8vLycnQcAMAtKnjyOkdHcIhjM/tWynLL+vlt9x6Zo0eP3lAwAACAisIN8QAAgGnZvUfGMAytXLlSmzdvVmZmZpGvL1i1alWFhQMAACiN3UVm/PjxWrBgge688075+/vLYrFURi4AAIDrsrvI/Pvf/9aqVavUp0+fysgDAABQZnafI+Pt7a2QkJDKyAIAAGAXu4vMtGnTlJCQoF9++aUy8gAAAJSZ3YeW/vrXv+rdd9+Vn5+fgoOD5eLiYjM9NTW1wsIBAACUxu4iM2zYMKWkpGjo0KGc7AsAABzK7iKzbt06bdiwQZ07d66MPAAAAGVm9zkygYGB3OofAABUCXYXmVdeeUVPPPGEjh07VglxAAAAys7uQ0tDhw7VpUuX1LhxY9WsWbPIyb7nzp2rsHAAAAClsbvIzJ49uxJiAAAA2K9cVy0BAABUBXYXmd+6fPmy8vPzbcY4ERgAANwsdp/sm5ubq9GjR8vPz0/u7u6qVauWzQMAAOBmsbvIPPHEE/rss880f/58ubm56e2331ZCQoLq16+vpUuXVkZGAACAYtl9aGnNmjVaunSpunfvrhEjRqhLly5q0qSJgoKC9N///ldDhgypjJwAAABF2L1H5ty5c9Zvv/by8rJebt25c2clJydXbDoAAIBS2F1kQkJCdPToUUlSixYt9P7770v6dU+Nj49PhYYDAAAojd1FZsSIEdqzZ48kafLkyZo7d66qV6+uCRMm6PHHH6/wgAAAACWx+xyZCRMmWP8cGRmp/fv3KzU1VU2aNFFYWFiFhgMAACjNDd1HRpKCg4MVHBxcAVEAAADsU+ZDS9u2bdPatWttxpYuXapGjRrJz89PDz/8sPLy8io8IAAAQEnKXGSeffZZffvtt9bne/fu1ciRIxUZGanJkydrzZo1SkxMrJSQAAAAxSlzkUlLS1PPnj2tz5cvX64OHTrorbfeUlxcnObMmWO9ggkAAOBmKHOROX/+vPz9/a3Pt2zZoujoaOvzO+64QydOnKjYdAAAAKUoc5Hx9/e33j8mPz9fqamp6tixo3X6hQsX5OLiYtfK58+fr7CwMHl5ecnLy0sRERH6+OOPrdMvX76s2NhY1alTRx4eHoqJiVFGRoZd6wAAALeuMheZPn36aPLkyfriiy8UHx+vmjVrqkuXLtbp33zzjRo3bmzXyhs0aKCZM2cqJSVFu3fvVo8ePTRgwADruTgTJkzQmjVrtGLFCm3ZskUnT57UoEGD7FoHAAC4dZX58uvnnntOgwYNUrdu3eTh4aElS5bI1dXVOv2dd95R79697Vp5//79bZ7PmDFD8+fP1/bt29WgQQMtXLhQy5YtU48ePSRJixYtUsuWLbV9+3abvUEAAOCPqcxFpm7dukpOTlZ2drY8PDzk7OxsM33FihXy8PAod5CCggKtWLFCubm5ioiIUEpKiq5cuaLIyEjrPC1atFDDhg21bds2igwAALD/hnje3t7FjteuXbtcAfbu3auIiAhdvnxZHh4eSkpKUmhoqNLS0uTq6lrk+5v8/f2Vnp5e4vLy8vJs7meTk5NTrlwAAKDqs/u7lipa8+bNlZaWph07dujRRx/VsGHD9N1335V7eYmJifL29rY+AgMDKzAtAACoShxeZFxdXdWkSROFh4crMTFRbdq00WuvvaaAgADl5+crKyvLZv6MjAwFBASUuLz4+HhlZ2dbH1wSDgDArcvhReb3CgsLlZeXp/DwcLm4uGjTpk3WaQcOHNDx48cVERFR4uvd3Nysl3NfewAAgFtTmYrM7bffrvPnz0v69asKLl26VCErj4+PV3Jyso4dO6a9e/cqPj5en3/+uYYMGSJvb2+NHDlScXFx2rx5s1JSUjRixAhFRERwoi8AAJBUxpN99+/fr9zcXNWqVUsJCQn6xz/+oZo1a97wyjMzM/XAAw/o1KlT8vb2VlhYmDZs2KBevXpJkl599VU5OTkpJiZGeXl5ioqK0rx58254vQAA4NZgMQzDuN5MERER8vDwUOfOnZWQkKBJkyaVeKn1lClTKjzkjcjJyZG3t7eys7M5zAQAqDTBk9c5OoJDHJvZt1KWW9bP7zLtkVm8eLGmTp2qtWvXymKx6OOPP1a1akVfarFYqlyRAW4V/CcJAEWVqcg0b95cy5cvlyQ5OTlp06ZN8vPzq9RgAAAA12P3DfEKCwsrIwcAAIDd7C4yknTkyBHNnj1b+/fvlySFhoZq3Lhxdn9pJAAAwI2w+z4yGzZsUGhoqHbu3KmwsDCFhYVpx44datWqlTZu3FgZGQEAAIpl9x6ZyZMna8KECZo5c2aR8SeffNJ66TQAAEBls3uPzP79+zVy5Mgi4w8++OANfUcSAACAvewuMr6+vkpLSysynpaWxpVMAADgprL70NJDDz2khx9+WD/88IP+8pe/SJK2bt2qF154QXFxcRUeEAAAoCR2F5lnnnlGnp6eeuWVVxQfHy9Jql+/vqZNm6axY8dWeEAAAICS2F1kLBaLJkyYoAkTJujChQuSJE9PzwoPBgAAcD3luo/MNRQYAADgSHaf7AsAAFBVUGQAAIBpUWQAAIBp2VVkrly5op49e+rQoUOVlQcAAKDM7CoyLi4u+uabbyorCwAAgF3sPrQ0dOhQLVy4sDKyAAAA2MXuy6+vXr2qd955R59++qnCw8Pl7u5uM33WrFkVFg4AAKA0dheZffv26fbbb5ckHTx40GaaxWKpmFQAAABlYHeR2bx5c2XkAAAAsFu5L78+fPiwNmzYoF9++UWSZBhGhYUCAAAoC7uLzNmzZ9WzZ081a9ZMffr00alTpyRJI0eO1MSJEys8IAAAQEnsLjITJkyQi4uLjh8/rpo1a1rH77vvPq1fv75CwwEAAJTG7nNkPvnkE23YsEENGjSwGW/atKl+/PHHCgsGAABwPXbvkcnNzbXZE3PNuXPn5ObmViGhAAAAysLuItOlSxctXbrU+txisaiwsFAvvvii7rzzzgoNBwAAUBq7Dy29+OKL6tmzp3bv3q38/Hw98cQT+vbbb3Xu3Dlt3bq1MjICAAAUy+49Mq1bt9bBgwfVuXNnDRgwQLm5uRo0aJC+/vprNW7cuDIyAgAAFMvuPTKS5O3trX/+858VnQUAAMAu5Soy58+f18KFC7V//35JUmhoqEaMGKHatWtXaDgAAIDS2H1oKTk5WcHBwZozZ47Onz+v8+fPa86cOWrUqJGSk5MrIyMAAECx7N4jExsbq/vuu0/z58+Xs7OzJKmgoECPPfaYYmNjtXfv3goPCQAAUBy798gcPnxYEydOtJYYSXJ2dlZcXJwOHz5coeEAAABKY3eRuf32263nxvzW/v371aZNmwoJBQAAUBZlOrT0zTffWP88duxYjRs3TocPH1bHjh0lSdu3b9fcuXM1c+bMykkJAABQjDIVmbZt28piscgwDOvYE088UWS+v/3tb7rvvvsqLh0AAEApylRkjh49Wtk5AAAA7FamIhMUFFTZOQAAAOxWrhvinTx5Ul9++aUyMzNVWFhoM23s2LEVEgwAAOB67C4yixcv1iOPPCJXV1fVqVNHFovFOs1isVBkAADATWN3kXnmmWc0ZcoUxcfHy8nJ7qu3AQAAKozdTeTSpUu6//77KTEAAMDh7G4jI0eO1IoVKyojCwAAgF3sPrSUmJiofv36af369brtttvk4uJiM33WrFkVFg4AAKA05SoyGzZsUPPmzSWpyMm+AFCVBE9e5+gIDnFsZl9HRwBuCruLzCuvvKJ33nlHw4cPr4Q4AAAAZWf3OTJubm7q1KlTZWQBAACwi91FZty4cXr99dcrIwsAAIBd7D60tHPnTn322Wdau3atWrVqVeRk31WrVlVYOAAAgNLYXWR8fHw0aNCgysgCAABgF7uLzKJFiyojBwAAgN24PS8AADAtu4tMo0aNFBISUuLDHomJibrjjjvk6ekpPz8/DRw4UAcOHLCZ5/Lly4qNjVWdOnXk4eGhmJgYZWRk2BsbAADcguw+tDR+/Hib51euXNHXX3+t9evX6/HHH7drWVu2bFFsbKzuuOMOXb16VU899ZR69+6t7777Tu7u7pKkCRMmaN26dVqxYoW8vb01evRoDRo0SFu3brU3OgAAuMXYXWTGjRtX7PjcuXO1e/duu5a1fv16m+eLFy+Wn5+fUlJS1LVrV2VnZ2vhwoVatmyZevToIenXc3Ratmyp7du3q2PHjvbGBwAAt5AKO0cmOjpaH3zwwQ0tIzs7W5JUu3ZtSVJKSoquXLmiyMhI6zwtWrRQw4YNtW3bthtaFwAAMD+798iUZOXKldYCUh6FhYUaP368OnXqpNatW0uS0tPT5erqKh8fH5t5/f39lZ6eXuxy8vLylJeXZ32ek5NT7kwAAKBqs7vI/PnPf7b5ckjDMJSenq7Tp09r3rx55Q4SGxurffv26csvvyz3MqRfTyBOSEi4oWUAAABzsLvIDBw40Oa5k5OTfH191b17d7Vo0aJcIUaPHq21a9cqOTlZDRo0sI4HBAQoPz9fWVlZNntlMjIyFBAQUOyy4uPjFRcXZ32ek5OjwMDAcuUCAABVm91FZurUqRW2csMwNGbMGCUlJenzzz9Xo0aNbKaHh4fLxcVFmzZtUkxMjCTpwIEDOn78uCIiIopdppubm9zc3CosIwAAqLoq7ByZ8oiNjdWyZcv00UcfydPT03rei7e3t2rUqCFvb2+NHDlScXFxql27try8vDRmzBhFRERwxRIAACh7kXFycrI5N6Y4FotFV69eLfPK58+fL0nq3r27zfiiRYs0fPhwSdKrr74qJycnxcTEKC8vT1FRUTd0Lg4AALh1lLnIJCUllTht27ZtmjNnjgoLC+1auWEY152nevXqmjt3rubOnWvXsgEAwK2vzEVmwIABRcYOHDigyZMna82aNRoyZIieffbZCg0HAABQmnLdEO/kyZN66KGHdNttt+nq1atKS0vTkiVLFBQUVNH5AAAASmRXkcnOztaTTz6pJk2a6Ntvv9WmTZu0Zs0a6w3sAAAAbqYyH1p68cUX9cILLyggIEDvvvtusYeaAAAAbqYyF5nJkyerRo0aatKkiZYsWaIlS5YUO9+qVasqLBwAAEBpylxkHnjggetefg0AAHAzlbnILF68uBJjAAAA2K9cVy0BAABUBRQZAABgWhQZAABgWhQZAABgWhQZAABgWhQZAABgWhQZAABgWhQZAABgWhQZAABgWhQZAABgWhQZAABgWhQZAABgWmX+0kgUFTx5naMjOMyxmX0dHQEAAPbIAAAA86LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06rm6AAAgKolePI6R0dwmGMz+zo6AuzEHhkAAGBaFBkAAGBaFBkAAGBaFBkAAGBaFBkAAGBaFBkAAGBaFBkAAGBaDi0yycnJ6t+/v+rXry+LxaIPP/zQZrphGJoyZYrq1aunGjVqKDIyUocOHXJMWAAAUOU4tMjk5uaqTZs2mjt3brHTX3zxRc2ZM0dvvvmmduzYIXd3d0VFReny5cs3OSkAAKiKHHpn3+joaEVHRxc7zTAMzZ49W08//bQGDBggSVq6dKn8/f314Ycf6v7777+ZUQEAQBVUZc+ROXr0qNLT0xUZGWkd8/b2VocOHbRt2zYHJgMAAFVFlf2upfT0dEmSv7+/zbi/v791WnHy8vKUl5dnfZ6Tk1M5AQEAgMNV2SJTXomJiUpISHB0DJTij/qFdHwZHQBUvCp7aCkgIECSlJGRYTOekZFhnVac+Ph4ZWdnWx8nTpyo1JwAAMBxqmyRadSokQICArRp0ybrWE5Ojnbs2KGIiIgSX+fm5iYvLy+bBwAAuDU59NDSxYsXdfjwYevzo0ePKi0tTbVr11bDhg01fvx4TZ8+XU2bNlWjRo30zDPPqH79+ho4cKDjQgMAgCrDoUVm9+7duvPOO63P4+LiJEnDhg3T4sWL9cQTTyg3N1cPP/ywsrKy1LlzZ61fv17Vq1d3VGQAAFCFOLTIdO/eXYZhlDjdYrHo2Wef1bPPPnsTUwEAALOosufIAAAAXA9FBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmBZFBgAAmJYpiszcuXMVHBys6tWrq0OHDtq5c6ejIwEAgCqgyheZ9957T3FxcZo6dapSU1PVpk0bRUVFKTMz09HRAACAg1X5IjNr1iw99NBDGjFihEJDQ/Xmm2+qZs2aeueddxwdDQAAOFiVLjL5+flKSUlRZGSkdczJyUmRkZHatm2bA5MBAICqoJqjA5TmzJkzKigokL+/v824v7+/vv/++2Jfk5eXp7y8POvz7OxsSVJOTk6F5yvMu1ThyzSLG9mef9TtdqM/g2y38mG72e+Pus0ktlt5VMbn62+XaxhGqfNV6SJTHomJiUpISCgyHhgY6IA0ty7v2Y5OYD5ss/Jhu5UP26182G72q+xtduHCBXl7e5c4vUoXmbp168rZ2VkZGRk24xkZGQoICCj2NfHx8YqLi7M+Lyws1Llz51SnTh1ZLJZKzXsz5eTkKDAwUCdOnJCXl5ej45gC26x82G7lw3YrH7ab/W7VbWYYhi5cuKD69euXOl+VLjKurq4KDw/Xpk2bNHDgQEm/FpNNmzZp9OjRxb7Gzc1Nbm5uNmM+Pj6VnNRxvLy8bqkf3JuBbVY+bLfyYbuVD9vNfrfiNittT8w1VbrISFJcXJyGDRumdu3aqX379po9e7Zyc3M1YsQIR0cDAAAOVuWLzH333afTp09rypQpSk9PV9u2bbV+/foiJwADAIA/nipfZCRp9OjRJR5K+qNyc3PT1KlTixxGQ8nYZuXDdisftlv5sN3s90ffZhbjetc1AQAAVFFV+oZ4AAAApaHIAAAA06LIAAAA06LIAAAA06LImNDcuXMVHBys6tWrq0OHDtq5c6ejI1VpycnJ6t+/v+rXry+LxaIPP/zQ0ZFMITExUXfccYc8PT3l5+engQMH6sCBA46OVaXNnz9fYWFh1huTRURE6OOPP3Z0LNOZOXOmLBaLxo8f7+goVdq0adNksVhsHi1atHB0rJuOImMy7733nuLi4jR16lSlpqaqTZs2ioqKUmZmpqOjVVm5ublq06aN5s6d6+goprJlyxbFxsZq+/bt2rhxo65cuaLevXsrNzfX0dGqrAYNGmjmzJlKSUnR7t271aNHDw0YMEDffvuto6OZxq5du7RgwQKFhYU5OooptGrVSqdOnbI+vvzyS0dHuum4/NpkOnTooDvuuENvvPGGpF+/siEwMFBjxozR5MmTHZyu6rNYLEpKSrJ+5QXK7vTp0/Lz89OWLVvUtWtXR8cxjdq1a+ull17SyJEjHR2lyrt48aJuv/12zZs3T9OnT1fbtm01e/ZsR8eqsqZNm6YPP/xQaWlpjo7iUOyRMZH8/HylpKQoMjLSOubk5KTIyEht27bNgcnwR5CdnS3p1w9mXF9BQYGWL1+u3NxcRUREODqOKcTGxqpv3742/8ehdIcOHVL9+vUVEhKiIUOG6Pjx446OdNOZ4s6++NWZM2dUUFBQ5OsZ/P399f333zsoFf4ICgsLNX78eHXq1EmtW7d2dJwqbe/evYqIiNDly5fl4eGhpKQkhYaGOjpWlbd8+XKlpqZq165djo5iGh06dNDixYvVvHlznTp1SgkJCerSpYv27dsnT09PR8e7aSgyAK4rNjZW+/bt+0Mef7dX8+bNlZaWpuzsbK1cuVLDhg3Tli1bKDOlOHHihMaNG6eNGzeqevXqjo5jGtHR0dY/h4WFqUOHDgoKCtL777//hzqUSZExkbp168rZ2VkZGRk24xkZGQoICHBQKtzqRo8erbVr1yo5OVkNGjRwdJwqz9XVVU2aNJEkhYeHa9euXXrttde0YMECByerulJSUpSZmanbb7/dOlZQUKDk5GS98cYbysvLk7OzswMTmoOPj4+aNWumw4cPOzrKTcU5Mibi6uqq8PBwbdq0yTpWWFioTZs2cQweFc4wDI0ePVpJSUn67LPP1KhRI0dHMqXCwkLl5eU5OkaV1rNnT+3du1dpaWnWR7t27TRkyBClpaVRYsro4sWLOnLkiOrVq+foKDcVe2RMJi4uTsOGDVO7du3Uvn17zZ49W7m5uRoxYoSjo1VZFy9etPkN5ejRo0pLS1Pt2rXVsGFDByar2mJjY7Vs2TJ99NFH8vT0VHp6uiTJ29tbNWrUcHC6qik+Pl7R0dFq2LChLly4oGXLlunzzz/Xhg0bHB2tSvP09Cxy7pW7u7vq1KnDOVmlmDRpkvr376+goCCdPHlSU6dOlbOzswYPHuzoaDcVRcZk7rvvPp0+fVpTpkxRenq62rZtq/Xr1xc5ARj/Z/fu3brzzjutz+Pi4iRJw4YN0+LFix2UquqbP3++JKl79+4244sWLdLw4cNvfiATyMzM1AMPPKBTp07J29tbYWFh2rBhg3r16uXoaLgF/fTTTxo8eLDOnj0rX19fde7cWdu3b5evr6+jo91U3EcGAACYFufIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAAAA06LIAKjSLBaLPvzwQ0fHAFBFUWQAOFR6errGjBmjkJAQubm5KTAwUP3797f5TjEAKAlfUQDAYY4dO6ZOnTrJx8dHL730km677TZduXJFGzZsUGxsrL7//ntHRwRQxbFHBoDDPPbYY7JYLNq5c6diYmLUrFkztWrVSnFxcdq+fXuxr3nyySfVrFkz1axZUyEhIXrmmWd05coV6/Q9e/bozjvvlKenp7y8vBQeHq7du3dLkn788Uf1799ftWrVkru7u1q1aqX//e9/N+W9Aqgc7JEB4BDnzp3T+vXrNWPGDLm7uxeZ7uPjU+zrPD09tXjxYtWvX1979+7VQw89JE9PTz3xxBOSpCFDhujPf/6z5s+fL2dnZ6WlpcnFxUXSr9/onZ+fr+TkZLm7u+u7776Th4dHpb1HAJWPIgPAIQ4fPizDMNSiRQu7Xvf0009b/xwcHKxJkyZp+fLl1iJz/PhxPf7449blNm3a1Dr/8ePHFRMTo9tuu02SFBIScqNvA4CDcWgJgEMYhlGu17333nvq1KmTAgIC5OHhoaefflrHjx+3To+Li9OoUaMUGRmpmTNn6siRI9ZpY8eO1fTp09WpUydNnTpV33zzzQ2/DwCORZEB4BBNmzaVxWKx64Tebdu2aciQIerTp4/Wrl2rr7/+Wv/85z+Vn59vnWfatGn69ttv1bdvX3322WcKDQ1VUlKSJGnUqFH64Ycf9Pe//1179+5Vu3bt9Prrr1f4ewNw81iM8v5aBAA3KDo6Wnv37tWBAweKnCeTlZUlHx8fWSwWJSUlaeDAgXrllVc0b948m70so0aN0sqVK5WVlVXsOgYPHqzc3FytXr26yLT4+HitW7eOPTOAibFHBoDDzJ07VwUFBWrfvr0++OADHTp0SPv379ecOXMUERFRZP6mTZvq+PHjWr58uY4cOaI5c+ZY97ZI0i+//KLRo0fr888/148//qitW7dq165datmypSRp/Pjx2rBhg44eParU1FRt3rzZOg2AOXGyLwCHCQkJUWpqqmbMmKGJEyfq1KlT8vX1VXh4uObPn19k/rvvvlsTJkzQ6NGjlZeXp759++qZZ57RtGnTJEnOzs46e/asHnjgAWVkZKhu3boaNGiQEhISJEkFBQWKjY3VTz/9JC8vL91111169dVXb+ZbBlDBOLQEAABMi0NLAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtCgyAADAtP4/ImTCn8vlYmsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74 files belonging to 6 classes.\n",
      "Fold 1 - Test Set Class Distribution:\n",
      "Class 0: 9 samples\n",
      "Class 1: 7 samples\n",
      "Class 2: 16 samples\n",
      "Class 3: 9 samples\n",
      "Class 4: 6 samples\n",
      "Class 5: 27 samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_class_distribution(fold_dirs: list):\n",
    "    \"\"\"\n",
    "    Prints and plots the class distribution for training, validation, and test sets across folds.\n",
    "    \n",
    "    Args:\n",
    "        fold_dirs (list): List of directory paths for each fold.\n",
    "    \"\"\"\n",
    "    for fold, fold_dir in enumerate(fold_dirs, 1):\n",
    "        for split in ['Train', 'Valid', 'Test']:\n",
    "            split_dir = os.path.join(fold_dir, split)\n",
    "            dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                split_dir,\n",
    "                labels='inferred',\n",
    "                label_mode='int',\n",
    "                batch_size=32,\n",
    "                image_size=(224, 224),\n",
    "                shuffle=False\n",
    "            )\n",
    "            labels = np.concatenate([y.numpy() for _, y in dataset], axis=0)\n",
    "            unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
    "            \n",
    "            print(f\"Fold {fold} - {split} Set Class Distribution:\")\n",
    "            for cls, count in zip(unique_classes, class_counts):\n",
    "                print(f\"Class {cls}: {count} samples\")\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.bar(unique_classes, class_counts)\n",
    "            plt.xlabel(\"Class\")\n",
    "            plt.ylabel(\"Number of Samples\")\n",
    "            plt.title(f\"Fold {fold} - {split} Set Class Distribution\")\n",
    "            plt.show()\n",
    "\n",
    "print_class_distribution([\"../data/archive/Original Images/Original Images/FOLDS/fold1\",\n",
    "                        #   \"../data/archive/Original Images/Original Images/FOLDS/fold2\",\n",
    "                        #   \"../data/archive/Original Images/Original Images/FOLDS/fold3\",\n",
    "                        #   \"../data/archive/Original Images/Original Images/FOLDS/fold4\",\n",
    "                        #   \"../data/archive/Original Images/Original Images/FOLDS/fold5\"\n",
    "                        ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
