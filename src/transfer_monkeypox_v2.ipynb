{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3321827643110032387\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23354343424\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4307283450541688654\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23006937088\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9839967239256393642\n",
      "physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 2144165316\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738803513.187858  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.188265  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.188542  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.188668  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.188786  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.188908  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.189080  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.189200  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1738803513.189321  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-05 20:58:33.189439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 22272 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "I0000 00:00:1738803513.189475  192603 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-05 20:58:33.189590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:1 with 21941 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with MonkeyPox Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"../data/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "batch_size = 32         # size of the batch that will be fed to model\n",
    "\n",
    "# folds = the amount of folds that will be created for cross-validation\n",
    "# fine_tune_epochs = number of epochs after which we start fine-tuning\n",
    "# fine_tune_at = layer number where we start unfreezing layers\n",
    "\n",
    "# configurations that will be used in training\n",
    "configs = [\n",
    "    {\"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    # {\"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": True, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    # {\"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 148},\n",
    "    # {\"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": True, \"fine_tune_epochs\": 25, \"fine_tune_at\": 148},\n",
    "]\n",
    "\n",
    "# Define the base path for saving models\n",
    "save_dir = \"../saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_dataset(directory: str, batch_size: int, image_size: tuple[int, int],\n",
    "                       label_mode, shuffle: bool = True) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Loads an image dataset from the specified directory using Keras' image_dataset_from_directory.\n",
    "\n",
    "    The directory should contain one subdirectory per class.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the image data directory.\n",
    "        batch_size (int): Number of images per batch.\n",
    "        image_size (Tuple[int, int]): Target size (height, width) for the images.\n",
    "        label_mode (str): Type of label encoding ('binary', 'categorical', or 'int'). Defaults to 'binary'.\n",
    "        shuffle (bool): Whether to shuffle the data. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A dataset yielding batches of (image, label) pairs with images normalized.\n",
    "    \"\"\"\n",
    "    # Load images and labels from the directory, inferring subdirectory names as class names.\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels='inferred',\n",
    "        label_mode=\"int\",\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    # print(dataset.class_names)\n",
    "    class_names = np.array(dataset.class_names)     # get the class names for the data\n",
    "    # num_classes = len(class_names)                  # get the number of classes in the dataset\n",
    "    # Normalize images to the [0, 1] range using a rescaling layer.\n",
    "    normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "    dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "    # Cache and prefetch data to optimize performance.\n",
    "    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset, class_names\n",
    "\n",
    "def callbacks_setup(checkpoint_filepath):\n",
    "    # EarlyStopping callback configuration\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',        # monitor validation loss\n",
    "        patience=5,                # number of epochs with no improvement to stop training\n",
    "        mode = 'min',              # want to minimize what it being monitored \n",
    "        restore_best_weights=False # don't restore in EarlyStopping, handled by ModelCheckpoint\n",
    "    )\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,   # path to save weights\n",
    "        save_weights_only=True,         # only save weights instead of full model\n",
    "        monitor='val_loss',             # monitor validation loss\n",
    "        mode='min',                     # want to maximize what is being monitored\n",
    "        save_best_only=True             # save the best weights\n",
    "    )            \n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',      # monitor validation loss \n",
    "        factor=0.5,              # factor by which the learning rate will be reduced \n",
    "        patience=3,              # number of epochs with no improvement to stop training \n",
    "        mode='min',              # want to minimize what it being monitored \n",
    "        min_lr=1e-6              # lower bound on the learning rate \n",
    "    )            \n",
    "\n",
    "    return early_stopping, model_checkpoint, reduce_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def save_confusion_matrix(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                          class_names: List[str], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots and saves the confusion matrix for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels.\n",
    "        class_names (List[str]): List of class names corresponding to class indices.\n",
    "        save_path (str): Path to save the confusion matrix plot.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix using sklearn\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def save_loss_curve(history: Dict[str, Any], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots and saves the training and validation loss curves.\n",
    "\n",
    "    Args:\n",
    "        history (Dict[str, Any]): Dictionary containing training history (loss values).\n",
    "        save_path (str): Path to save the loss curve plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def save_evaluation_metrics(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                            predicted_probs: np.ndarray, save_path: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes evaluation metrics for multi-class classification and saves a bar chart.\n",
    "    The metrics include accuracy, precision, recall, F1 score, and ROC AUC.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels.\n",
    "        predicted_probs (np.ndarray): Array of predicted probabilities (shape: [n_samples, n_classes]).\n",
    "        save_path (str): Path to save the evaluation metrics bar chart.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary containing computed metrics.\n",
    "    \"\"\"\n",
    "    # Calculate accuracy by comparing predicted and true labels\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    # Compute macro-averaged metrics for multi-class classification\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    # For ROC AUC, first binarize the true labels to one-hot encoding\n",
    "    n_classes = predicted_probs.shape[1]\n",
    "    true_labels_binarized = label_binarize(true_labels, classes=list(range(n_classes)))\n",
    "    # Compute ROC AUC with a one-vs-rest approach and macro average\n",
    "    roc_auc = roc_auc_score(true_labels_binarized, predicted_probs, multi_class='ovr', average='macro')\n",
    "\n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Sensitivity (Recall)\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "    # Plot metrics as a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(metrics.keys(), metrics.values(), \n",
    "                   color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen', 'mediumpurple'])\n",
    "    # Annotate each bar with its value\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.4f}', ha='center', va='bottom')\n",
    "    plt.title(\"Model Evaluation Metrics\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def save_classification_report(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                               class_names: List[str], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the classification report to a text file for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels.\n",
    "        class_names (List[str]): List of class names.\n",
    "        save_path (str): Path to save the classification report.\n",
    "    \"\"\"\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "def calculate_metrics(true_labels: np.ndarray, predictions: np.ndarray) -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculates evaluation metrics for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels.\n",
    "        predictions (np.ndarray): Array of predicted probabilities (shape: [n_samples, n_classes]).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, float, float]: A tuple containing accuracy, precision, recall, \n",
    "            F1 score, and ROC AUC score.\n",
    "    \"\"\"\n",
    "    # Convert predicted probabilities to predicted class labels using argmax\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    # Binarize true labels for ROC AUC calculation\n",
    "    n_classes = predictions.shape[1]\n",
    "    true_labels_binarized = label_binarize(true_labels, classes=list(range(n_classes)))\n",
    "    auc = roc_auc_score(true_labels_binarized, predictions, multi_class='ovr', average='macro')\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "def save_best_model_visuals(history: tf.keras.callbacks.History, model: tf.keras.Model, \n",
    "                              val_ds: tf.data.Dataset, class_names: List[str], \n",
    "                              weights_path: str, fold: int) -> None:\n",
    "    \"\"\"\n",
    "    Generates and saves evaluation visuals including confusion matrix, loss curve, evaluation \n",
    "    metrics bar chart, and classification report for the best performing model in a given fold.\n",
    "\n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): Training history object.\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        val_ds (tf.data.Dataset): Validation dataset.\n",
    "        class_names (List[str]): List of class names.\n",
    "        weights_path (str): Directory path to save visuals.\n",
    "        fold (int): Current fold number.\n",
    "    \"\"\"\n",
    "    # Generate predictions (predicted probabilities) for the validation set\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    # Convert predicted probabilities to class labels using argmax\n",
    "    val_predicted_ids = np.argmax(val_predictions, axis=1)\n",
    "    # Concatenate true labels from the validation dataset\n",
    "    true_labels = np.concatenate([y for _, y in val_ds], axis=0)\n",
    "\n",
    "    # Save the confusion matrix\n",
    "    confusion_matrix_path = os.path.join(weights_path, f\"confusion_matrix_fold{fold}.png\")\n",
    "    save_confusion_matrix(true_labels, val_predicted_ids, class_names, confusion_matrix_path)\n",
    "\n",
    "    # Save the loss curve using the training history\n",
    "    loss_curve_path = os.path.join(weights_path, f\"loss_curve_fold{fold}.png\")\n",
    "    save_loss_curve(history.history, loss_curve_path)\n",
    "\n",
    "    # Save evaluation metrics bar chart (passing predicted probabilities for ROC AUC calculation)\n",
    "    metrics_bar_chart_path = os.path.join(weights_path, f\"evaluation_metrics_fold{fold}.png\")\n",
    "    save_evaluation_metrics(true_labels, val_predicted_ids, val_predictions, metrics_bar_chart_path)\n",
    "\n",
    "    # Save the classification report as a text file\n",
    "    classification_report_path = os.path.join(weights_path, f\"classification_report_fold{fold}.txt\")\n",
    "    save_classification_report(true_labels, val_predicted_ids, class_names, classification_report_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_confusion_matrix_binary(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                          save_path: str, mpox_index: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Converts multi-class labels to binary (Mpox vs Other) and plots/saves the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels (multi-class integers).\n",
    "        save_path (str): Path to save the confusion matrix plot.\n",
    "        mpox_index (int): The index corresponding to Mpox. All other labels are considered \"Other\".\n",
    "    \"\"\"\n",
    "    # Convert multi-class labels to binary: 1 if label equals mpox_index, else 0.\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels == mpox_index).astype(int)\n",
    "    cm = confusion_matrix(binary_true, binary_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Other\", \"Mpox\"])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix (Mpox vs Other)\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def save_loss_curve_binary(history: Dict[str, Any], save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Plots and saves the training and validation loss curves.\n",
    "\n",
    "    Args:\n",
    "        history (Dict[str, Any]): Dictionary containing training history (loss values).\n",
    "        save_path (str): Path to save the loss curve plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def save_evaluation_metrics_binary(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                            predicted_probs: np.ndarray, save_path: str, \n",
    "                            mpox_index: int = 0) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes and plots evaluation metrics for binary classification (Mpox vs Other).\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels (multi-class integers).\n",
    "        predicted_probs (np.ndarray): Array of predicted probabilities for each class \n",
    "                                      (shape: [n_samples, n_classes]).\n",
    "        save_path (str): Path to save the evaluation metrics bar chart.\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary containing computed metrics.\n",
    "    \"\"\"\n",
    "    # Convert to binary labels\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels == mpox_index).astype(int)\n",
    "    # Use the probability for the Mpox class as the positive probability.\n",
    "    mpox_probs = predicted_probs[:, mpox_index]\n",
    "\n",
    "    accuracy = np.mean(binary_true == binary_pred)\n",
    "    precision = precision_score(binary_true, binary_pred)\n",
    "    recall = recall_score(binary_true, binary_pred)\n",
    "    f1 = f1_score(binary_true, binary_pred)\n",
    "    roc_auc = roc_auc_score(binary_true, mpox_probs)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Sensitivity (Recall)\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "    # Plot metrics as a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(metrics.keys(), metrics.values(), \n",
    "                   color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen', 'mediumpurple'])\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.4f}', ha='center', va='bottom')\n",
    "    plt.title(\"Evaluation Metrics (Mpox vs Other)\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def save_classification_report_binary(true_labels: np.ndarray, predicted_labels: np.ndarray, \n",
    "                               save_path: str, mpox_index: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Saves the classification report for binary classification (Mpox vs Other).\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predicted_labels (np.ndarray): Array of predicted class labels (multi-class integers).\n",
    "        save_path (str): Path to save the classification report.\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "    \"\"\"\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels == mpox_index).astype(int)\n",
    "    report = classification_report(binary_true, binary_pred, target_names=[\"Other\", \"Mpox\"], digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "def calculate_metrics_binary(true_labels: np.ndarray, predictions: np.ndarray, \n",
    "                      mpox_index: int = 0) -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculates binary evaluation metrics for Mpox vs Other.\n",
    "    The multi-class predictions are converted into binary predictions where the positive class \n",
    "    is Mpox (identified by mpox_index) and all other classes are negative.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.ndarray): Array of true class labels (multi-class integers).\n",
    "        predictions (np.ndarray): Array of predicted probabilities (shape: [n_samples, n_classes]).\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, float, float]:\n",
    "            Accuracy, Precision, Recall, F1 Score, and ROC AUC.\n",
    "    \"\"\"\n",
    "    # Convert multi-class predictions to class indices\n",
    "    predicted_labels_multi = np.argmax(predictions, axis=1)\n",
    "    # Convert to binary: 1 if Mpox, 0 otherwise.\n",
    "    binary_true = (true_labels == mpox_index).astype(int)\n",
    "    binary_pred = (predicted_labels_multi == mpox_index).astype(int)\n",
    "    mpox_probs = predictions[:, mpox_index]\n",
    "\n",
    "    accuracy = np.mean(binary_true == binary_pred)\n",
    "    precision = precision_score(binary_true, binary_pred)\n",
    "    recall = recall_score(binary_true, binary_pred)\n",
    "    f1 = f1_score(binary_true, binary_pred)\n",
    "    auc = roc_auc_score(binary_true, mpox_probs)\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "def save_best_model_visuals_binary(history: tf.keras.callbacks.History, model: tf.keras.Model, \n",
    "                              val_ds: tf.data.Dataset, weights_path: str, \n",
    "                              fold: int, mpox_index: int = 1) -> None:\n",
    "    \"\"\"\n",
    "    Generates and saves evaluation visuals (confusion matrix, loss curve, metrics bar chart,\n",
    "    and classification report) for binary classification (Mpox vs Other) for the best performing model.\n",
    "\n",
    "    Args:\n",
    "        history (tf.keras.callbacks.History): Training history object.\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        val_ds (tf.data.Dataset): Validation dataset.\n",
    "        weights_path (str): Directory path to save visuals.\n",
    "        fold (int): Current fold number.\n",
    "        mpox_index (int): The index corresponding to Mpox.\n",
    "    \"\"\"\n",
    "    # Generate predictions for the validation set\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    predicted_ids_multi = np.argmax(val_predictions, axis=1)\n",
    "    true_labels = np.concatenate([y for _, y in val_ds], axis=0)\n",
    "    \n",
    "    # Save the confusion matrix\n",
    "    confusion_matrix_path = os.path.join(weights_path, f\"confusion_matrix_binary_fold{fold}.png\")\n",
    "    save_confusion_matrix_binary(true_labels, predicted_ids_multi, confusion_matrix_path, mpox_index)\n",
    "    \n",
    "    # Save the loss curve\n",
    "    loss_curve_path = os.path.join(weights_path, f\"loss_curve_binary_fold{fold}.png\")\n",
    "    save_loss_curve_binary(history.history, loss_curve_path)\n",
    "    \n",
    "    # Save evaluation metrics bar chart\n",
    "    metrics_bar_chart_path = os.path.join(weights_path, f\"evaluation_metrics_binary_fold{fold}.png\")\n",
    "    save_evaluation_metrics_binary(true_labels, predicted_ids_multi, val_predictions, metrics_bar_chart_path, mpox_index)\n",
    "    \n",
    "    # Save the classification report\n",
    "    classification_report_path = os.path.join(weights_path, f\"classification_report_binary_fold{fold}.txt\")\n",
    "    save_classification_report_binary(true_labels, predicted_ids_multi, classification_report_path, mpox_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation and fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and compile the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "def create_model(num_classes: int, config: dict, fine_tune: bool = False) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Creates a MobileNetV2-based model for multi-class classification.\n",
    "\n",
    "    The model uses a pre-trained MobileNetV2 as a feature extractor (with ImageNet weights) \n",
    "    and adds a global average pooling layer followed by a dense layer that outputs logits \n",
    "    for each class. The model is compiled using SparseCategoricalCrossentropy (from_logits=True)\n",
    "    which is appropriate for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of classes for classification.\n",
    "        config (dict): Configuration dictionary containing:\n",
    "            - \"image_size\": Tuple[int, int] representing the target (height, width) for images.\n",
    "            - \"optimizer\": Optimizer name (\"adam\" or \"sgd\").\n",
    "            - \"learning_rate\": Learning rate for the optimizer.\n",
    "        fine_tune (bool, optional): If True, the base model will be set as trainable for fine-tuning.\n",
    "                                    Otherwise, the base model is frozen. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: The compiled Keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate the MobileNetV2 base model with pre-trained ImageNet weights.\n",
    "    # Exclude the top layer to allow for transfer learning.\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(config[\"image_size\"], config[\"image_size\"], 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Set the trainability of the base model based on the fine_tune flag.\n",
    "    base_model.trainable = False\n",
    "\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1)\n",
    "    ])\n",
    "\n",
    "    # Build the model using the Keras Sequential API.\n",
    "    # For multi-class classification, the final Dense layer outputs 'num_classes' logits.\n",
    "    model = Sequential([\n",
    "        data_augmentation,\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        # Dropout layer to randomly drop 50% of the neurons during training\n",
    "        # layers.Dropout(0.25),\n",
    "        # Dense layer with L2 regularization\n",
    "        # layers.Dense(num_classes, kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
    "        layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    # Select the optimizer based on configuration.\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
    "\n",
    "    # Compile the model with SparseCategoricalCrossentropy loss which expects logits.\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# fine tune model by unfreezing the layers after the first fine_tune_at layers\n",
    "def fine_tune_model(base_model, fine_tune_at):\n",
    "    # Unfreeze the layers starting from fine_tune_at index\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def train_fold(fold: int, config: dict, best_f1_score: float, best_f1_dir: str, model_subdir: str) -> float:\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model for one fold of the dataset using images from the specified folders.\n",
    "    \n",
    "    Training images are loaded from 'Augmented Images/Fold{fold}/train',\n",
    "    validation images from 'Original Images/Fold{fold}/val', and test images from 'Original Images/Fold{fold}/test'.\n",
    "    \n",
    "    Args:\n",
    "        fold (int): The fold number to process.\n",
    "        config (dict): Configuration parameters including hyperparameters and paths.\n",
    "        best_f1_score (float): The best F1 score recorded so far.\n",
    "        best_f1_dir (str): Directory where the best model is saved.\n",
    "        model_subdir (str): Subdirectory for saving additional visuals and metrics.\n",
    "    \n",
    "    Returns:\n",
    "        float: The updated best F1 score after processing the current fold.\n",
    "    \"\"\"\n",
    "    # Define directory paths for the current fold\n",
    "    # augmented_train_dir = os.path.join(\"../data\", \"archive\", \"Augmented Images\", \"Augmented Images\", \"FOLDS_AUG\", f\"fold{fold}_AUG\", \"Train\")\n",
    "    augmented_train_dir = os.path.join(\"../data\", \"archive\", \"Original Images\", \"Original Images\", \"FOLDS\", f\"fold{fold}\", \"Train\")\n",
    "    original_val_dir = os.path.join(\"../data\", \"archive\", \"Original Images\", \"Original Images\", \"FOLDS\", f\"fold{fold}\", \"Valid\")\n",
    "    original_test_dir = os.path.join(\"../data\", \"archive\", \"Original Images\", \"Original Images\", \"FOLDS\", f\"fold{fold}\", \"Test\")\n",
    "\n",
    "    print(f\"\\nProcessing Fold {fold}...\")\n",
    "\n",
    "    # Load the training, validation, and test datasets\n",
    "    train_ds, class_names = load_image_dataset(augmented_train_dir, config['batch_size'],\n",
    "                                  config['image_size'], label_mode=config.get('label_mode', 'int'), shuffle=True)\n",
    "    val_ds, _ = load_image_dataset(original_val_dir, config['batch_size'],\n",
    "                                config['image_size'], label_mode=config.get('label_mode', 'int'), shuffle=False)\n",
    "    test_ds, _ = load_image_dataset(original_test_dir, config['batch_size'],\n",
    "                                 config['image_size'], label_mode=config.get('label_mode', 'int'), shuffle=False)\n",
    "    \n",
    "    # --- Compute class weights using sklearn ---\n",
    "    # Extract the labels from the training dataset.\n",
    "    # Note: train_ds is a tf.data.Dataset yielding (images, labels)\n",
    "    train_labels = np.concatenate([y.numpy() for _, y in train_ds], axis=0)\n",
    "    # Compute the class weights\n",
    "    classes = np.unique(train_labels)\n",
    "    computed_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n",
    "    # Create a dictionary mapping each class index to its weight.\n",
    "    class_weight_dict = {int(cls): weight for cls, weight in zip(classes, computed_weights)}\n",
    "    print(\"Class Weight Dictionary:\", class_weight_dict)\n",
    "\n",
    "    # Set up a filepath for model checkpointing for this fold\n",
    "    checkpoint_filepath = os.path.join(config['checkpoint_folder'], f'checkpoint_fold{fold}.weights.h5')\n",
    "\n",
    "    # -------------------- Step 1: Train with Frozen Base Layers --------------------\n",
    "    print(f\"Training with frozen base layers for {config['epochs']} epochs on Fold {fold}...\")\n",
    "\n",
    "    # Create the model for this fold (replace create_model with your actual model creation function)\n",
    "    model = create_model(len(class_names), config, fine_tune=False)\n",
    "    \n",
    "    # Setup callbacks (replace callbacks_setup with your callback setup function)\n",
    "    early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "    \n",
    "    # Train the model using the training and validation datasets, including class weights\n",
    "    history_frozen = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=config['epochs'],\n",
    "        callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Load the best weights saved during training\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # -------------------- Step 2: Fine-Tuning (Optional) --------------------\n",
    "    if config.get(\"fine_tune\", False):\n",
    "        print(f\"Unfreezing layers starting from layer {config['fine_tune_at']} for fine-tuning on Fold {fold}...\")\n",
    "        fine_tune_model(model.layers[0], config['fine_tune_at'])\n",
    "        # Set a lower learning rate for fine-tuning\n",
    "        fine_tune_lr = config['learning_rate'] * 0.01\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(f\"Fine-tuning for {config['fine_tune_epochs']} epochs on Fold {fold}...\")\n",
    "        early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "        history_fine_tune = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=config['fine_tune_epochs'],\n",
    "            callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "            class_weight=class_weight_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        # Load the best weights after fine-tuning\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # -------------------- Evaluation on Validation Dataset --------------------\n",
    "    # Get predictions and compute metrics on the validation dataset\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    avg_val_loss = model.evaluate(val_ds, verbose=0)[0]\n",
    "    avg_val_accuracy, avg_val_precision, avg_val_recall, avg_val_f1, avg_val_auc = calculate_metrics(\n",
    "        np.concatenate([y for _, y in val_ds]),  # combine labels from val_ds\n",
    "        val_predictions\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFold {fold} Validation Metrics:\")\n",
    "    print(f\"  Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {avg_val_accuracy:.4f}\")\n",
    "    print(f\"  Precision: {avg_val_precision:.4f}\")\n",
    "    print(f\"  Recall: {avg_val_recall:.4f}\")\n",
    "    print(f\"  F1 Score: {avg_val_f1:.4f}\")\n",
    "    print(f\"  ROC AUC Score: {avg_val_auc:.4f}\")\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=1)\n",
    "    print(f\"Fold {fold} Test Metrics: Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # -------------------- Optional: Evaluation on Test Dataset --------------------\n",
    "    # If this fold produces the best F1 score so far, save the model and visuals\n",
    "    if avg_val_f1 > best_f1_score:\n",
    "        best_f1_score = avg_val_f1\n",
    "        # Save the best model (using model.export for TensorFlow SavedModel format)\n",
    "        model.export(best_f1_dir)\n",
    "        print(f\"Best model updated at Fold {fold} with F1 Score: {best_f1_score:.4f}\")\n",
    "        if config.get('save_metrics', False):\n",
    "            save_best_model_visuals(history_frozen, model, test_ds, class_names, model_subdir, fold)\n",
    "            save_best_model_visuals_binary(history_frozen, model, test_ds, model_subdir, fold, 5)\n",
    "    return best_f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_training_loop(config: dict, best_f1_dir: str, model_subdir: str) -> None:\n",
    "    \"\"\"\n",
    "    Main loop that iterates over each fold, training and evaluating the model.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration parameters including hyperparameters and training settings.\n",
    "        num_classes (int): Number of classes in the classification task.\n",
    "        best_f1_dir (str): Directory to save the best performing model.\n",
    "        model_subdir (str): Subdirectory for saving additional metrics and visuals.\n",
    "        class_names (List[str]): List of class names.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    best_val_f1score = 0.0\n",
    "    total_folds = config.get('folds', 5)  # default to 5 folds if not specified\n",
    "\n",
    "    # Iterate through each fold and update the best F1 score if improved.\n",
    "    for fold in range(1, total_folds + 1):\n",
    "        best_val_f1score = train_fold(fold, config, best_val_f1score,\n",
    "                                      best_f1_dir, model_subdir)\n",
    "    print(f\"\\nTraining complete. Best Validation F1 Score: {best_val_f1score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Fold 1...\n",
      "Found 537 files belonging to 6 classes.\n",
      "Found 144 files belonging to 6 classes.\n",
      "Found 74 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.79, 1: 1.8265306122448979, 2: 0.771551724137931, 3: 1.0783132530120483, 4: 2.418918918918919, 5: 0.4430693069306931}\n",
      "Training with frozen base layers for 50 epochs on Fold 1...\n",
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2341 - loss: 1.8957 - val_accuracy: 0.4167 - val_loss: 1.5964 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5290 - loss: 1.0667 - val_accuracy: 0.5417 - val_loss: 1.2797 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6628 - loss: 0.7840 - val_accuracy: 0.5972 - val_loss: 1.1266 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7308 - loss: 0.6411 - val_accuracy: 0.6458 - val_loss: 1.0176 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7858 - loss: 0.5488 - val_accuracy: 0.6667 - val_loss: 0.9920 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8021 - loss: 0.5011 - val_accuracy: 0.6806 - val_loss: 0.9798 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8155 - loss: 0.4522 - val_accuracy: 0.6875 - val_loss: 0.9443 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8231 - loss: 0.4294 - val_accuracy: 0.7014 - val_loss: 0.9120 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8326 - loss: 0.4028 - val_accuracy: 0.7014 - val_loss: 0.9077 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8606 - loss: 0.3942 - val_accuracy: 0.7153 - val_loss: 0.9047 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8604 - loss: 0.3679 - val_accuracy: 0.7153 - val_loss: 0.8733 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8714 - loss: 0.3246 - val_accuracy: 0.7222 - val_loss: 0.8702 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8728 - loss: 0.3131 - val_accuracy: 0.7014 - val_loss: 0.8778 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8954 - loss: 0.2684 - val_accuracy: 0.7153 - val_loss: 0.8712 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9021 - loss: 0.2855 - val_accuracy: 0.7153 - val_loss: 0.8752 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8975 - loss: 0.2522 - val_accuracy: 0.7014 - val_loss: 0.8652 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8895 - loss: 0.2564 - val_accuracy: 0.6875 - val_loss: 0.8811 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8984 - loss: 0.2571 - val_accuracy: 0.6875 - val_loss: 0.8496 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8984 - loss: 0.2380 - val_accuracy: 0.7014 - val_loss: 0.8465 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9074 - loss: 0.2403 - val_accuracy: 0.6944 - val_loss: 0.8531 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8983 - loss: 0.2352 - val_accuracy: 0.7014 - val_loss: 0.8438 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9124 - loss: 0.2319 - val_accuracy: 0.7014 - val_loss: 0.8477 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9339 - loss: 0.2055 - val_accuracy: 0.6944 - val_loss: 0.8550 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9108 - loss: 0.2216 - val_accuracy: 0.7014 - val_loss: 0.8529 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9019 - loss: 0.2146 - val_accuracy: 0.6875 - val_loss: 0.8419 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9427 - loss: 0.1995 - val_accuracy: 0.7014 - val_loss: 0.8522 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9317 - loss: 0.1979 - val_accuracy: 0.6944 - val_loss: 0.8544 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9319 - loss: 0.1951 - val_accuracy: 0.6806 - val_loss: 0.8656 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9177 - loss: 0.1988 - val_accuracy: 0.6875 - val_loss: 0.8632 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9147 - loss: 0.1961 - val_accuracy: 0.6944 - val_loss: 0.8611 - learning_rate: 1.2500e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step\n",
      "\n",
      "Fold 1 Validation Metrics:\n",
      "  Loss: 0.8419\n",
      "  Accuracy: 0.6875\n",
      "  Precision: 0.6969\n",
      "  Recall: 0.6596\n",
      "  F1 Score: 0.6694\n",
      "  ROC AUC Score: 0.8929\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.7579 \n",
      "Fold 1 Test Metrics: Loss: 0.6955, Accuracy: 0.7568\n",
      "INFO:tensorflow:Assets written to: ../saved_models/model1/best_f1score_fold/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/model1/best_f1score_fold/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_models/model1/best_f1score_fold'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_11575')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  124714509443216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509446672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509447248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399752464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399748816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399752272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399753232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399748432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399752080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399754384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399754576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399754192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399753424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399754960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399756304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399756496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399756112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399755344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399756880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890000144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890000912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399753040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399757264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890000720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890002256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890002448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890002064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890001296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890002832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890004176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890004368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890003984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890003216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890004752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890006096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890006288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890005904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890005136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890006672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890008016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890008208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890007824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890007056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890008592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890009936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890010128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890009744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890008976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890010512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890011856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890012048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890011664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890010896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890012432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890013584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890013776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890013392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890012624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890014160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890015504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890015696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890015312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890014544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715890013008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177015632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177014864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177015824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177015056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177016592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177017936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177018128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177017744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177016976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177018512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177019856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177020048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177019664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177018896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177020432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177021776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177021968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177021584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177020816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177022352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177023696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177023888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177023504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177022736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177024272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177025616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177025808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177025424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177024656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177026192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177027536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177027728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177027344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177026576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177028112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177029456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177029648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177029264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177028496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177030032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177030416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176589456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177016208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716177028880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176589648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176590992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176591184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176590800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176590032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176591568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176592912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176593104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176592720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176591952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176593488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176594832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176595024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176594640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176593872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176595408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176596752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176596944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176596560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176595792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176597328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176598672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176598864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176598480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176597712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176599248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176600592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176600784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176600400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176599632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176601168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176602512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176602704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176602320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176601552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176603088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176604432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176604624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176604240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176603472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176601936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176344272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176343120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176344080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176344464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176344848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176346192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176346384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176346000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176345232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176346768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176348112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176348304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176347920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176347152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176348688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176350032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176350224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176349840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176349072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176350608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176351952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176352144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176351760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176350992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176352528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176353872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176354064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176353680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176352912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176354448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176355792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176355984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176355600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176354832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176356368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176357712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176357904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176357520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176356752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176358288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176358672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509320848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176343696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124716176357136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509321040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509322384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509322576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509322192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509321424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509322960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509324304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509324496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509324112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509323344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509324880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509326224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509326416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509326032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509325264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509326800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509328144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509328336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509327952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509327184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509328720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509330064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509330256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509329872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509329104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509330640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509331984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509332176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509331792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509331024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509332560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509333904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509334096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509333712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509332944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509334480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509335824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509336016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509335632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509334864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509333328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509435728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509434960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509435920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509435152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509436688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509438032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509438224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509437840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509437072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509438608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509439952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509440144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509439760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509438992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509440528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509441872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509442064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509441680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509440912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509442448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509443792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509443984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509443600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509442832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509444368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509445712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509445904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509445520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509444752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509449936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714509451088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Best model updated at Fold 1 with F1 Score: 0.6694\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\n",
      "Processing Fold 2...\n",
      "Found 509 files belonging to 6 classes.\n",
      "Found 164 files belonging to 6 classes.\n",
      "Found 82 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.6633986928104576, 1: 1.8049645390070923, 2: 0.7782874617737003, 3: 1.0604166666666666, 4: 2.120833333333333, 5: 0.4661172161172161}\n",
      "Training with frozen base layers for 50 epochs on Fold 2...\n",
      "Epoch 1/50\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2130 - loss: 1.9404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1738803528.822323  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.822608  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.822856  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.823113  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.823368  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.823638  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.823985  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.824380  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.824719  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.825162  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.825588  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.826018  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.826464  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.826937  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.827532  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.828127  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.828740  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.829202  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.829817  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.830324  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.830882  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.831417  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.832106  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1738803528.832884  192869 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2175 - loss: 1.9213 - val_accuracy: 0.3293 - val_loss: 1.5436 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5751 - loss: 1.1527 - val_accuracy: 0.4634 - val_loss: 1.3241 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6503 - loss: 0.8899 - val_accuracy: 0.5366 - val_loss: 1.1016 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7096 - loss: 0.7220 - val_accuracy: 0.5610 - val_loss: 1.0217 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7299 - loss: 0.6651 - val_accuracy: 0.5854 - val_loss: 0.9693 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8104 - loss: 0.5550 - val_accuracy: 0.6037 - val_loss: 0.9394 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8191 - loss: 0.5390 - val_accuracy: 0.6159 - val_loss: 0.8956 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8175 - loss: 0.5020 - val_accuracy: 0.6220 - val_loss: 0.8753 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8533 - loss: 0.4486 - val_accuracy: 0.6646 - val_loss: 0.8253 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8682 - loss: 0.4133 - val_accuracy: 0.6220 - val_loss: 0.8509 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8379 - loss: 0.4263 - val_accuracy: 0.6585 - val_loss: 0.8137 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8429 - loss: 0.3936 - val_accuracy: 0.6646 - val_loss: 0.7626 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8775 - loss: 0.3671 - val_accuracy: 0.6463 - val_loss: 0.7874 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8711 - loss: 0.3468 - val_accuracy: 0.6341 - val_loss: 0.8206 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8645 - loss: 0.3360 - val_accuracy: 0.6524 - val_loss: 0.7918 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8815 - loss: 0.3172 - val_accuracy: 0.6707 - val_loss: 0.7577 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9135 - loss: 0.2877 - val_accuracy: 0.6768 - val_loss: 0.7841 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9130 - loss: 0.2916 - val_accuracy: 0.6707 - val_loss: 0.7417 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9050 - loss: 0.3017 - val_accuracy: 0.6646 - val_loss: 0.7542 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9094 - loss: 0.2761 - val_accuracy: 0.6829 - val_loss: 0.7513 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9011 - loss: 0.2727 - val_accuracy: 0.6707 - val_loss: 0.7607 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9221 - loss: 0.2545 - val_accuracy: 0.6768 - val_loss: 0.7592 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9112 - loss: 0.2605 - val_accuracy: 0.6890 - val_loss: 0.7430 - learning_rate: 2.5000e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step\n",
      "\n",
      "Fold 2 Validation Metrics:\n",
      "  Loss: 0.7417\n",
      "  Accuracy: 0.6707\n",
      "  Precision: 0.6602\n",
      "  Recall: 0.6852\n",
      "  F1 Score: 0.6591\n",
      "  ROC AUC Score: 0.9220\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7182 - loss: 0.6927 \n",
      "Fold 2 Test Metrics: Loss: 0.7753, Accuracy: 0.6707\n",
      "\n",
      "Processing Fold 3...\n",
      "Found 538 files belonging to 6 classes.\n",
      "Found 153 files belonging to 6 classes.\n",
      "Found 64 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.7581699346405228, 1: 1.9078014184397163, 2: 0.7865497076023392, 3: 1.1955555555555555, 4: 2.490740740740741, 5: 0.4170542635658915}\n",
      "Training with frozen base layers for 50 epochs on Fold 3...\n",
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.2252 - loss: 1.9711 - val_accuracy: 0.4052 - val_loss: 1.4845 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5285 - loss: 1.1818 - val_accuracy: 0.5490 - val_loss: 1.2289 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6988 - loss: 0.8829 - val_accuracy: 0.5556 - val_loss: 1.1740 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7070 - loss: 0.7195 - val_accuracy: 0.5752 - val_loss: 1.1363 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7812 - loss: 0.6161 - val_accuracy: 0.5882 - val_loss: 1.0965 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7979 - loss: 0.5404 - val_accuracy: 0.5882 - val_loss: 1.0764 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8067 - loss: 0.5162 - val_accuracy: 0.6013 - val_loss: 1.0636 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8290 - loss: 0.4644 - val_accuracy: 0.5948 - val_loss: 1.0547 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8463 - loss: 0.4447 - val_accuracy: 0.5948 - val_loss: 1.0499 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8713 - loss: 0.4274 - val_accuracy: 0.5948 - val_loss: 1.0545 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8809 - loss: 0.3716 - val_accuracy: 0.6013 - val_loss: 1.0544 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8528 - loss: 0.3690 - val_accuracy: 0.5948 - val_loss: 1.0493 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8715 - loss: 0.3591 - val_accuracy: 0.6144 - val_loss: 1.0396 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8881 - loss: 0.3331 - val_accuracy: 0.6013 - val_loss: 1.0335 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9221 - loss: 0.2993 - val_accuracy: 0.5948 - val_loss: 1.0332 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8952 - loss: 0.3081 - val_accuracy: 0.6078 - val_loss: 1.0382 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8726 - loss: 0.3178 - val_accuracy: 0.6078 - val_loss: 1.0477 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9133 - loss: 0.2593 - val_accuracy: 0.5948 - val_loss: 1.0382 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9090 - loss: 0.2667 - val_accuracy: 0.5948 - val_loss: 1.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9199 - loss: 0.2663 - val_accuracy: 0.6078 - val_loss: 1.0303 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9015 - loss: 0.2411 - val_accuracy: 0.6144 - val_loss: 1.0299 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9225 - loss: 0.2401 - val_accuracy: 0.6078 - val_loss: 1.0308 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9399 - loss: 0.2171 - val_accuracy: 0.6144 - val_loss: 1.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9190 - loss: 0.2293 - val_accuracy: 0.6144 - val_loss: 1.0493 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9288 - loss: 0.2414 - val_accuracy: 0.6078 - val_loss: 1.0407 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9204 - loss: 0.2453 - val_accuracy: 0.6078 - val_loss: 1.0357 - learning_rate: 2.5000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step\n",
      "\n",
      "Fold 3 Validation Metrics:\n",
      "  Loss: 1.0299\n",
      "  Accuracy: 0.6144\n",
      "  Precision: 0.6400\n",
      "  Recall: 0.6170\n",
      "  F1 Score: 0.6203\n",
      "  ROC AUC Score: 0.8838\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6979 - loss: 0.6359 \n",
      "Fold 3 Test Metrics: Loss: 0.7161, Accuracy: 0.6719\n",
      "\n",
      "Processing Fold 4...\n",
      "Found 524 files belonging to 6 classes.\n",
      "Found 150 files belonging to 6 classes.\n",
      "Found 81 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.6794871794871795, 1: 1.9848484848484849, 2: 0.7594202898550725, 3: 1.0522088353413654, 4: 2.425925925925926, 5: 0.45017182130584193}\n",
      "Training with frozen base layers for 50 epochs on Fold 4...\n",
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2988 - loss: 1.7933 - val_accuracy: 0.3467 - val_loss: 1.4804 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5591 - loss: 1.0520 - val_accuracy: 0.5333 - val_loss: 1.1572 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6688 - loss: 0.8072 - val_accuracy: 0.5867 - val_loss: 1.0436 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7494 - loss: 0.6483 - val_accuracy: 0.5867 - val_loss: 1.0111 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7846 - loss: 0.5782 - val_accuracy: 0.6000 - val_loss: 0.9807 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7911 - loss: 0.5587 - val_accuracy: 0.6333 - val_loss: 0.9305 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8090 - loss: 0.5081 - val_accuracy: 0.6200 - val_loss: 0.9582 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8068 - loss: 0.4417 - val_accuracy: 0.6533 - val_loss: 0.8974 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8405 - loss: 0.4291 - val_accuracy: 0.6467 - val_loss: 0.8967 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8563 - loss: 0.3974 - val_accuracy: 0.6733 - val_loss: 0.8735 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8518 - loss: 0.3699 - val_accuracy: 0.6800 - val_loss: 0.8722 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8717 - loss: 0.3474 - val_accuracy: 0.6533 - val_loss: 0.8934 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8749 - loss: 0.3231 - val_accuracy: 0.6933 - val_loss: 0.8658 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8711 - loss: 0.3302 - val_accuracy: 0.6867 - val_loss: 0.8720 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8807 - loss: 0.2818 - val_accuracy: 0.6733 - val_loss: 0.8574 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8929 - loss: 0.2791 - val_accuracy: 0.6733 - val_loss: 0.8727 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8877 - loss: 0.2546 - val_accuracy: 0.6867 - val_loss: 0.8790 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8903 - loss: 0.2452 - val_accuracy: 0.6867 - val_loss: 0.8384 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9248 - loss: 0.2399 - val_accuracy: 0.6933 - val_loss: 0.8584 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9112 - loss: 0.2201 - val_accuracy: 0.6867 - val_loss: 0.8606 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8965 - loss: 0.2443 - val_accuracy: 0.7133 - val_loss: 0.8479 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.2222 - val_accuracy: 0.7000 - val_loss: 0.8430 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9281 - loss: 0.2065 - val_accuracy: 0.6933 - val_loss: 0.8506 - learning_rate: 5.0000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step\n",
      "\n",
      "Fold 4 Validation Metrics:\n",
      "  Loss: 0.8384\n",
      "  Accuracy: 0.6867\n",
      "  Precision: 0.6767\n",
      "  Recall: 0.6851\n",
      "  F1 Score: 0.6649\n",
      "  ROC AUC Score: 0.9048\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7454 - loss: 0.7876 \n",
      "Fold 4 Test Metrics: Loss: 0.7328, Accuracy: 0.7407\n",
      "\n",
      "Processing Fold 5...\n",
      "Found 538 files belonging to 6 classes.\n",
      "Found 154 files belonging to 6 classes.\n",
      "Found 63 files belonging to 6 classes.\n",
      "Class Weight Dictionary: {0: 1.6918238993710693, 1: 2.0852713178294575, 2: 0.8226299694189603, 3: 1.0803212851405624, 4: 2.3596491228070176, 5: 0.4229559748427673}\n",
      "Training with frozen base layers for 50 epochs on Fold 5...\n",
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2761 - loss: 1.8911 - val_accuracy: 0.5325 - val_loss: 1.2845 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5796 - loss: 1.2192 - val_accuracy: 0.5649 - val_loss: 1.1962 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6314 - loss: 0.9040 - val_accuracy: 0.6429 - val_loss: 1.0137 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6955 - loss: 0.7514 - val_accuracy: 0.6688 - val_loss: 0.9425 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7450 - loss: 0.6757 - val_accuracy: 0.6883 - val_loss: 0.8935 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7740 - loss: 0.5863 - val_accuracy: 0.7078 - val_loss: 0.8540 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7923 - loss: 0.5485 - val_accuracy: 0.6818 - val_loss: 0.8450 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8138 - loss: 0.5000 - val_accuracy: 0.6948 - val_loss: 0.8279 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8324 - loss: 0.4508 - val_accuracy: 0.6948 - val_loss: 0.8259 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8389 - loss: 0.4077 - val_accuracy: 0.7338 - val_loss: 0.7699 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8658 - loss: 0.3938 - val_accuracy: 0.7273 - val_loss: 0.7599 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8572 - loss: 0.4094 - val_accuracy: 0.7078 - val_loss: 0.8022 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8464 - loss: 0.3706 - val_accuracy: 0.7208 - val_loss: 0.7446 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8880 - loss: 0.3450 - val_accuracy: 0.7338 - val_loss: 0.7729 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8732 - loss: 0.3141 - val_accuracy: 0.7338 - val_loss: 0.7297 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8901 - loss: 0.3198 - val_accuracy: 0.7468 - val_loss: 0.7383 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8934 - loss: 0.2939 - val_accuracy: 0.7532 - val_loss: 0.7435 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8885 - loss: 0.2946 - val_accuracy: 0.7468 - val_loss: 0.7485 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9087 - loss: 0.2654 - val_accuracy: 0.7403 - val_loss: 0.7239 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9092 - loss: 0.2749 - val_accuracy: 0.7338 - val_loss: 0.7179 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9052 - loss: 0.2649 - val_accuracy: 0.7468 - val_loss: 0.7372 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9096 - loss: 0.2560 - val_accuracy: 0.7468 - val_loss: 0.7237 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9223 - loss: 0.2533 - val_accuracy: 0.7338 - val_loss: 0.7246 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8942 - loss: 0.2555 - val_accuracy: 0.7338 - val_loss: 0.7247 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9300 - loss: 0.2228 - val_accuracy: 0.7338 - val_loss: 0.7200 - learning_rate: 2.5000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
      "\n",
      "Fold 5 Validation Metrics:\n",
      "  Loss: 0.7179\n",
      "  Accuracy: 0.7338\n",
      "  Precision: 0.7299\n",
      "  Recall: 0.7321\n",
      "  F1 Score: 0.7221\n",
      "  ROC AUC Score: 0.9270\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8317 - loss: 0.4953\n",
      "Fold 5 Test Metrics: Loss: 0.5061, Accuracy: 0.8413\n",
      "INFO:tensorflow:Assets written to: ../saved_models/model1/best_f1score_fold/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/model1/best_f1score_fold/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_models/model1/best_f1score_fold'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_12227')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 6), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  124718986509392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718986495376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718986506512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399150288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399138960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399146640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399150672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399149520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399755728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399757456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399755920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399756688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399752656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399751504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399753616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399751696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399754000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399755536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399752848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399741520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399742864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399743632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399746512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399748240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399747856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399746128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399744208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399749776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399750544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226063440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226061904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399748048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399745552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226063824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226061136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226061520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226064208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226050576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226060368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226058064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226057296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226058448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226059984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226052496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226052304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226055376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226050768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226056144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226049616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226054224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912304784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226063056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226051920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912308816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912302864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912311504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912304592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912310352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912306704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912305744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912306128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912312272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912307664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912304976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912312656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912314192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912308624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912302480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912315728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912312464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912313424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912303248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912314576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912185232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912184464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912186000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912180432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912182544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124715399135504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912176592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912180624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912181776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912182352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912174096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912170256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912171024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912172176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912172944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912176016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912176400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912178320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912176784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912174864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912177936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226193552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226193168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124714912182160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226193936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226196816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226194320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226191248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226190288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226192208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226186448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226188560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226188176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226184528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226195856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226187792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226183568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226183952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226182416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226186640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226182800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226185488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718358221200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226188368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226181648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718358218896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718358227152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718358225808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718358230032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718358227344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205198928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205202000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205197776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205201232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205195664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205204496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205194512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205194704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205202960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205205072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717205205456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204794704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204784720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204793168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204798928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204797008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204784336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204788560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204790864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204787408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717204789712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226714384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226715536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226719952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226710544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226707856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226710160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226711696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226717072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226720912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226719376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226114512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226108944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226719760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226112592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226102992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226100304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226107984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226110288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226102608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226100688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799201168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799200784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226106448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717226104144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799198480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799206160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799203088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799197328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799199632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799195024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799206928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718784827408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799208272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718784839312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718784833552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941730000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941721936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941717712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941726160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941725776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941728272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215552080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941723472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941724240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215559376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215554768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215555920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215549392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215549776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215563216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783495632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215563408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215553232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215555536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783485456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215969552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215972048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783491600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215967248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215968400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215961872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215971856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215960336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215965712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215963408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783091664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718993111952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783087824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215973200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124717215972240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719371386960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718793249360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783102608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718976697552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719195524752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719183520848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718976703312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718975323984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719371236368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718976701200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719142151632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719146045840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718793254352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718975005712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718975004944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719150685584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783850512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719150681744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719371147728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718975324752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719150876624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718792532112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783849168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718783842640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718792529040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718963446736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718784465616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718792539024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718784466384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718963456720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719141976976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718784471760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719157921552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718792512848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718792517648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941842000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941845264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718991710864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719141971984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941836432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941843920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719141927056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941839888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799386384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718941832016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718986499216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718986497680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124719141923600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718799376400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718963332048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  124718963338192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Best model updated at Fold 5 with F1 Score: 0.7221\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\n",
      "Training complete. Best Validation F1 Score: 0.7221\n"
     ]
    }
   ],
   "source": [
    "for i, config in enumerate(configs):\n",
    "    # Define the base path for saving models\n",
    "    model_subdir = os.path.join(save_dir, f'model{i + 1}')\n",
    "    os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving cthe model with the best f1-score\n",
    "    best_f1_dir = os.path.join(model_subdir, 'best_f1score_fold')\n",
    "    os.makedirs(best_f1_dir, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving checkpoints for model\n",
    "    checkpoint_folder = os.path.join(model_subdir, 'checkpoints')\n",
    "    os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "    \n",
    "    config['checkpoint_folder'] = checkpoint_folder\n",
    "\n",
    "    main_training_loop(configs[i], best_f1_dir, model_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
