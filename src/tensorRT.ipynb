{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = tf.keras.models.load_model(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"../data/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 32         # size of the batch that will be fed to model\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "test_size = 0.2\n",
    "\n",
    "# Load dataset without splitting\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,                                  # loads images from the data_root directory\n",
    "    image_size=(img_height, img_width),         # resizes all images to (224, 224) pixels\n",
    "    batch_size=batch_size,                      # set the batch size\n",
    "    shuffle=True                                # shufle data when loaded\n",
    ")\n",
    "\n",
    "# Preprocess dataset (we only need the images for inference)\n",
    "image_batches = []\n",
    "for image_batch, _ in dataset:\n",
    "    image_batches.append(image_batch)\n",
    "\n",
    "image_batches = np.concatenate(image_batches)  # Flatten batches to get all images\n",
    "print(f\"Total images: {image_batches.shape[0]}\")\n",
    "\n",
    "# Split the data into test subset for benchmarking\n",
    "_, X_test = train_test_split(image_batches, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "trials = 1000\n",
    "inference_times = []\n",
    "\n",
    "print(f\"Running {trials} inference trials on {len(X_test)} test images...\")\n",
    "for i in range(trials):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # Run inference for a batch of images\n",
    "    model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    inference_time = end_time - start_time\n",
    "    inference_times.append(inference_time)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        avg_inference = np.mean(inference_times)  # Average inference time per trial\n",
    "        print(f\"Step {i}: average inference time = {avg_inference:.6f} seconds\")\n",
    "        \n",
    "    tf.keras.backend.clear_session()\n",
    "        \n",
    "# Compute throughput (images per second)\n",
    "total_time = np.sum(inference_times)\n",
    "throughput = (trials * len(X_test)) / total_time\n",
    "print(f\"Throughput: {throughput:.2f} images/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "# Define the conversion parameters\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "    precision_mode=trt.TrtPrecisionMode.FP16,  # You can use FP32 or INT8 if supported\n",
    "    max_workspace_size_bytes=8000000000  # 8GB, adjust as per your GPU memory\n",
    ")\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir='path/to/save/saved_model',\n",
    "    conversion_params=conversion_params\n",
    ")\n",
    "\n",
    "# Convert the model\n",
    "converter.convert()\n",
    "converter.summary()\n",
    "\n",
    "# Save the optimized model\n",
    "converter.save('path/to/save/tensorrt_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the optimized TensorRT model\n",
    "# saved_model_loaded = tf.saved_model.load('path/to/save/tensorrt_model')\n",
    "# infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "# # Example input data (adjust as per your model's input requirements)\n",
    "# input_tensor = tf.convert_to_tensor(your_input_data)\n",
    "\n",
    "# # Run inference\n",
    "# output = infer(input_tensor)\n",
    "\n",
    "# # Process output as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
