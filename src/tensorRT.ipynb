{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:17:37.778348: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-08 21:17:37.811657: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# How to create the docker run directly in Lambda2\n",
    "# docker run --gpus all -it --mount type=bind,source=/home/jacob-delgado/Documents/CAPSTONE,target=/workspace/CAPSTONE nvcr.io/nvidia/tensorflow:24.10-tf2-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15426006686882890183\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 18310823936\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6426993958775620940\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22671196160\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4619222676308665363\n",
      "physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 2144165316\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 22:54:53.151232: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.151401: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.151534: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.151655: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.151776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.151898: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.160021: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.160182: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.160311: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.160435: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.160562: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.160682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /device:GPU:0 with 17462 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2024-11-07 22:54:53.160974: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-07 22:54:53.161105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /device:GPU:1 with 21620 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 0)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "print(trt.trt_utils._pywrap_py_utils.get_linked_tensorrt_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:17:41.483219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.483391: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.519819: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.520024: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.520167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.520301: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.636952: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.637134: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.637271: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.637396: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.637520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.637645: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.646020: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.646184: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.646318: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.646449: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.646641: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.646765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2024-11-08 21:17:41.647221: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:17:41.647447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22008 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "data_root = pathlib.Path(\"../data/Monkeypox_Data/Original_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 32         # size of the batch that will be fed to model\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "test_size = 0.2\n",
    "\n",
    "# Load dataset without splitting\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,                                  # loads images from the data_root directory\n",
    "    image_size=(img_height, img_width),         # resizes all images to (224, 224) pixels\n",
    "    batch_size=batch_size,                      # set the batch size\n",
    "    shuffle=True                                # shufle data when loaded\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:51:00.443322: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Preprocess dataset (we only need the images for inference)\n",
    "image_batches = []\n",
    "for image_batch, _ in dataset:\n",
    "    image_batches.append(image_batch)\n",
    "\n",
    "image_batches = np.concatenate(image_batches)  # Flatten batches to get all images\n",
    "print(f\"Total images: {image_batches.shape[0]}\")\n",
    "\n",
    "# Split the data into test subset for benchmarking\n",
    "_, X_test,  = train_test_split(image_batches, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 228 and Labels: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:17:45.322350: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "image_batches, labels = [], []\n",
    "for image_batch, label_batch in dataset:\n",
    "    image_batches.append(image_batch)\n",
    "    labels.append(label_batch)\n",
    "\n",
    "image_batches = np.concatenate(image_batches)\n",
    "labels = np.concatenate(labels)\n",
    "print(f\"Total images: {image_batches.shape[0]} and Labels: {labels.shape[0]}\")\n",
    "\n",
    "train_images_UNUSED, X_test, train_labels_UNUSED, Y_test = train_test_split(\n",
    "    image_batches, labels, test_size=test_size, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference on original model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'sequential_1/dense_1/bias:0' shape=(1,) dtype=float32>\n",
      "  <tf.Variable 'sequential_1/dense_1/kernel:0' shape=(1280, 1) dtype=float32>\n",
      "  <tf.Variable 'Conv_1_bn/beta:0' shape=(1280,) dtype=float32>\n",
      "  <tf.Variable 'Conv_1_bn/gamma:0' shape=(1280,) dtype=float32>\n",
      "  <tf.Variable 'Conv_1/kernel:0' shape=(1, 1, 320, 1280) dtype=float32>\n",
      "  <tf.Variable 'block_16_project_BN/beta:0' shape=(320,) dtype=float32>\n",
      "  <tf.Variable 'block_16_project_BN/gamma:0' shape=(320,) dtype=float32>\n",
      "  <tf.Variable 'block_16_project/kernel:0' shape=(1, 1, 960, 320) dtype=float32>\n",
      "  <tf.Variable 'block_16_depthwise_BN/beta:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_16_depthwise_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_16_depthwise/kernel:0' shape=(3, 3, 960, 1) dtype=float32>\n",
      "  <tf.Variable 'block_16_expand_BN/beta:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_16_expand_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_16_expand/kernel:0' shape=(1, 1, 160, 960) dtype=float32>\n",
      "  <tf.Variable 'block_15_project_BN/beta:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_15_project_BN/gamma:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_15_project/kernel:0' shape=(1, 1, 960, 160) dtype=float32>\n",
      "  <tf.Variable 'block_15_depthwise_BN/beta:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_15_depthwise_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_15_depthwise/kernel:0' shape=(3, 3, 960, 1) dtype=float32>\n",
      "  <tf.Variable 'block_15_expand_BN/beta:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_15_expand_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_15_expand/kernel:0' shape=(1, 1, 160, 960) dtype=float32>\n",
      "  <tf.Variable 'block_14_project_BN/beta:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_14_project_BN/gamma:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_14_project/kernel:0' shape=(1, 1, 960, 160) dtype=float32>\n",
      "  <tf.Variable 'block_14_depthwise_BN/beta:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_14_depthwise_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_14_depthwise/kernel:0' shape=(3, 3, 960, 1) dtype=float32>\n",
      "  <tf.Variable 'block_14_expand_BN/beta:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_14_expand_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_14_expand/kernel:0' shape=(1, 1, 160, 960) dtype=float32>\n",
      "  <tf.Variable 'block_13_project_BN/beta:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_13_project_BN/gamma:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_13_project/kernel:0' shape=(1, 1, 576, 160) dtype=float32>\n",
      "  <tf.Variable 'block_13_depthwise_BN/beta:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_13_depthwise_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_13_depthwise/kernel:0' shape=(3, 3, 576, 1) dtype=float32>\n",
      "  <tf.Variable 'block_13_expand_BN/beta:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_13_expand_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_13_expand/kernel:0' shape=(1, 1, 96, 576) dtype=float32>\n",
      "  <tf.Variable 'block_12_project_BN/beta:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_12_project_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_12_project/kernel:0' shape=(1, 1, 576, 96) dtype=float32>\n",
      "  <tf.Variable 'block_12_depthwise_BN/beta:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_12_depthwise_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_12_depthwise/kernel:0' shape=(3, 3, 576, 1) dtype=float32>\n",
      "  <tf.Variable 'block_12_expand_BN/beta:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_12_expand_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_12_expand/kernel:0' shape=(1, 1, 96, 576) dtype=float32>\n",
      "  <tf.Variable 'block_11_project_BN/beta:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_11_project_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_11_project/kernel:0' shape=(1, 1, 576, 96) dtype=float32>\n",
      "  <tf.Variable 'block_11_depthwise_BN/beta:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_11_depthwise_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_11_depthwise/kernel:0' shape=(3, 3, 576, 1) dtype=float32>\n",
      "  <tf.Variable 'block_11_expand_BN/beta:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_11_expand_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_11_expand/kernel:0' shape=(1, 1, 96, 576) dtype=float32>\n",
      "  <tf.Variable 'block_10_project_BN/beta:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_10_project_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_10_project/kernel:0' shape=(1, 1, 384, 96) dtype=float32>\n",
      "  <tf.Variable 'block_10_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_10_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_10_depthwise/kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "  <tf.Variable 'block_10_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_10_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_10_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "  <tf.Variable 'block_9_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_9_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_9_project/kernel:0' shape=(1, 1, 384, 64) dtype=float32>\n",
      "  <tf.Variable 'block_9_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_9_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_9_depthwise/kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "  <tf.Variable 'block_9_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_9_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_9_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "  <tf.Variable 'block_8_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_8_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_8_project/kernel:0' shape=(1, 1, 384, 64) dtype=float32>\n",
      "  <tf.Variable 'block_8_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_8_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_8_depthwise/kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "  <tf.Variable 'block_8_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_8_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_8_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "  <tf.Variable 'block_7_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_7_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_7_project/kernel:0' shape=(1, 1, 384, 64) dtype=float32>\n",
      "  <tf.Variable 'block_7_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_7_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_7_depthwise/kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "  <tf.Variable 'block_7_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_7_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_7_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "  <tf.Variable 'block_6_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_6_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_6_project/kernel:0' shape=(1, 1, 192, 64) dtype=float32>\n",
      "  <tf.Variable 'block_6_depthwise_BN/beta:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_6_depthwise_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_6_depthwise/kernel:0' shape=(3, 3, 192, 1) dtype=float32>\n",
      "  <tf.Variable 'block_6_expand_BN/beta:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_6_expand_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_6_expand/kernel:0' shape=(1, 1, 32, 192) dtype=float32>\n",
      "  <tf.Variable 'block_5_project_BN/beta:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_5_project_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_5_project/kernel:0' shape=(1, 1, 192, 32) dtype=float32>\n",
      "  <tf.Variable 'block_5_depthwise_BN/beta:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_5_depthwise_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_5_depthwise/kernel:0' shape=(3, 3, 192, 1) dtype=float32>\n",
      "  <tf.Variable 'block_5_expand_BN/beta:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_5_expand_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_5_expand/kernel:0' shape=(1, 1, 32, 192) dtype=float32>\n",
      "  <tf.Variable 'block_4_project_BN/beta:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_4_project_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_4_project/kernel:0' shape=(1, 1, 192, 32) dtype=float32>\n",
      "  <tf.Variable 'block_4_depthwise_BN/beta:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_4_depthwise_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_4_depthwise/kernel:0' shape=(3, 3, 192, 1) dtype=float32>\n",
      "  <tf.Variable 'block_4_expand_BN/beta:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_4_expand_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_4_expand/kernel:0' shape=(1, 1, 32, 192) dtype=float32>\n",
      "  <tf.Variable 'block_3_project_BN/beta:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_3_project_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_3_project/kernel:0' shape=(1, 1, 144, 32) dtype=float32>\n",
      "  <tf.Variable 'block_3_depthwise_BN/beta:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_3_depthwise_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_3_depthwise/kernel:0' shape=(3, 3, 144, 1) dtype=float32>\n",
      "  <tf.Variable 'block_3_expand_BN/beta:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_3_expand_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_3_expand/kernel:0' shape=(1, 1, 24, 144) dtype=float32>\n",
      "  <tf.Variable 'block_2_project_BN/beta:0' shape=(24,) dtype=float32>\n",
      "  <tf.Variable 'block_2_project_BN/gamma:0' shape=(24,) dtype=float32>\n",
      "  <tf.Variable 'block_2_project/kernel:0' shape=(1, 1, 144, 24) dtype=float32>\n",
      "  <tf.Variable 'block_2_depthwise_BN/beta:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_2_depthwise_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_2_depthwise/kernel:0' shape=(3, 3, 144, 1) dtype=float32>\n",
      "  <tf.Variable 'block_2_expand_BN/beta:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_2_expand_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_2_expand/kernel:0' shape=(1, 1, 24, 144) dtype=float32>\n",
      "  <tf.Variable 'block_1_project_BN/beta:0' shape=(24,) dtype=float32>\n",
      "  <tf.Variable 'block_1_project_BN/gamma:0' shape=(24,) dtype=float32>\n",
      "  <tf.Variable 'block_1_project/kernel:0' shape=(1, 1, 96, 24) dtype=float32>\n",
      "  <tf.Variable 'block_1_depthwise_BN/beta:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_1_depthwise_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_1_depthwise/kernel:0' shape=(3, 3, 96, 1) dtype=float32>\n",
      "  <tf.Variable 'block_1_expand_BN/beta:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_1_expand_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_1_expand/kernel:0' shape=(1, 1, 16, 96) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_project_BN/beta:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_project_BN/gamma:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_project/kernel:0' shape=(1, 1, 32, 16) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_depthwise_BN/beta:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_depthwise_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_depthwise/kernel:0' shape=(3, 3, 32, 1) dtype=float32>\n",
      "  <tf.Variable 'bn_Conv1/beta:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'bn_Conv1/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'Conv1/kernel:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Running 1000 inference trials on 46 test images...\n",
      "Step 0: average inference time = 5.566995 seconds\n",
      "Step 50: average inference time = 0.755272 seconds\n",
      "Step 100: average inference time = 0.704571 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Run inference for a batch of images\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     32\u001b[0m inference_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py:2650\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2648\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2650\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run inference\n",
    "trials = 1000\n",
    "inference_times = []\n",
    "\n",
    "# Load the SavedModel directly\n",
    "saved_model = tf.saved_model.load('../best_model/model1/best_f1score_fold')\n",
    "\n",
    "# # Load the SavedModel using TFSMLayer, treating it as a Keras layer\n",
    "# model_layer = tf.keras.layers.TFSMLayer('../best_model/model1/best_f1score_fold', call_endpoint='serving_default')\n",
    "\n",
    "# # Wrap the TFSMLayer in a Sequential model for inference\n",
    "# saved_model = tf.keras.Sequential([model_layer])\n",
    "\n",
    "# Wrap the SavedModel for inference\n",
    "def saved_model_call(inputs):\n",
    "    return saved_model.signatures[\"serving_default\"](inputs)[\"output_0\"]\n",
    "\n",
    "# Create a Keras Sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),  # Replace with your model's input shape\n",
    "    tf.keras.layers.Lambda(saved_model_call)\n",
    "])\n",
    "\n",
    "print(f\"Running {trials} inference trials on {len(X_test)} test images...\")\n",
    "for i in range(trials):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # Run inference for a batch of images\n",
    "    model.predict(X_test, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    inference_time = end_time - start_time\n",
    "    inference_times.append(inference_time)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        avg_inference = np.mean(inference_times)  # Average inference time per trial\n",
    "        print(f\"Step {i}: average inference time = {avg_inference:.6f} seconds\")\n",
    "        \n",
    "    tf.keras.backend.clear_session()\n",
    "        \n",
    "# Compute throughput (images per second)\n",
    "total_time = np.sum(inference_times)\n",
    "throughput = (trials * len(X_test)) / total_time\n",
    "print(f\"Throughput: {throughput:.2f} images/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Optimization FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (10, 5, 0)\n",
      "INFO:tensorflow:Loaded TensorRT version: (10, 5, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:01:33.206442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.206646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.206748: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
      "2024-11-08 21:01:33.206819: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-11-08 21:01:33.207064: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.207197: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.207312: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.207421: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.207529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.207638: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.207807: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.207918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.208028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.208136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16758 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2024-11-08 21:01:33.208163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:33.208266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22008 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing prior device assignments in loaded saved model\n",
      "INFO:tensorflow:Automatic mixed precision will be used on the whole TensorFlow Graph. This behavior can be deactivated using the environment variable: TF_TRT_EXPERIMENTAL_FEATURES=deactivate_mixed_precision.\n",
      "More information can be found on: https://www.tensorflow.org/guide/mixed_precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:01:34.498053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.498283: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.498390: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
      "2024-11-08 21:01:34.498476: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-11-08 21:01:34.498732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.498862: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.498982: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499105: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499220: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499335: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499508: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499626: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499741: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16758 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2024-11-08 21:01:34.499873: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-08 21:01:34.499975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22008 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\n",
      "2024-11-08 21:01:34.525473: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2373] Running auto_mixed_precision graph optimizer\n",
      "2024-11-08 21:01:34.528355: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 1055\n",
      "Recognized nodes available for conversion: 684\n",
      "Total nodes converted: 256\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 104\n",
      "Allowlisted nodes converted: 53\n",
      "Denylisted nodes blocking conversion: 2\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2024-11-08 21:01:34.571927: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:204] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.\n",
      "2024-11-08 21:01:34.577829: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:970] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- NoOp -> 2x\n",
      "\t- Identity -> 1x\n",
      "\t- Placeholder -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 4\n",
      "\t- Total nonconverted OP Types: 3\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2024-11-08 21:01:34.580278: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1298] The environment variable TF_TRT_MAX_ALLOWED_ENGINES=20 has no effect since there are only 1 TRT Engines with  at least minimum_segment_size=3 nodes.\n",
      "2024-11-08 21:01:34.580666: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:805] Number of TensorRT candidate segments: 1\n",
      "2024-11-08 21:01:34.583200: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 0 consisting of 304 nodes by TRTEngineOp_000_000.\n",
      "2024-11-08 21:01:34.590775: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 313\n",
      "Recognized nodes available for conversion: 179\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 53\n",
      "Denylisted nodes blocking conversion: 2\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRTEngineOP Name                 Device        # Nodes # Inputs      # Outputs     Input DTypes       Output Dtypes      Input Shapes       Output Shapes     \n",
      "================================================================================================================================================================\n",
      "TRTEngineOp_000_000              device:GPU:0  304     1             1             ['float32']        ['float32']        [[-1, 224, 224 ... [[-1, 1]]         \n",
      "\n",
      "\t- AddV2: 63x\n",
      "\t- Cast: 4x\n",
      "\t- Const: 126x\n",
      "\t- Conv2D: 35x\n",
      "\t- DepthwiseConv2dNative: 17x\n",
      "\t- MatMul: 1x\n",
      "\t- Mean: 1x\n",
      "\t- Mul: 18x\n",
      "\t- Pad: 4x\n",
      "\t- Relu6: 35x\n",
      "\n",
      "================================================================================================================================================================\n",
      "[*] Total number of TensorRT engines: 1\n",
      "[*] % of OPs Converted: 99.35% [304/306]\n",
      "\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_000 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: ../tensorRT_model/test/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 21:01:34.779195: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: NOT_FOUND: TRTEngineCacheResource not yet created\n",
      "INFO:tensorflow:Assets written to: ../tensorRT_model/test/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "# Load the SavedModel\n",
    "saved_model_dir = '../best_model/model1/best_f1score_fold'\n",
    "optimized_model_dir = '../tensorRT_model/test'\n",
    "\n",
    "# Define the conversion parameters\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "    precision_mode=trt.TrtPrecisionMode.FP16,                   # You can use FP32 or INT8 if supported\n",
    "    max_workspace_size_bytes=8000000000                         # 8GB, adjust as per your GPU memory\n",
    ")\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=saved_model_dir,\n",
    "    conversion_params=conversion_params)\n",
    "\n",
    "# Convert the model\n",
    "converter.convert()\n",
    "converter.summary()\n",
    "\n",
    "# Save the optimized model\n",
    "converter.save(optimized_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Optimization INT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the SavedModel\n",
    "saved_model_dir = '../best_model/model1/best_f1score_fold'\n",
    "optimized_model_dir = '../tensorRT_model/test_INT8'\n",
    "\n",
    "# Define the conversion parameters\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "    precision_mode=trt.TrtPrecisionMode.INT8,  # Enable INT8 precision\n",
    "    max_workspace_size_bytes=8000000000       # 8GB, adjust based on your GPU memory\n",
    ")\n",
    "\n",
    "# Create a converter\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=saved_model_dir,\n",
    "    conversion_params=conversion_params\n",
    ")\n",
    "\n",
    "# Function to provide calibration data (generator)\n",
    "def calibration_input_fn():\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"../data/Monkeypox_Data/Original_Images\",\n",
    "        image_size=(224, 224),  # Fixed image size must match model input\n",
    "        batch_size=32,\n",
    "        shuffle=True\n",
    "    )\n",
    "    for batch, _ in dataset.take(10):  # Limit to 10 batches for calibration\n",
    "        yield tf.convert_to_tensor(batch)\n",
    "\n",
    "# Convert the model and calibrate\n",
    "converter.convert(calibration_input_fn=calibration_input_fn)\n",
    "\n",
    "# Explicitly define input shapes for TensorRT during `build()`\n",
    "print(\"Building and calibrating the model with fixed input shapes...\")\n",
    "converter.build(input_fn=lambda: [tf.ones((32, 224, 224, 3))])  # Fixed batch size and input shape\n",
    "\n",
    "# Save the optimized model\n",
    "converter.save(optimized_model_dir)\n",
    "print(f\"INT8 optimized model saved at {optimized_model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 inference trials on 46 test images...\n",
      "Step 0: average inference time = 0.504493 seconds\n",
      "Step 100: average inference time = 0.491925 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:442\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py:264\u001b[0m, in \u001b[0;36mFunctionType.bind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/usr/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03mand `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03mif the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/inspect.py:3112\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m (_VAR_KEYWORD, _KEYWORD_ONLY):\n\u001b[1;32m   3110\u001b[0m     \u001b[38;5;66;03m# Looks like we have no parameter for this positional\u001b[39;00m\n\u001b[1;32m   3111\u001b[0m     \u001b[38;5;66;03m# argument\u001b[39;00m\n\u001b[0;32m-> 3112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3113\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoo many positional arguments\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m _VAR_POSITIONAL:\n\u001b[1;32m   3116\u001b[0m     \u001b[38;5;66;03m# We have an '*args'-like argument, let's fill it with\u001b[39;00m\n\u001b[1;32m   3117\u001b[0m     \u001b[38;5;66;03m# all positional arguments we have left and move on to\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m     \u001b[38;5;66;03m# the next phase\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: too many positional arguments",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1179\u001b[0m, in \u001b[0;36mConcreteFunction._call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1179\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_structured_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m structured_err:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1259\u001b[0m, in \u001b[0;36mConcreteFunction._call_with_structured_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes the wrapped function with the structured signature.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;124;03m    of this `ConcreteFunction`.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1259\u001b[0m     \u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_function_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m )\n\u001b[1;32m   1262\u001b[0m filtered_flat_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:422\u001b[0m, in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values, is_pure)\u001b[0m\n\u001b[1;32m    421\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m _convert_variables_to_tensors(args, kwargs)\n\u001b[0;32m--> 422\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m \u001b[43mbind_function_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:446\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 446\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinding inputs to tf.function failed due to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msanitized_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for signature:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor: shape=(32, 224, 224, 3), dtype=float32, numpy=\narray([[[[234., 194., 194.],\n         [233., 193., 193.],\n         [225., 187., 186.],\n         ...,\n         [195., 142., 138.],\n         [192., 139., 135.],\n         [191., 138., 134.]],\n\n        [[248., 208., 208.],\n         [248., 208., 208.],\n         [240., 202., 201.],\n         ...,\n         [194., 141., 137.],\n         [190., 137., 133.],\n         [188., 135., 131.]],\n\n        [[245., 206., 207.],\n         [244., 205., 206.],\n         [238., 199., 200.],\n         ...,\n         [194., 141., 137.],\n         [191., 138., 134.],\n         [189., 136., 132.]],\n\n        ...,\n\n        [[234., 175., 169.],\n         [239., 180., 174.],\n         [242., 183., 177.],\n         ...,\n         [208., 161., 151.],\n         [204., 157., 147.],\n         [209., 162., 152.]],\n\n        [[227., 168., 162.],\n         [229., 170., 164.],\n         [231., 172., 166.],\n         ...,\n         [207., 160., 150.],\n         [207., 163., 152.],\n         [220., 176., 165.]],\n\n        [[216., 157., 151.],\n         [215., 156., 150.],\n         [217., 158., 152.],\n         ...,\n         [205., 158., 148.],\n         [207., 163., 152.],\n         [223., 179., 168.]]],\n\n\n       [[[150., 137., 131.],\n         [150., 137., 131.],\n         [150., 137., 131.],\n         ...,\n         [167., 171., 174.],\n         [167., 171., 174.],\n         [167., 171., 174.]],\n\n        [[149., 136., 130.],\n         [149., 136., 130.],\n         [149., 136., 130.],\n         ...,\n         [167., 171., 174.],\n         [167., 171., 174.],\n         [167., 171., 174.]],\n\n        [[148., 133., 128.],\n         [149., 134., 129.],\n         [148., 135., 129.],\n         ...,\n         [167., 171., 174.],\n         [167., 171., 174.],\n         [167., 171., 174.]],\n\n        ...,\n\n        [[120., 103.,  93.],\n         [120., 104.,  91.],\n         [120., 103.,  93.],\n         ...,\n         [138., 130., 119.],\n         [138., 130., 119.],\n         [138., 130., 119.]],\n\n        [[118., 102.,  89.],\n         [119., 103.,  88.],\n         [120., 104.,  91.],\n         ...,\n         [138., 130., 119.],\n         [138., 130., 119.],\n         [138., 130., 119.]],\n\n        [[117., 101.,  86.],\n         [118., 102.,  87.],\n         [120., 104.,  89.],\n         ...,\n         [139., 131., 120.],\n         [139., 131., 120.],\n         [139., 131., 120.]]],\n\n\n       [[[ 18.,  19.,  23.],\n         [ 18.,  19.,  23.],\n         [ 18.,  19.,  23.],\n         ...,\n         [ 25.,  16.,  19.],\n         [ 25.,  16.,  19.],\n         [ 25.,  16.,  19.]],\n\n        [[ 18.,  19.,  23.],\n         [ 18.,  19.,  23.],\n         [ 18.,  19.,  23.],\n         ...,\n         [ 26.,  17.,  20.],\n         [ 26.,  17.,  20.],\n         [ 26.,  17.,  20.]],\n\n        [[ 18.,  19.,  23.],\n         [ 18.,  19.,  23.],\n         [ 18.,  19.,  23.],\n         ...,\n         [ 26.,  17.,  20.],\n         [ 26.,  17.,  20.],\n         [ 26.,  17.,  20.]],\n\n        ...,\n\n        [[ 20.,  15.,  21.],\n         [ 20.,  15.,  21.],\n         [ 20.,  15.,  21.],\n         ...,\n         [241., 209., 186.],\n         [242., 211., 190.],\n         [238., 207., 186.]],\n\n        [[ 20.,  15.,  21.],\n         [ 20.,  15.,  21.],\n         [ 20.,  15.,  21.],\n         ...,\n         [245., 213., 190.],\n         [246., 215., 194.],\n         [240., 212., 191.]],\n\n        [[ 20.,  15.,  21.],\n         [ 20.,  15.,  21.],\n         [ 20.,  15.,  21.],\n         ...,\n         [246., 216., 192.],\n         [249., 218., 197.],\n         [242., 214., 193.]]],\n\n\n       ...,\n\n\n       [[[209., 170., 111.],\n         [201., 162., 103.],\n         [198., 159., 100.],\n         ...,\n         [196., 155., 101.],\n         [194., 153.,  99.],\n         [193., 152.,  98.]],\n\n        [[208., 169., 110.],\n         [205., 166., 107.],\n         [203., 164., 105.],\n         ...,\n         [199., 158., 104.],\n         [198., 157., 103.],\n         [198., 157., 103.]],\n\n        [[201., 162., 103.],\n         [203., 164., 105.],\n         [204., 165., 108.],\n         ...,\n         [200., 159., 105.],\n         [200., 159., 105.],\n         [201., 160., 106.]],\n\n        ...,\n\n        [[245., 212., 169.],\n         [244., 211., 168.],\n         [241., 208., 165.],\n         ...,\n         [105.,  75.,  37.],\n         [104.,  74.,  36.],\n         [103.,  73.,  35.]],\n\n        [[243., 210., 167.],\n         [242., 209., 166.],\n         [241., 208., 165.],\n         ...,\n         [106.,  76.,  38.],\n         [105.,  75.,  37.],\n         [105.,  75.,  37.]],\n\n        [[249., 216., 173.],\n         [248., 215., 172.],\n         [248., 215., 172.],\n         ...,\n         [106.,  76.,  38.],\n         [106.,  76.,  38.],\n         [106.,  76.,  38.]]],\n\n\n       [[[ 90.,  29.,   8.],\n         [ 88.,  27.,   6.],\n         [ 93.,  33.,   9.],\n         ...,\n         [145.,  86.,  56.],\n         [130.,  73.,  43.],\n         [119.,  62.,  32.]],\n\n        [[102.,  41.,  20.],\n         [ 91.,  31.,   7.],\n         [ 87.,  27.,   3.],\n         ...,\n         [143.,  84.,  54.],\n         [129.,  72.,  42.],\n         [118.,  61.,  31.]],\n\n        [[108.,  48.,  24.],\n         [ 90.,  30.,   6.],\n         [ 85.,  23.,   0.],\n         ...,\n         [140.,  83.,  54.],\n         [130.,  73.,  43.],\n         [118.,  61.,  31.]],\n\n        ...,\n\n        [[ 72.,   2.,   0.],\n         [ 72.,   2.,   0.],\n         [ 73.,   3.,   1.],\n         ...,\n         [ 84.,  30.,  30.],\n         [ 98.,  44.,  44.],\n         [107.,  53.,  53.]],\n\n        [[ 72.,   2.,   0.],\n         [ 72.,   2.,   0.],\n         [ 73.,   3.,   1.],\n         ...,\n         [ 84.,  30.,  30.],\n         [100.,  46.,  46.],\n         [110.,  56.,  56.]],\n\n        [[ 72.,   2.,   0.],\n         [ 72.,   2.,   0.],\n         [ 72.,   2.,   0.],\n         ...,\n         [ 84.,  30.,  30.],\n         [101.,  47.,  47.],\n         [112.,  58.,  58.]]],\n\n\n       [[[221., 138., 120.],\n         [224., 141., 123.],\n         [226., 143., 125.],\n         ...,\n         [228., 168., 144.],\n         [227., 166., 145.],\n         [226., 165., 144.]],\n\n        [[218., 135., 117.],\n         [223., 140., 122.],\n         [228., 145., 127.],\n         ...,\n         [227., 167., 143.],\n         [225., 164., 143.],\n         [224., 163., 142.]],\n\n        [[217., 134., 118.],\n         [224., 141., 125.],\n         [231., 148., 132.],\n         ...,\n         [225., 165., 141.],\n         [223., 162., 141.],\n         [221., 160., 139.]],\n\n        ...,\n\n        [[121.,  81.,  56.],\n         [123.,  83.,  58.],\n         [124.,  83.,  61.],\n         ...,\n         [123.,  81.,  59.],\n         [122.,  80.,  56.],\n         [121.,  79.,  55.]],\n\n        [[120.,  82.,  59.],\n         [121.,  83.,  60.],\n         [122.,  84.,  61.],\n         ...,\n         [120.,  78.,  54.],\n         [118.,  76.,  52.],\n         [118.,  76.,  52.]],\n\n        [[121.,  83.,  60.],\n         [122.,  84.,  61.],\n         [122.,  84.,  61.],\n         ...,\n         [119.,  77.,  53.],\n         [118.,  76.,  52.],\n         [117.,  75.,  51.]]]], dtype=float32)>,) and kwargs: {} for signature: (*, keras_tensor_312: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_312')) -> Dict[['output_0', TensorSpec(shape=(None, 1), dtype=tf.float32, name='output_0')]].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(inference_times), throughput\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# # Measure inference time for both models\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m original_avg_time, original_throughput \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_inference_time\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m optimized_avg_time, optimized_throughput \u001b[38;5;241m=\u001b[39m measure_inference_time(\n\u001b[1;32m     45\u001b[0m     optimized_model, X_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m     46\u001b[0m )\n",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m, in \u001b[0;36mmeasure_inference_time\u001b[0;34m(model, X_test, batch_size, trials)\u001b[0m\n\u001b[1;32m     20\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(batch_images) \u001b[38;5;66;03m# Ensure the batch is in tensor format\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Run inference for the batch\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Perform inference directly\u001b[39;00m\n\u001b[1;32m     25\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     26\u001b[0m inference_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1170\u001b[0m, in \u001b[0;36mConcreteFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the wrapped function.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \n\u001b[1;32m   1123\u001b[0m \u001b[38;5;124;03m  ConcreteFunctions have two signatures:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;124;03m    TypeError: If the arguments do not match the function's signature.\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1182\u001b[0m, in \u001b[0;36mConcreteFunction._call_impl\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m structured_err:\n\u001b[1;32m   1181\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_flat_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m flat_err:\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(  \u001b[38;5;66;03m# pylint: disable=raise-missing-from\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;28mstr\u001b[39m(structured_err)\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFallback to flat signature also failed due to: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(flat_err)\n\u001b[1;32m   1188\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1242\u001b[0m, in \u001b[0;36mConcreteFunction._call_with_flat_signature\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1238\u001b[0m       arg, (tensor_lib\u001b[38;5;241m.\u001b[39mTensor, resource_variable_ops\u001b[38;5;241m.\u001b[39mBaseResourceVariable)):\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_signature_summary()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: expected argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1240\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(zero-based) to be a Tensor; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1241\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py:146\u001b[0m, in \u001b[0;36m_WrapperFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# cross-replica context\u001b[39;00m\n\u001b[1;32m    145\u001b[0m   captured_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(get_unused_handle, captured_inputs))\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "original_model = tf.saved_model.load('../best_model/model1/best_f1score_fold')\n",
    "optimized_model = tf.saved_model.load('../tensorRT_model/test_INT8')\n",
    "\n",
    "\n",
    "def measure_inference_time(model, X_test, batch_size, trials=500):\n",
    "    inference_times = []\n",
    "\n",
    "    print(f\"Running {trials} inference trials on {len(X_test)} test images...\")\n",
    "    num_batches = len(X_test) // batch_size\n",
    "\n",
    "    for i in range(trials):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Loop over the batches of X_test\n",
    "        for j in range(num_batches):\n",
    "            batch_start = j * batch_size\n",
    "            batch_end = (j + 1) * batch_size\n",
    "            batch_images = X_test[batch_start:batch_end]  # Get a batch of images\n",
    "            inputs = tf.convert_to_tensor(batch_images) # Ensure the batch is in tensor format\n",
    "\n",
    "            # Run inference for the batch\n",
    "            model.signatures[\"serving_default\"](inputs)  # Perform inference directly\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        inference_time = end_time - start_time\n",
    "        inference_times.append(inference_time)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            avg_inference = np.mean(inference_times)  # Average inference time per trial\n",
    "            print(f\"Step {i}: average inference time = {avg_inference:.6f} seconds\")\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    # Compute throughput (images per second)\n",
    "    total_time = np.sum(inference_times)\n",
    "    throughput = (trials * len(X_test)) / total_time\n",
    "    return np.mean(inference_times), throughput\n",
    "\n",
    "# # Measure inference time for both models\n",
    "original_avg_time, original_throughput = measure_inference_time(\n",
    "    original_model, X_test, batch_size=batch_size\n",
    ")\n",
    "optimized_avg_time, optimized_throughput = measure_inference_time(\n",
    "    optimized_model, X_test, batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Optimized Model - Average Inference Time: 0.043120 seconds\n",
      "Optimized Model - Throughput: 1066.78 images/second\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nResults:\")\n",
    "print(f\"Original Model - Average Inference Time: {original_avg_time:.6f} seconds\")\n",
    "print(f\"Original Model - Throughput: {original_throughput:.2f} images/second\")\n",
    "print(f\"Optimized Model - Average Inference Time: {optimized_avg_time:.6f} seconds\")\n",
    "print(f\"Optimized Model - Throughput: {optimized_throughput:.2f} images/second\")\n",
    "\n",
    "# Compute speedup\n",
    "speedup_factor = original_avg_time / optimized_avg_time\n",
    "print(f\"\\nSpeedup Factor: {speedup_factor:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Metrics on Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating metrics on 46 test images...\n",
      "Metrics: {'accuracy': 0.5652173913043478, 'precision': 0.6071428571428571, 'recall': 0.6538461538461539, 'f1_score': 0.6296296296296297}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load models\n",
    "original_model = tf.saved_model.load('../best_model/model1/best_f1score_fold')\n",
    "# optimized_model = tf.saved_model.load('../tensorRT_model/test_INT8')\n",
    "\n",
    "def measure_metrics(model, X_test, Y_test, batch_size):\n",
    "    print(f\"Evaluating metrics on {len(X_test)} test images...\")\n",
    "    \n",
    "    num_batches = len(X_test) // batch_size\n",
    "    all_predicted_classes = []\n",
    "\n",
    "    # Loop over the test dataset in batches\n",
    "    for j in range(num_batches):\n",
    "        batch_start = j * batch_size\n",
    "        batch_end = (j + 1) * batch_size\n",
    "        batch_images = X_test[batch_start:batch_end]\n",
    "        inputs = tf.convert_to_tensor(batch_images)  # Convert batch to tensor\n",
    "\n",
    "        # Run predictions\n",
    "        result = model.signatures[\"serving_default\"](inputs)  # Inference\n",
    "        prediction_logits = result[\"output_0\"].numpy()  # Extract logits\n",
    "        probabilities = tf.nn.sigmoid(prediction_logits).numpy()  # Apply sigmoid\n",
    "        predicted_classes = (probabilities > 0.5).astype(int)  # Threshold for binary classification\n",
    "\n",
    "        # Collect predictions\n",
    "        all_predicted_classes.extend(predicted_classes)\n",
    "\n",
    "    # Handle any remaining images that don't fit evenly in batches\n",
    "    remaining_samples = len(X_test) % batch_size\n",
    "    if remaining_samples > 0:\n",
    "        batch_images = X_test[-remaining_samples:]\n",
    "        inputs = tf.convert_to_tensor(batch_images)\n",
    "        result = model.signatures[\"serving_default\"](inputs)\n",
    "        prediction_logits = result[\"output_0\"].numpy()\n",
    "        probabilities = tf.nn.sigmoid(prediction_logits).numpy()\n",
    "        predicted_classes = (probabilities > 0.5).astype(int)\n",
    "        all_predicted_classes.extend(predicted_classes)\n",
    "\n",
    "    # Flatten predictions and labels to ensure they are 1D arrays\n",
    "    all_predicted_classes = np.array(all_predicted_classes).flatten()\n",
    "    Y_test = np.array(Y_test).flatten()\n",
    "\n",
    "    # Ensure the number of predictions matches the number of ground truth labels\n",
    "    if len(all_predicted_classes) != len(Y_test):\n",
    "        raise ValueError(f\"Number of predicted classes ({len(all_predicted_classes)}) \"\n",
    "                         f\"does not match the number of ground truth labels ({len(Y_test)}).\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(Y_test, all_predicted_classes)\n",
    "    precision = precision_score(Y_test, all_predicted_classes, average=\"binary\")\n",
    "    recall = recall_score(Y_test, all_predicted_classes, average=\"binary\")\n",
    "    f1 = f1_score(Y_test, all_predicted_classes, average=\"binary\")\n",
    "\n",
    "    # Output metrics\n",
    "    metrics_dict = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "    print(f\"Metrics: {metrics_dict}\")\n",
    "    return metrics_dict\n",
    "\n",
    "# Measure metrics for both models\n",
    "original_metrics = measure_metrics(\n",
    "    model=original_model, \n",
    "    X_test=X_test, \n",
    "    Y_test=Y_test, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# optimized_metrics = measure_metrics(\n",
    "#     model=optimized_model, \n",
    "#     X_test=X_test, \n",
    "#     Y_test=Y_test, \n",
    "#     batch_size=batch_size\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Metrics:\n",
      "Metric       Original Model  Optimized Model\n",
      "------------------------------------------\n",
      "accuracy     0.5000          0.5000         \n",
      "precision    0.5517          0.5517         \n",
      "recall       0.6154          0.6154         \n",
      "f1_score     0.5818          0.5818         \n",
      "\n",
      "Summary of Changes:\n",
      "accuracy     Change: 0.0000\n",
      "precision    Change: 0.0000\n",
      "recall       Change: 0.0000\n",
      "f1_score     Change: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparison of Metrics:\")\n",
    "print(f\"{'Metric':<12} {'Original Model':<15} {'Optimized Model':<15}\")\n",
    "print(\"-\" * 42)\n",
    "for metric in original_metrics.keys():\n",
    "    print(f\"{metric:<12} {original_metrics[metric]:<15.4f} {optimized_metrics[metric]:<15.4f}\")\n",
    "\n",
    "# Highlighting model differences\n",
    "print(\"\\nSummary of Changes:\")\n",
    "for metric in original_metrics.keys():\n",
    "    change = optimized_metrics[metric] - original_metrics[metric]\n",
    "    print(f\"{metric:<12} Change: {change:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the optimized TensorRT model\n",
    "# saved_model_loaded = tf.saved_model.load('path/to/save/tensorrt_model')\n",
    "# infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "# # Example input data (adjust as per your model's input requirements)\n",
    "# input_tensor = tf.convert_to_tensor(your_input_data)\n",
    "\n",
    "# # Run inference\n",
    "# output = infer(input_tensor)\n",
    "\n",
    "# # Process output as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
