{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 17:42:26.817391: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-31 17:42:26.900256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-31 17:42:26.930681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-31 17:42:26.941767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-31 17:42:26.995435: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-31 17:42:27.570512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with MonkeyPox Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"../data/MSLD/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "batch_size = 16         # size of the batch that will be fed to model\n",
    "\n",
    "# folds = the amount of folds that will be created for cross-validation\n",
    "# fine_tune_epochs = number of epochs after which we start fine-tuning\n",
    "# fine_tune_at = layer number where we start unfreezing layers\n",
    "\n",
    "# configurations that will be used in training\n",
    "# supported models: mobilenet_v2, efficientnet_v2, inception_v3, resnet_50\n",
    "# mobilenet (contains 154 layers)\n",
    "# efficientnet_v2 (contains 513 layers)\n",
    "# inception_v3 (contains 311 layers)\n",
    "# resnet_50 (contains 175 layers)\n",
    "configs = [\n",
    "    {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    # {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": True, \"fine_tune_epochs\": 25, \"fine_tune_at\": 148},\n",
    "    # {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    # {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": True, \"fine_tune_epochs\": 25, \"fine_tune_at\": 148},\n",
    "\n",
    "    # {\"model_name\": \"efficientnet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    \n",
    "    # {\"model_name\": \"densenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "\n",
    "    # {\"model_name\": \"inceptionv3\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "\n",
    "    # {\"model_name\": \"resnet50\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "\n",
    "    # {\"model_name\": \"vgg16\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 15\n",
    "\n",
    "    # {\"model_name\": \"xception\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "]\n",
    "\n",
    "# Define the base path for saving models\n",
    "save_dir = \"../saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset without splitting\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,                                  # loads images from the data_root directory\n",
    "    image_size=(img_height, img_width),         # resizes all images to (224, 224) pixels\n",
    "    batch_size=batch_size,                      # set the batch size\n",
    "    shuffle=True                                # shufle data when loaded\n",
    ")\n",
    "\n",
    "class_names = np.array(dataset.class_names)     # get the class names for the data\n",
    "num_classes = len(class_names)                  # get the number of classes in the dataset\n",
    "\n",
    "# convert the dataset to a list of (image, label) pairs. This makes it easier to perform cross-validation\n",
    "image_paths, labels = [], []\n",
    "for image_batch, label_batch in dataset:\n",
    "    image_paths.extend(image_batch.numpy())\n",
    "    labels.extend(label_batch.numpy())\n",
    "\n",
    "image_paths = np.array(image_paths)             # convert to numpy array to facilitate training\n",
    "labels = np.array(labels)                       # convert to numpy array to facilitate training\n",
    "\n",
    "# Split the dataset into training/validation and test sets\n",
    "train_val_images, test_images, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.10, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "def callbacks_setup(checkpoint_filepath):\n",
    "    # EarlyStopping callback configuration\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',        # monitor validation loss\n",
    "        patience=4,                # number of epochs with no improvement to stop training\n",
    "        mode = 'min',              # want to minimize what it being monitored \n",
    "        restore_best_weights=False # don't restore in EarlyStopping, handled by ModelCheckpoint\n",
    "    )\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,   # path to save weights\n",
    "        save_weights_only=True,         # only save weights instead of full model\n",
    "        monitor='val_recall',        # monitor validation loss\n",
    "        mode='max',                     # want to maximize what is being monitored\n",
    "        save_best_only=True             # save the best weights\n",
    "    )            \n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',      # monitor validation loss \n",
    "        factor=0.5,              # factor by which the learning rate will be reduced \n",
    "        patience=2,              # number of epochs with no improvement to stop training \n",
    "        mode='min',              # want to minimize what it being monitored \n",
    "        min_lr=1e-6              # lower bound on the learning rate \n",
    "    )            \n",
    "\n",
    "    return early_stopping, model_checkpoint, reduce_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, classification_report, roc_auc_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plot and save confusion matrix\n",
    "def save_confusion_matrix(true_labels, predicted_labels, class_names, save_path):\n",
    "    # Compute confusion matrix using sklearn\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "    # Plot with adjustments\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=12)\n",
    "    ax.set_ylabel(\"True label\", fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.yticks(rotation=30, ha='right')\n",
    "\n",
    "    # Prevent labels from being cut off\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and close plot\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# plot and save loss curves\n",
    "def save_loss_curve(history, save_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# compute and plot evaluation metrics (accuracy, sensitivity, specificity, F1 score)\n",
    "def save_evaluation_metrics(true_labels, predicted_labels, cm, save_path): \n",
    "\n",
    "    accuracy = np.mean(predicted_labels == true_labels)  \n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')     \n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')   \n",
    "    f1 = f1_score(true_labels, predicted_labels, average='binary')                \n",
    "    roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "    # specificity = np.mean(np.diag(cm) / (np.diag(cm) + np.sum(cm, axis=0) - np.diag(cm)))   \n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Sensitivity (Recall)\": recall,\n",
    "        # \"Specificity: specificity,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot the metrics as bars\n",
    "    bars = plt.bar(metrics.keys(), metrics.values(), color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen', 'mediumpurple'])\n",
    "\n",
    "    # Annotate each bar with the corresponding value\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.4f}', ha='center', va='bottom')  # Add metric value at the top of the bar\n",
    "\n",
    "    plt.title(\"Model Evaluation Metrics\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return metrics\n",
    "\n",
    "# save classification report\n",
    "def save_classification_report(true_labels, predicted_labels, class_names, save_path):\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(class_report)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Apply threshold of 0.5 to convert probabilities to binary predictions\n",
    "    predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')  \n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')        \n",
    "    f1 = f1_score(true_labels, predicted_labels, average='binary')                \n",
    "    auc = roc_auc_score(true_labels, predictions)                                 \n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "# Function to save metrics, loss curve, and confusion matrix for the best model\n",
    "def save_best_model_visuals(history, model, val_ds, class_names, weights_path, fold):\n",
    "    # Generate predictions for the validation set\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    val_predicted_probs = val_predictions.flatten()  # Convert 2D predictions into 1D probabilities\n",
    "    val_predicted_ids = (val_predicted_probs > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "    true_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    confusion_matrix_path = os.path.join(weights_path, \"confusion_matrix_fold.png\")\n",
    "    save_confusion_matrix(true_labels, val_predicted_ids, class_names, confusion_matrix_path)\n",
    "\n",
    "    # Loss Curve\n",
    "    loss_curve_path = os.path.join(weights_path, \"loss_curve_fold.png\")\n",
    "    save_loss_curve(history.history, loss_curve_path)\n",
    "\n",
    "    # Evaluation Metrics (Accuracy, Sensitivity, Specificity, F1 Score)\n",
    "    cm = confusion_matrix(true_labels, val_predicted_ids)\n",
    "    metrics_bar_chart_path = os.path.join(weights_path, \"evaluation_metrics_fold.png\")\n",
    "    save_evaluation_metrics(true_labels, val_predicted_ids, cm, metrics_bar_chart_path)\n",
    "\n",
    "    # Save classification report as a text file\n",
    "    classification_report_path = os.path.join(weights_path, \"classification_report_fold.txt\")\n",
    "    save_classification_report(true_labels, val_predicted_ids, class_names, classification_report_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into training/validation set for hyperparameter tuning\n",
    "# train_images_tuning, val_images_tuning, train_labels_tuning, val_labels_tuning = train_test_split(\n",
    "#     image_paths, labels, test_size=0.1, random_state=42, stratify=labels\n",
    "# )\n",
    "\n",
    "# # Define the hypermodel for hyperparameter tuning\n",
    "# def build_model(hp):\n",
    "#     base_model = tf.keras.applications.MobileNetV2(\n",
    "#         input_shape=(img_height, img_width, 3),\n",
    "#         include_top=False,\n",
    "#         weights='imagenet'\n",
    "#     )\n",
    "#     base_model.trainable = False  # Freeze layers initially\n",
    "    \n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         layers.GlobalAveragePooling2D(),\n",
    "#         layers.Dense(num_classes)\n",
    "#     ])\n",
    "\n",
    "#     # Tune hyperparameters\n",
    "#     learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "#     optimizer = hp.Choice('optimizer', values=['adam', 'sgd'])\n",
    "\n",
    "#     if optimizer == 'adam':\n",
    "#         opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     else:\n",
    "#         opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=opt,\n",
    "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Set up the tuner for hyperparameter tuning\n",
    "# tuner = kt.RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',  # Optimize for validation accuracy\n",
    "#     max_trials=10,             # Try 10 different hyperparameter combinations\n",
    "#     executions_per_trial=1,    # Run each combination once\n",
    "#     directory='hyperparameter_tuning',\n",
    "#     project_name='best_hyperparams_tuning'\n",
    "# )\n",
    "\n",
    "# # Prepare TensorFlow datasets for training and validation\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((train_images_tuning, train_labels_tuning)).batch(batch_size)\n",
    "# val_ds = tf.data.Dataset.from_tensor_slices((val_images_tuning, val_labels_tuning)).batch(batch_size)\n",
    "\n",
    "# # Perform the hyperparameter search on the validation set\n",
    "# tuner.search(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "# # Get the best hyperparameters after the search\n",
    "# best_hyperparams = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# # Print the best hyperparameters\n",
    "# print(f\"Best Hyperparameters: {best_hyperparams.values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation and fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and compile the model\n",
    "def create_model(num_classes, config, fine_tune=None):\n",
    "    # if you are not fine tuning the model, instantiate a new model \n",
    "    if(fine_tune == False):         \n",
    "\n",
    "        model_name = config[\"model_name\"]\n",
    "\n",
    "        if model_name == \"mobilenet\":\n",
    "            base_model = tf.keras.applications.MobileNetV2\n",
    "        elif model_name == \"efficientnet\":\n",
    "            base_model = tf.keras.applications.EfficientNetB3\n",
    "        elif model_name == \"densenet\":\n",
    "            base_model = tf.keras.applications.DenseNet121\n",
    "        elif model_name == \"inceptionv3\":\n",
    "            base_model = tf.keras.applications.InceptionV3\n",
    "        elif model_name == \"resnet50\":\n",
    "            base_model = tf.keras.applications.ResNet50\n",
    "        elif model_name == \"vgg16\":\n",
    "            base_model = tf.keras.applications.VGG16\n",
    "        elif model_name == \"xception\":\n",
    "            base_model = tf.keras.applications.Xception\n",
    "        else:\n",
    "            raise ValueError(f\"Model name '{model_name}' is not supported.\")\n",
    "\n",
    "\n",
    "        # instantiate mobilenet (contains 154 layers)\n",
    "        base_model = base_model(\n",
    "            input_shape=(img_height, img_width, 3),     # set the input it will receive\n",
    "            include_top=False,                          # do not include top layer to perform transfer learning\n",
    "            weights='imagenet'                          # load weights from imagenet dataset\n",
    "        )\n",
    "        base_model.trainable = False                    # Freeze the base model\n",
    "        # print(len(base_model.layers))\n",
    "        # add a layer in order to perform classification on our dataset\n",
    "        model = Sequential([\n",
    "            base_model,                         # use base_model as the start of your model\n",
    "            layers.GlobalAveragePooling2D(),    # add a final layer to perform classification\n",
    "            layers.Dense(1)                     # set the number of possible prediction to the num of classes in dataset for multiclass classification and 1 for binary classification\n",
    "        ])\n",
    "        \n",
    "    # select optimizer and learning rate based on configuration\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fine tune model by unfreezing the layers after the first fine_tune_at layers\n",
    "def fine_tune_model(base_model, fine_tune_at):\n",
    "    # Unfreeze the layers starting from fine_tune_at index\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = []      # list to save training metrics\n",
    "val_metrics = []        # list to save validation metrics\n",
    "normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).batch(32)\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"Training model {i + 1}/{len(configs)} with config: {config}\")\n",
    "\n",
    "    # K-fold Cross Validation\n",
    "    kfold = StratifiedKFold(n_splits=config['folds'], shuffle=True, random_state=42)\n",
    "    best_val_f1score = -float('inf')            # Initialize best F1 score with a very low value\n",
    "\n",
    "    # Define the base path for saving models\n",
    "    model_subdir = os.path.join(save_dir, f'model{i + 1}')\n",
    "    os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving checkpoints for model\n",
    "    checkpoint_folder = os.path.join(model_subdir, 'checkpoints')\n",
    "    os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving cthe model with the best f1-score\n",
    "    best_f1_dir = os.path.join(model_subdir, 'best_f1score_fold')\n",
    "    os.makedirs(best_f1_dir, exist_ok=True)\n",
    "    \n",
    "    # Training and validation loop for each fold\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kfold.split(train_val_images, train_val_labels):\n",
    "        print(f\"\\nFold {fold}/{config['folds']}...\")\n",
    "\n",
    "        checkpoint_filepath = os.path.join(checkpoint_folder, f'checkpoint_fold{fold}.weights.h5')\n",
    "\n",
    "        # Create subset datasets for training and validation\n",
    "        train_images, train_labels = train_val_images[train_idx], train_val_labels[train_idx]\n",
    "        val_images, val_labels = train_val_images[val_idx], train_val_labels[val_idx]\n",
    "\n",
    "        # Convert NumPy arrays back to TensorFlow datasets\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "        val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "\n",
    "        # Normalize datasets \n",
    "        normalization_layer = layers.Rescaling(1./255)\n",
    "        train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "        # prefetch data to improve performance by overlapping data preprocessing and model execution and cache the dataset in memory and batch\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        train_ds = train_ds.batch(batch_size).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        val_ds = val_ds.batch(batch_size).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        # Step 1: Train model with frozen layers\n",
    "        print(f\"Training with frozen base layers for {config['epochs']} epochs...\")\n",
    "\n",
    "        # Create and compile model for each fold\n",
    "        model = create_model(num_classes, config, fine_tune=False) \n",
    "\n",
    "        # setup callbacks \n",
    "        early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "\n",
    "        # train the model on the training set until the epochs specified\n",
    "        history_frozen = model.fit(\n",
    "            train_ds,                                       # dataset used for training\n",
    "            validation_data=val_ds,                         # dataset used for validation\n",
    "            epochs=config['epochs'],                        # epochs used for training\n",
    "            callbacks=[early_stopping, model_checkpoint, reduce_lr],   # set early stopping to avoid overfitting\n",
    "            verbose=1\n",
    "        ) \n",
    "\n",
    "        # load the best weights from ModelCheckpoint after training\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        if(config[\"fine_tune\"] == True):\n",
    "            # Step 2: Unfreeze layers and fine-tune\n",
    "            print(f\"Unfreezing layers starting from layer {config['fine_tune_at']} for fine-tuning...\")\n",
    "            fine_tune_model(model.layers[0], config['fine_tune_at'])      # fine tune model\n",
    "\n",
    "            # re-compile the model with a lower learning rate for fine-tuning\n",
    "            fine_tune_lr = config['learning_rate'] * 0.01\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
    "            )\n",
    "                \n",
    "            print(f\"Fine-tuning for {config['fine_tune_epochs']} epochs...\")\n",
    "\n",
    "            # setup callbacks again for fine-tuning phase with a unique checkpoint\n",
    "            early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "            \n",
    "            history_fine_tune = model.fit(\n",
    "                train_ds,                                       # dataset used for training\n",
    "                validation_data=val_ds,                         # dataset used for validation\n",
    "                epochs=config['fine_tune_epochs'],                        # epochs used for training\n",
    "                callbacks=[early_stopping, model_checkpoint, reduce_lr],   # set early stopping to avoid overfitting\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # load weights after fine-tuning\n",
    "            model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        # evaluate on validation set after training\n",
    "        val_predictions = model.predict(val_ds)\n",
    "        avg_val_loss = model.evaluate(val_ds, verbose=0)[0]\n",
    "        avg_val_accuracy, avg_val_precision, avg_val_recall, avg_val_f1, avg_val_auc = calculate_metrics(\n",
    "            np.concatenate([y for x, y in val_ds]), val_predictions\n",
    "        )\n",
    "\n",
    "        print(f\"\\nValidation: \\tFold {fold} - Loss: {avg_val_loss:.4f}, Accuracy: {avg_val_accuracy:.4f}, Precision: {avg_val_precision:.4f}, Recall: {avg_val_recall:.4f}, F1 Score: {avg_val_f1:.4f}, ROC AUC Score: {avg_val_auc:.4f}\")\n",
    "\n",
    "        test_predictions = model.predict(test_ds)\n",
    "        predicted_labels = np.argmax(test_predictions, axis=-1)\n",
    "        true_labels = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "\n",
    "        avg_test_f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "        # save the best model based on validation F1 score\n",
    "        if avg_test_f1 > best_val_f1score:\n",
    "            best_val_f1score = avg_test_f1\n",
    "\n",
    "            # Save model in TensorFlow SavedModel format (for TensorRT compatibility)\n",
    "            # model.save(best_f1_dir)\n",
    "            # tf.saved_model.save(model, best_f1_dir)\n",
    "            model.export(best_f1_dir)\n",
    "            print(f\"Model with best F1 score during Validation saved at Fold {fold} with F1 Score of {best_val_f1score:.4f}\")\n",
    "\n",
    "            if (config['save_metrics'] == True):\n",
    "                #save confusion matrix, loss curve, evaluation metrics for the best model\n",
    "                history = history_frozen\n",
    "                save_best_model_visuals(history, model, test_ds, class_names, model_subdir, fold)\n",
    "\n",
    "        fold += 1       # Move to the next fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, config in enumerate(configs):\n",
    "    # model = tf.keras.models.load_model(f'../saved_models/model{i+1}/best_f1score_fold')\n",
    "\n",
    "    # Load the SavedModel using TFSMLayer, treating it as a Keras layer\n",
    "    model_layer = tf.keras.layers.TFSMLayer(f'../saved_models/model{i+1}/best_f1score_fold', call_endpoint='serving_default')\n",
    "    \n",
    "    # Wrap the TFSMLayer in a Sequential model for inference\n",
    "    model = tf.keras.Sequential([model_layer])\n",
    "\n",
    "    # once training is complete, evaluate on the held-out test set\n",
    "    print(f\"Evaluating the best model for model{i+1} on the held-out test set...\")\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "    test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).batch(batch_size)\n",
    "\n",
    "    test_predictions = model.predict(test_ds)\n",
    "\n",
    "    # Print the shape and type of predictions for debugging\n",
    "    # print(f\"Predictions shape: {len(test_predictions['output_0'])}, type: {type(test_predictions)}\")\n",
    "    # print(f\"First few predictions: {test_predictions[:5]}\")  # Check the first few predictions\n",
    "\n",
    "    # avg_test_loss = model.evaluate(test_ds, verbose=0)[0]\n",
    "    avg_test_accuracy, avg_test_precision, avg_test_recall, avg_test_f1, avg_test_auc = calculate_metrics(\n",
    "        np.concatenate([y for x, y in test_ds]), test_predictions['output_0']\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTest Set Evaluation - Accuracy: {avg_test_accuracy:.4f}, Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1 Score: {avg_test_f1:.4f}, AUC Score: {avg_test_auc:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
