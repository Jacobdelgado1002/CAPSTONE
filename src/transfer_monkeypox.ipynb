{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "import tf_keras as tfk                          # needed due to incompatability with tensorflow_hub version\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"      # mobileNetV2\n",
    "# inception_v3 = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"        # inceptionNetV3\n",
    "\n",
    "classifier_model = mobilenet_v2     # choose model that will be used for transfer learning\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)            # shape of the images that will be used\n",
    "\n",
    "# instantiate classifier model\n",
    "classifier = tfk.Sequential([\n",
    "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))  # Specifies the input shape as (224, 224, 3) to match the 3 channels (RGB)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_6 (KerasLayer)  (None, 1001)              3540265   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3540265 (13.51 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 3540265 (13.51 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()    # summary of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['matchstick', 'maypole', 'maze', 'measuring cup', 'medicine chest',\n",
       "       'megalith', 'microphone', 'microwave', 'military uniform',\n",
       "       'milk can'], dtype='<U30')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import imageNet labels (dataset that mobileNet was originally trained on)\n",
    "labels_path = tfk.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "imagenet_labels[645:655]    # A quick check to inspect some labels from the file and make sure it was imported correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with MonkeyPox Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_root = pathlib.Path(\"../data/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validations datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3192 files belonging to 2 classes.\n",
      "Using 2554 files for training.\n",
      "Found 3192 files belonging to 2 classes.\n",
      "Using 638 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),                         # loads images from the data_root directory\n",
    "  validation_split=0.2,                   # the dataset is split into training and validation sets using an 80-20 split\n",
    "  subset=\"training\",                      # set this as the training split\n",
    "  seed=123,                               # sets a seed for reproducibility in splitting the data\n",
    "  image_size=(img_height, img_width),     # resizes all images to (224, 224) pixels\n",
    "  batch_size=batch_size\n",
    ")\n",
    "# validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),                         # loads images from the data_root directory\n",
    "  validation_split=0.2,                   # the dataset is split into training and validation sets using an 80-20 split\n",
    "  subset=\"validation\",                    # set this as the validation split\n",
    "  seed=123,                               # sets a seed for reproducibility in splitting the data\n",
    "  image_size=(img_height, img_width),     # resizes all images to (224, 224) pixels\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monkeypox' 'Others']\n"
     ]
    }
   ],
   "source": [
    "class_names = np.array(train_ds.class_names)    # class labels for Monkeypox dataset\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing before transfer learning is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)           # normalize pixel values of images from [0, 255] to [0, 1] by dividing\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # normalize training split where x—images, y—labels.\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))     # normalize validation split where x—images, y—labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "# prefetch data to improve performance by overlapping data preprocessing and model execution and cache the dataset in memory\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# sanity check by iterating through the train_ds dataset to inspect the shapes of the images and labels in a batch\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the pre-trained MobileNetV2 model to make predictions on the training dataset before transfer learning\n",
    "result_batch = classifier.predict(train_ds)\n",
    "\n",
    "# find the index of the highest predicted value for each image and match it with the image\n",
    "predicted_class_names = imagenet_labels[tf.math.argmax(result_batch, axis=-1)]  \n",
    "predicted_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of predictions made by the model before transfer learning\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  plt.title(predicted_class_names[n])\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"ImageNet predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model without final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 from tf.keras.applications \n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Create the model\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "# plot and save confusion matrix\n",
    "def save_confusion_matrix(true_labels, predicted_labels, class_names, save_path):\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# plot and save loss curves\n",
    "def save_loss_curve(history, save_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# compute and plot evaluation metrics (accuracy, sensitivity, specificity, F1 score)\n",
    "def save_evaluation_metrics(true_labels, predicted_labels, history, cm, save_path):\n",
    "    accuracy = history['val_accuracy'][-1]\n",
    "    sensitivity = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    specificity = np.mean(np.diag(cm) / (np.diag(cm) + np.sum(cm, axis=0) - np.diag(cm)))\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Sensitivity (Recall)\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(metrics.keys(), metrics.values(), color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen'])\n",
    "    plt.title(\"Model Evaluation Metrics\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return metrics\n",
    "\n",
    "# save classification report\n",
    "def save_classification_report(true_labels, predicted_labels, class_names, save_path):\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/1 with config: {'learning_rate': 0.001, 'optimizer': 'adam', 'epochs': 14, 'save_metrics': False}\n",
      "Epoch 1/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 261ms/step - accuracy: 0.6733 - loss: 0.6183 - val_accuracy: 0.8323 - val_loss: 0.3728\n",
      "Epoch 2/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 230ms/step - accuracy: 0.8579 - loss: 0.3449 - val_accuracy: 0.8511 - val_loss: 0.3221\n",
      "Epoch 3/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 230ms/step - accuracy: 0.8958 - loss: 0.2850 - val_accuracy: 0.8699 - val_loss: 0.2945\n",
      "Epoch 4/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 232ms/step - accuracy: 0.9114 - loss: 0.2493 - val_accuracy: 0.8762 - val_loss: 0.2765\n",
      "Epoch 5/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 230ms/step - accuracy: 0.9238 - loss: 0.2245 - val_accuracy: 0.8871 - val_loss: 0.2637\n",
      "Epoch 6/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 231ms/step - accuracy: 0.9332 - loss: 0.2059 - val_accuracy: 0.8934 - val_loss: 0.2542\n",
      "Epoch 7/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 230ms/step - accuracy: 0.9393 - loss: 0.1910 - val_accuracy: 0.8934 - val_loss: 0.2469\n",
      "Epoch 8/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 228ms/step - accuracy: 0.9454 - loss: 0.1788 - val_accuracy: 0.8997 - val_loss: 0.2413\n",
      "Epoch 9/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 229ms/step - accuracy: 0.9503 - loss: 0.1685 - val_accuracy: 0.9044 - val_loss: 0.2369\n",
      "Epoch 10/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 239ms/step - accuracy: 0.9541 - loss: 0.1595 - val_accuracy: 0.9091 - val_loss: 0.2335\n",
      "Epoch 11/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 443ms/step - accuracy: 0.9563 - loss: 0.1516 - val_accuracy: 0.9107 - val_loss: 0.2307\n",
      "Epoch 12/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 226ms/step - accuracy: 0.9572 - loss: 0.1446 - val_accuracy: 0.9107 - val_loss: 0.2286\n",
      "Epoch 13/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 228ms/step - accuracy: 0.9589 - loss: 0.1382 - val_accuracy: 0.9138 - val_loss: 0.2269\n",
      "Epoch 14/14\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 225ms/step - accuracy: 0.9610 - loss: 0.1324 - val_accuracy: 0.9138 - val_loss: 0.2257\n",
      "Model 1 finished training\n",
      "\n",
      "Models ranked by validation accuracy:\n",
      "Model 1: Config: {'learning_rate': 0.001, 'optimizer': 'adam', 'epochs': 14, 'save_metrics': False}, Validation Accuracy: 0.9138\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the base path for saving models\n",
    "save_dir = \"../saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# List to store accuracy results for comparison\n",
    "model_performance = []\n",
    "\n",
    "# Parameters\n",
    "NUM_MODELS = 1\n",
    "# NUM_EPOCHS = 14  # Or any number of epochs you prefer\n",
    "\n",
    "# TODO: Add function for custom configurations (eg. different optimizer, learning rate, etc.)\n",
    "\n",
    "# configurations that will be used in training\n",
    "configs = [\n",
    "    {\"learning_rate\": 0.001, \"optimizer\": \"adam\", \"epochs\": 14, \"save_metrics\": False},\n",
    "    # {\"learning_rate\": 0.0001, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": False},\n",
    "    # {\"learning_rate\": 0.001, \"optimizer\": \"sgd\", \"epochs\": 50, \"save_metrics\": False},\n",
    "    # {\"learning_rate\": 0.0001, \"optimizer\": \"sgd\", \"epochs\": 50, \"save_metrics\": False},\n",
    "]\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"Training model {i + 1}/{len(configs)} with config: {config}\")\n",
    "\n",
    "    # Recreate the model architecture for each loop iteration\n",
    "    # feature_extractor_layer = hub.KerasLayer(\n",
    "    #     feature_extractor_model,\n",
    "    #     input_shape=(224, 224, 3),\n",
    "    #     trainable=False)\n",
    "\n",
    "    # model = tfk.Sequential([\n",
    "    #     feature_extractor_layer,\n",
    "    #     tfk.layers.Dense(num_classes)\n",
    "    # ])\n",
    "\n",
    "    # Recreate the model architecture for each loop iteration\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    # model.compile(\n",
    "    #     optimizer=tfk.optimizers.Adam(),\n",
    "    #     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    #     metrics=['accuracy'])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Select optimizer based on configuration\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=config[\"epochs\"])\n",
    "    \n",
    "    if(config[\"save_metrics\"] == True):\n",
    "\n",
    "        # Create subdirectory for this model\n",
    "        model_subdir = os.path.join(save_dir, f\"model_{i + 1}\")\n",
    "        os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "        # Save the model\n",
    "        model_path = os.path.join(model_subdir, f\"model_{i + 1}.h5\")\n",
    "        model.save(model_path)\n",
    "        \n",
    "        # Save training history for analysis later\n",
    "        history_path = os.path.join(model_subdir, f\"history_{i + 1}.npy\")\n",
    "        np.save(history_path, history.history)\n",
    "\n",
    "        # Save metrics and plots as PNGs\n",
    "\n",
    "        # Predictions and true labels\n",
    "        val_predictions = model.predict(val_ds)\n",
    "        val_predicted_ids = np.argmax(val_predictions, axis=-1)\n",
    "        true_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "        # Save confusion matrix\n",
    "        confusion_matrix_path = os.path.join(model_subdir, \"confusion_matrix.png\")\n",
    "        save_confusion_matrix(true_labels, val_predicted_ids, class_names, confusion_matrix_path)\n",
    "\n",
    "        # Plot and save loss curve\n",
    "        loss_curve_path = os.path.join(model_subdir, \"loss_curve.png\")\n",
    "        save_loss_curve(history.history, loss_curve_path)\n",
    "\n",
    "        # Calculate and plot metrics\n",
    "        cm = confusion_matrix(true_labels, val_predicted_ids)\n",
    "        bar_chart_path = os.path.join(model_subdir, \"evaluation_metrics.png\")\n",
    "        save_evaluation_metrics(true_labels, val_predicted_ids, history.history, cm, bar_chart_path)\n",
    "\n",
    "        # Save classification report\n",
    "        classification_report_path = os.path.join(model_subdir, \"classification_report.txt\")\n",
    "        save_classification_report(true_labels, val_predicted_ids, class_names, classification_report_path)\n",
    "\n",
    "    # Record the final validation accuracy for comparison\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    model_performance.append({\n",
    "        \"model_path\": model_path,\n",
    "        \"config\": config,\n",
    "        \"validation_accuracy\": final_val_acc\n",
    "    })\n",
    "\n",
    "    print(f\"Model {i + 1} finished training\")\n",
    "\n",
    "\n",
    "# After the loop, print out the results for comparison\n",
    "model_performance.sort(key=lambda x: x['validation_accuracy'], reverse=True)\n",
    "print(\"\\nModels ranked by validation accuracy:\")\n",
    "for i, perf in enumerate(model_performance):\n",
    "    print(f\"Model {i + 1}: Config: {perf['config']}, Validation Accuracy: {perf['validation_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tfk.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "# train model\n",
    "trained_model = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]\n",
    "print(predicted_label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  plt.title(predicted_label_batch[n].title())\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
