{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "import tf_keras as tfk                          # needed due to incompatability with tensorflow_hub version\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"      # mobileNetV2\n",
    "# inception_v3 = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"        # inceptionNetV3\n",
    "\n",
    "classifier_model = mobilenet_v2     # choose model that will be used for transfer learning\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)            # shape of the images that will be used\n",
    "\n",
    "# instantiate classifier model\n",
    "classifier = tfk.Sequential([\n",
    "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))  # Specifies the input shape as (224, 224, 3) to match the 3 channels (RGB)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()    # summary of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageNet labels (dataset that mobileNet was originally trained on)\n",
    "labels_path = tfk.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "imagenet_labels[645:655]    # A quick check to inspect some labels from the file and make sure it was imported correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with MonkeyPox Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "data_root = pathlib.Path(\"../data/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validations datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3192 files belonging to 2 classes.\n",
      "Using 2554 files for training.\n",
      "Found 3192 files belonging to 2 classes.\n",
      "Using 638 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),                         # loads images from the data_root directory\n",
    "  validation_split=0.2,                   # the dataset is split into training and validation sets using an 80-20 split\n",
    "  subset=\"training\",                      # set this as the training split\n",
    "  seed=123,                               # sets a seed for reproducibility in splitting the data\n",
    "  image_size=(img_height, img_width),     # resizes all images to (224, 224) pixels\n",
    "  batch_size=batch_size\n",
    ")\n",
    "# validation dataset\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),                         # loads images from the data_root directory\n",
    "  validation_split=0.2,                   # the dataset is split into training and validation sets using an 80-20 split\n",
    "  subset=\"validation\",                    # set this as the validation split\n",
    "  seed=123,                               # sets a seed for reproducibility in splitting the data\n",
    "  image_size=(img_height, img_width),     # resizes all images to (224, 224) pixels\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monkeypox' 'Others']\n"
     ]
    }
   ],
   "source": [
    "class_names = np.array(train_ds.class_names)    # class labels for Monkeypox dataset\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing before transfer learning is performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)           # normalize pixel values of images from [0, 255] to [0, 1] by dividing\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # normalize training split where x—images, y—labels.\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))     # normalize validation split where x—images, y—labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "# prefetch data to improve performance by overlapping data preprocessing and model execution and cache the dataset in memory\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# sanity check by iterating through the train_ds dataset to inspect the shapes of the images and labels in a batch\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the pre-trained MobileNetV2 model to make predictions on the training dataset before transfer learning\n",
    "result_batch = classifier.predict(train_ds)\n",
    "\n",
    "# find the index of the highest predicted value for each image and match it with the image\n",
    "predicted_class_names = imagenet_labels[tf.math.argmax(result_batch, axis=-1)]  \n",
    "predicted_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of predictions made by the model before transfer learning\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  plt.title(predicted_class_names[n])\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"ImageNet predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model without final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"     # mobileNetV2\n",
    "# inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"     # inceptionNetV3\n",
    "\n",
    "feature_extractor_model = mobilenet_v2\n",
    "num_classes = len(class_names)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "# plot and save confusion matrix\n",
    "def save_confusion_matrix(true_labels, predicted_labels, class_names, save_path):\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# plot and save loss curves\n",
    "def save_loss_curve(history, save_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# compute and plot evaluation metrics (accuracy, sensitivity, specificity, F1 score)\n",
    "def save_evaluation_metrics(true_labels, predicted_labels, history, cm, save_path):\n",
    "    accuracy = history['val_accuracy'][-1]\n",
    "    sensitivity = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    specificity = np.mean(np.diag(cm) / (np.diag(cm) + np.sum(cm, axis=0) - np.diag(cm)))\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Sensitivity (Recall)\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(metrics.keys(), metrics.values(), color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen'])\n",
    "    plt.title(\"Model Evaluation Metrics\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return metrics\n",
    "\n",
    "# save classification report\n",
    "def save_classification_report(true_labels, predicted_labels, class_names, save_path):\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/2\n",
      "Epoch 1/2\n",
      "80/80 [==============================] - 19s 189ms/step - loss: 0.5352 - accuracy: 0.7412 - val_loss: 0.4104 - val_accuracy: 0.8119\n",
      "Epoch 2/2\n",
      "80/80 [==============================] - 14s 169ms/step - loss: 0.3522 - accuracy: 0.8489 - val_loss: 0.3341 - val_accuracy: 0.8527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\capstone\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 3s 142ms/step\n",
      "Model 1 saved to ../saved_models\\model_1\\model_1.h5 with validation accuracy: 0.8527\n",
      "Training model 2/2\n",
      "Epoch 1/2\n",
      "80/80 [==============================] - 18s 178ms/step - loss: 0.5052 - accuracy: 0.7678 - val_loss: 0.4142 - val_accuracy: 0.8245\n",
      "Epoch 2/2\n",
      "80/80 [==============================] - 23s 285ms/step - loss: 0.3446 - accuracy: 0.8551 - val_loss: 0.3430 - val_accuracy: 0.8558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\capstone\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 17s 768ms/step\n",
      "Model 2 saved to ../saved_models\\model_2\\model_2.h5 with validation accuracy: 0.8558\n",
      "\n",
      "Models ranked by validation accuracy:\n",
      "Model 1: ../saved_models\\model_2\\model_2.h5, Validation Accuracy: 0.8558\n",
      "Model 2: ../saved_models\\model_1\\model_1.h5, Validation Accuracy: 0.8527\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the base path for saving models\n",
    "save_dir = \"../saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# List to store accuracy results for comparison\n",
    "model_performance = []\n",
    "\n",
    "# Parameters\n",
    "NUM_MODELS = 2\n",
    "NUM_EPOCHS = 2  # Or any number of epochs you prefer\n",
    "\n",
    "# TODO: Add function for custom configurations (eg. different optimizer, learning rate, etc.)\n",
    "\n",
    "# configurations that will be used in training\n",
    "# configs = [\n",
    "#     {\"learning_rate\": 0.001, \"optimizer\": \"adam\", \"epochs\": 3},\n",
    "#     {\"learning_rate\": 0.0001, \"optimizer\": \"adam\", \"epochs\": 50},\n",
    "#     {\"learning_rate\": 0.001, \"optimizer\": \"sgd\", \"epochs\": 50},\n",
    "#     {\"learning_rate\": 0.0001, \"optimizer\": \"sgd\", \"epochs\": 50},\n",
    "# ]\n",
    "\n",
    "for i in range(NUM_MODELS):\n",
    "    print(f\"Training model {i + 1}/{NUM_MODELS}\")\n",
    "\n",
    "    # Create subdirectory for this model\n",
    "    model_subdir = os.path.join(save_dir, f\"model_{i + 1}\")\n",
    "    os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "    # Recreate the model architecture for each loop iteration\n",
    "    feature_extractor_layer = hub.KerasLayer(\n",
    "        feature_extractor_model,\n",
    "        input_shape=(224, 224, 3),\n",
    "        trainable=False)\n",
    "\n",
    "    model = tfk.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        tfk.layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tfk.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=NUM_EPOCHS)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = os.path.join(model_subdir, f\"model_{i + 1}.h5\")\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Save training history for analysis later\n",
    "    history_path = os.path.join(model_subdir, f\"history_{i + 1}.npy\")\n",
    "    np.save(history_path, history.history)\n",
    "\n",
    "    # Save metrics and plots as PNGs\n",
    "\n",
    "    # Predictions and true labels\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    val_predicted_ids = np.argmax(val_predictions, axis=-1)\n",
    "    true_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "    # Save confusion matrix\n",
    "    confusion_matrix_path = os.path.join(model_subdir, \"confusion_matrix.png\")\n",
    "    save_confusion_matrix(true_labels, val_predicted_ids, class_names, confusion_matrix_path)\n",
    "\n",
    "    # Plot and save loss curve\n",
    "    loss_curve_path = os.path.join(model_subdir, \"loss_curve.png\")\n",
    "    save_loss_curve(history.history, loss_curve_path)\n",
    "\n",
    "    # Calculate and plot metrics\n",
    "    cm = confusion_matrix(true_labels, val_predicted_ids)\n",
    "    bar_chart_path = os.path.join(model_subdir, \"evaluation_metrics.png\")\n",
    "    save_evaluation_metrics(true_labels, val_predicted_ids, history.history, cm, bar_chart_path)\n",
    "\n",
    "    # Save classification report\n",
    "    classification_report_path = os.path.join(model_subdir, \"classification_report.txt\")\n",
    "    save_classification_report(true_labels, val_predicted_ids, class_names, classification_report_path)\n",
    "\n",
    "    # Record the final validation accuracy for comparison\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    model_performance.append((model_path, final_val_acc))\n",
    "\n",
    "    print(f\"Model {i + 1} saved to {model_path} with validation accuracy: {final_val_acc:.4f}\")\n",
    "\n",
    "# After the loop, print out the results for comparison\n",
    "model_performance.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nModels ranked by validation accuracy:\")\n",
    "for i, (model_path, accuracy) in enumerate(model_performance):\n",
    "    print(f\"Model {i + 1}: {model_path}, Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tfk.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "# train model\n",
    "trained_model = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(image_batch)\n",
    "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]\n",
    "print(predicted_label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.imshow(image_batch[n])\n",
    "  plt.title(predicted_label_batch[n].title())\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
