{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with MonkeyPox Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"../data/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 32         # size of the batch that will be fed to model\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "NUM_MODELS = 1          # number of models that you wish to train\n",
    "\n",
    "# k-fold cross-validation parameters\n",
    "FOLDS = 5               # the amount of folds that will be created for cross-validation\n",
    "\n",
    "# Fine-tuning parameters\n",
    "FINE_TUNE_EPOCHS = 10   # number of epochs after which we start fine-tuning\n",
    "FINE_TUNE_AT = 150      # layer number where we start unfreezing layers\n",
    "\n",
    "# configurations that will be used in training\n",
    "configs = [\n",
    "    {\"learning_rate\": 0.001, \"optimizer\": \"adam\", \"epochs\": 14, \"save_metrics\": False},\n",
    "    # {\"learning_rate\": 0.0001, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": False},\n",
    "    # {\"learning_rate\": 0.001, \"optimizer\": \"sgd\", \"epochs\": 50, \"save_metrics\": False},\n",
    "    # {\"learning_rate\": 0.0001, \"optimizer\": \"sgd\", \"epochs\": 50, \"save_metrics\": False},\n",
    "]\n",
    "\n",
    "# Define the base path for saving models\n",
    "save_dir = \"../saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3192 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset without splitting\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,                                  # loads images from the data_root directory\n",
    "    image_size=(img_height, img_width),         # resizes all images to (224, 224) pixels\n",
    "    batch_size=batch_size,                      # set the batch size\n",
    "    shuffle=True                                # shufle data when loaded\n",
    ")\n",
    "\n",
    "class_names = np.array(dataset.class_names)     # get the class names for the data\n",
    "num_classes = len(class_names)                  # get the number of classes in the dataset\n",
    "\n",
    "# convert the dataset to a list of (image, label) pairs. This makes it easier to perform cross-validation\n",
    "image_paths, labels = [], []\n",
    "for image_batch, label_batch in dataset:\n",
    "    image_paths.extend(image_batch.numpy())\n",
    "    labels.extend(label_batch.numpy())\n",
    "\n",
    "image_paths = np.array(image_paths)             # convert to numpy array to facilitate training\n",
    "labels = np.array(labels)                       # convert to numpy array to facilitate training\n",
    "\n",
    "# Split the dataset into training/validation and test sets\n",
    "train_val_images, test_images, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.10, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# K-fold Cross Validation\n",
    "kfold = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "best_val_f1score = -float('inf')  # Initialize best F1 score with a very low value\n",
    "\n",
    "# Define the base path for saving models\n",
    "checkpoint_folder = \"../model_checkpoints\"\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "def callbacks_setup(checkpoint_filepath):\n",
    "    # EarlyStopping callback configuration\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',        # monitor validation loss\n",
    "        patience=3,                # number of epochs with no improvement to stop training\n",
    "        mode = 'min',              # want to minimize what it being monitored \n",
    "        restore_best_weights=False # don't restore in EarlyStopping, handled by ModelCheckpoint\n",
    "    )\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,   # path to save weights\n",
    "        save_weights_only=True,         # only save weights instead of full model\n",
    "        monitor='val_loss',             # monitor validation loss\n",
    "        mode='min',                     # want to minimize what is being monitored\n",
    "        save_best_only=True             # save the best weights\n",
    "    )            \n",
    "\n",
    "    return early_stopping, model_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, classification_report, roc_auc_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plot and save confusion matrix\n",
    "def save_confusion_matrix(true_labels, predicted_labels, class_names, save_path):\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# plot and save loss curves\n",
    "def save_loss_curve(history, save_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# compute and plot evaluation metrics (accuracy, sensitivity, specificity, F1 score)\n",
    "def save_evaluation_metrics(true_labels, predicted_labels, history, cm, save_path):\n",
    "    accuracy = history['val_accuracy'][-1]\n",
    "    sensitivity = recall_score(true_labels, predicted_labels, average='macro')\n",
    "    specificity = np.mean(np.diag(cm) / (np.diag(cm) + np.sum(cm, axis=0) - np.diag(cm)))\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Sensitivity (Recall)\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(metrics.keys(), metrics.values(), color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen'])\n",
    "    plt.title(\"Model Evaluation Metrics\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return metrics\n",
    "\n",
    "# save classification report\n",
    "def save_classification_report(true_labels, predicted_labels, class_names, save_path):\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(class_report)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    accuracy = np.mean(np.argmax(predictions, axis=1) == true_labels)\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=1), average='macro')\n",
    "    recall = recall_score(true_labels, np.argmax(predictions, axis=1), average='macro')\n",
    "    f1 = f1_score(true_labels, np.argmax(predictions, axis=1), average='macro')\n",
    "    auc = roc_auc_score(tf.keras.utils.to_categorical(true_labels), predictions, multi_class='ovr')\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "# Function to save metrics, loss curve, and confusion matrix for the best model\n",
    "def save_best_model_visuals(history, model, val_ds, class_names, weights_path, fold):\n",
    "    # generate predictions for the validation set\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    val_predicted_ids = np.argmax(val_predictions, axis=-1)\n",
    "    true_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "    # confusion Matrix\n",
    "    confusion_matrix_path = os.path.join(weights_path, f\"confusion_matrix_fold_{fold}.png\")\n",
    "    save_confusion_matrix(true_labels, val_predicted_ids, class_names, confusion_matrix_path)\n",
    "\n",
    "    # loss curve\n",
    "    loss_curve_path = os.path.join(weights_path, f\"loss_curve_fold_{fold}.png\")\n",
    "    save_loss_curve(history.history, loss_curve_path)\n",
    "\n",
    "    # evaluation Metrics (Accuracy, Sensitivity, Specificity, F1 Score)\n",
    "    cm = confusion_matrix(true_labels, val_predicted_ids)\n",
    "    metrics_bar_chart_path = os.path.join(weights_path, f\"evaluation_metrics_fold_{fold}.png\")\n",
    "    save_evaluation_metrics(true_labels, val_predicted_ids, history.history, cm, metrics_bar_chart_path)\n",
    "\n",
    "    # save classification report as a text file\n",
    "    classification_report_path = os.path.join(weights_path, f\"classification_report_fold_{fold}.txt\")\n",
    "    save_classification_report(true_labels, val_predicted_ids, class_names, classification_report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation and fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and compile the model\n",
    "def create_model(num_classes, config, fine_tune=None):\n",
    "    # if you are not fine tuning the model, instantiate a new model \n",
    "    if(fine_tune == False):         \n",
    "        # instantiate mobilenet (contains 154 layers)\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=(img_height, img_width, 3),     # set the input it will receive\n",
    "            include_top=False,                          # do not include top layer to perform transfer learning\n",
    "            weights='imagenet'                          # load weights from imagenet dataset\n",
    "        )\n",
    "        base_model.trainable = False                    # Freeze the base model\n",
    "        \n",
    "        # add a layer in order to perform classification on our dataset\n",
    "        model = Sequential([\n",
    "            base_model,                                 # use base_model as the start of your model\n",
    "            layers.GlobalAveragePooling2D(),            # add a final layer to perform classification\n",
    "            layers.Dense(num_classes)                   # set the number of possible prediction to the num of classes in dataset\n",
    "        ])\n",
    "        \n",
    "    # select optimizer and learning rate based on configuration\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fine tune model by unfreezing the layers after the first fine_tune_at layers\n",
    "def fine_tune_model(base_model, fine_tune_at):\n",
    "    # Unfreeze the layers starting from fine_tune_at index\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/1 with config: {'learning_rate': 0.001, 'optimizer': 'adam', 'epochs': 14, 'save_metrics': False}\n",
      "\n",
      "Fold 1/5...\n",
      "Training with frozen base layers for 14 epochs...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=../model_checkpoints\\checkpoint_fold1.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(num_classes, config, fine_tune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# setup callbacks \u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m early_stopping, model_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mcallbacks_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# train the model on the training set until the epochs specified\u001b[39;00m\n\u001b[0;32m     43\u001b[0m history_frozen \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     44\u001b[0m     train_ds,                                       \u001b[38;5;66;03m# dataset used for training\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,                         \u001b[38;5;66;03m# dataset used for validation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     49\u001b[0m )\n",
      "Cell \u001b[1;32mIn[9], line 43\u001b[0m, in \u001b[0;36mcallbacks_setup\u001b[1;34m(checkpoint_filepath)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallbacks_setup\u001b[39m(checkpoint_filepath):\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# EarlyStopping callback configuration\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m     37\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,        \u001b[38;5;66;03m# monitor validation loss\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,                \u001b[38;5;66;03m# number of epochs with no improvement to stop training\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,              \u001b[38;5;66;03m# want to minimize what it being monitored \u001b[39;00m\n\u001b[0;32m     40\u001b[0m         restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# don't restore in EarlyStopping, handled by ModelCheckpoint\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     )\n\u001b[1;32m---> 43\u001b[0m     model_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# path to save weights\u001b[39;49;00m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# only save weights instead of full model\u001b[39;49;00m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# monitor validation loss\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# want to minimize what is being monitored\u001b[39;49;00m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# save the best weights\u001b[39;49;00m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m            \n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m early_stopping, model_checkpoint\n",
      "File \u001b[1;32mc:\\Users\\jacob\\anaconda3\\envs\\capstone\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:183\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[1;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_weights_only:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `save_weights_only=True` in `ModelCheckpoint`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the filepath provided must end in `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras weights format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         )\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=../model_checkpoints\\checkpoint_fold1.h5"
     ]
    }
   ],
   "source": [
    "train_metrics = []      # list to save training metrics\n",
    "val_metrics = []        # list to save validation metrics\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"Training model {i + 1}/{len(configs)} with config: {config}\")\n",
    "\n",
    "    # Training and validation loop for each fold\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kfold.split(train_val_images, train_val_labels):\n",
    "        print(f\"\\nFold {fold}/{FOLDS}...\")\n",
    "\n",
    "        # checkpoint_filepath = f\"../model_checkpoints/checkpoint_fold{fold}.h5\"\n",
    "        checkpoint_filepath = os.path.join(checkpoint_folder, f'checkpoint_fold{fold}.weights.h5')\n",
    "\n",
    "        # Create subset datasets for training and validation\n",
    "        train_images, train_labels = train_val_images[train_idx], train_val_labels[train_idx]\n",
    "        val_images, val_labels = train_val_images[val_idx], train_val_labels[val_idx]\n",
    "\n",
    "        # Convert NumPy arrays back to TensorFlow datasets\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "        val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "\n",
    "        # Normalize datasets and batch\n",
    "        normalization_layer = layers.Rescaling(1./255)\n",
    "        train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).batch(batch_size)\n",
    "        val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)).batch(batch_size)\n",
    "\n",
    "        # prefetch data to improve performance by overlapping data preprocessing and model execution and cache the dataset in memor\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        # Step 1: Train model with frozen layers\n",
    "        print(f\"Training with frozen base layers for {config['epochs']} epochs...\")\n",
    "\n",
    "        # Create and compile model for each fold\n",
    "        model = create_model(num_classes, config, fine_tune=False) \n",
    "\n",
    "        # setup callbacks \n",
    "        early_stopping, model_checkpoint = callbacks_setup(checkpoint_filepath)\n",
    "\n",
    "        # train the model on the training set until the epochs specified\n",
    "        history_frozen = model.fit(\n",
    "            train_ds,                                       # dataset used for training\n",
    "            validation_data=val_ds,                         # dataset used for validation\n",
    "            epochs=config['epochs'],                        # epochs used for training\n",
    "            callbacks=[early_stopping, model_checkpoint],   # set early stopping to avoid overfitting\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # load the best weights from ModelCheckpoint after training\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        # Step 2: Unfreeze layers and fine-tune\n",
    "        print(f\"Unfreezing layers starting from layer {FINE_TUNE_AT} for fine-tuning...\")\n",
    "        fine_tune_model(model.layers[0], FINE_TUNE_AT)      # fine tune model\n",
    "\n",
    "        # re-compile the model with a lower learning rate for fine-tuning\n",
    "        fine_tune_lr = config['learning_rate'] * 0.01\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        print(f\"Fine-tuning for {FINE_TUNE_EPOCHS} epochs...\")\n",
    "\n",
    "        # setup callbacks again for fine-tuning phase with a unique checkpoint\n",
    "        early_stopping, model_checkpoint = callbacks_setup(checkpoint_filepath)\n",
    "        \n",
    "        history_fine_tune = model.fit(\n",
    "            train_ds,                                       # dataset used for training\n",
    "            validation_data=val_ds,                         # dataset used for validation\n",
    "            epochs=FINE_TUNE_EPOCHS,                        # epochs used for training\n",
    "            callbacks=[early_stopping, model_checkpoint],   # set early stopping to avoid overfitting\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # load weights after fine-tuning\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        # evaluate on validation set after training\n",
    "        val_predictions = model.predict(val_ds)\n",
    "        avg_val_loss = model.evaluate(val_ds, verbose=0)[0]\n",
    "        avg_val_accuracy, avg_val_precision, avg_val_recall, avg_val_f1, avg_val_auc = calculate_metrics(\n",
    "            np.concatenate([y for x, y in val_ds]), val_predictions\n",
    "        )\n",
    "\n",
    "        print(f\"\\nValidation: \\tFold {fold} - Loss: {avg_val_loss:.4f}, Accuracy: {avg_val_accuracy:.4f}, Precision: {avg_val_precision:.4f}, Recall: {avg_val_recall:.4f}, F1 Score: {avg_val_f1:.4f}, AUC Score: {avg_val_auc:.4f}\")\n",
    "\n",
    "        # save the best model based on validation F1 score\n",
    "        if avg_val_f1 > best_val_f1score:\n",
    "            best_val_f1score = avg_val_f1\n",
    "            model.save(os.path.join(save_dir, f'mobilenetv2_best_f1score_fold_{fold}.h5'))\n",
    "            print(f\"Model with best F1 score during Validation saved at Fold {fold} with F1 Score of {best_val_f1score:.4f}\")\n",
    "\n",
    "            if (config['save_metrics'] == True):\n",
    "                #save confusion matrix, loss curve, evaluation metrics for the best model\n",
    "                save_best_model_visuals(history_fine_tune, model, val_ds, class_names, save_dir, fold)\n",
    "\n",
    "        fold += 1       # Move to the next fold\n",
    "\n",
    "# save metrics after training\n",
    "# np.save(os.path.join(save_dir, 'train_metrics.npy'), train_metrics)\n",
    "# np.save(os.path.join(save_dir, 'val_metrics.npy'), val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the best model on the held-out test set...\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step\n",
      "\n",
      "Test Set Evaluation - Loss: 0.1917, Accuracy: 0.9062, Precision: 0.9222, Recall: 0.8971, F1 Score: 0.9031, AUC Score: 0.9748\n"
     ]
    }
   ],
   "source": [
    "# once training is complete, evaluate on the held-out test set\n",
    "print(\"Evaluating the best model on the held-out test set...\")\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).batch(batch_size)\n",
    "\n",
    "test_predictions = model.predict(test_ds)\n",
    "avg_test_loss = model.evaluate(test_ds, verbose=0)[0]\n",
    "avg_test_accuracy, avg_test_precision, avg_test_recall, avg_test_f1, avg_test_auc = calculate_metrics(\n",
    "    np.concatenate([y for x, y in test_ds]), test_predictions\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Set Evaluation - Loss: {avg_test_loss:.4f}, Accuracy: {avg_test_accuracy:.4f}, Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1 Score: {avg_test_f1:.4f}, AUC Score: {avg_test_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
