{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 13:45:30.841507: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-13 13:45:30.850099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-13 13:45:30.859513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-13 13:45:30.862317: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-13 13:45:30.870155: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-13 13:45:31.285594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "tf.keras.backend.clear_session()  # Clear the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with MonkeyPox Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(\"../data/MSLD/Augmented_Images\")    # points to the folder containing the images that will be used for training\n",
    "\n",
    "# hyperparameters\n",
    "img_height = 224        # input image height\n",
    "img_width = 224         # input image width\n",
    "batch_size = 32         # size of the batch that will be fed to model\n",
    "\n",
    "# folds = the amount of folds that will be created for cross-validation\n",
    "# fine_tune_epochs = number of epochs after which we start fine-tuning\n",
    "# fine_tune_at = layer number where we start unfreezing layers\n",
    "\n",
    "# configurations that will be used in training\n",
    "configs = [\n",
    "    {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    # {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": True, \"fine_tune_epochs\": 25, \"fine_tune_at\": 148},\n",
    "    # {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    # {\"model_name\": \"mobilenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": True, \"fine_tune_epochs\": 25, \"fine_tune_at\": 148},\n",
    "\n",
    "    # {\"model_name\": \"efficientnet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "    \n",
    "    # {\"model_name\": \"densenet\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "\n",
    "    # {\"model_name\": \"inceptionv3\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "\n",
    "    # {\"model_name\": \"resnet50\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "\n",
    "    # {\"model_name\": \"vgg16\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 15},\n",
    "\n",
    "    # {\"model_name\": \"xception\", \"learning_rate\": 0.001, \"batch_size\": 32, \"image_size\" : 224, \"optimizer\": \"adam\", \"epochs\": 50, \"save_metrics\": True, \"folds\": 5, \"fine_tune\": False, \"fine_tune_epochs\": 25, \"fine_tune_at\": 150},\n",
    "]\n",
    "\n",
    "# Define the base path for saving models\n",
    "save_dir = \"../saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3192 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739468731.927343   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468731.927534   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468731.958783   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468731.958975   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468731.959094   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468731.959201   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.060302   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.060464   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.060577   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.060680   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.060783   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.060891   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.066836   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.066966   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.067076   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.067182   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1739468732.067292   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 13:45:32.067400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22265 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "I0000 00:00:1739468732.067756   25854 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 13:45:32.067861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21948 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:82:00.0, compute capability: 8.9\n",
      "2025-02-13 13:45:33.134020: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Load dataset without splitting\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,                                  # loads images from the data_root directory\n",
    "    image_size=(img_height, img_width),         # resizes all images to (224, 224) pixels\n",
    "    batch_size=batch_size,                      # set the batch size\n",
    "    shuffle=True                                # shufle data when loaded\n",
    ")\n",
    "\n",
    "class_names = np.array(dataset.class_names)     # get the class names for the data\n",
    "num_classes = len(class_names)                  # get the number of classes in the dataset\n",
    "\n",
    "# convert the dataset to a list of (image, label) pairs. This makes it easier to perform cross-validation\n",
    "image_paths, labels = [], []\n",
    "for image_batch, label_batch in dataset:\n",
    "    image_paths.extend(image_batch.numpy())\n",
    "    labels.extend(label_batch.numpy())\n",
    "\n",
    "image_paths = np.array(image_paths)             # convert to numpy array to facilitate training\n",
    "labels = np.array(labels)                       # convert to numpy array to facilitate training\n",
    "\n",
    "# Split the dataset into training/validation and test sets\n",
    "train_val_images, test_images, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.10, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "def callbacks_setup(checkpoint_filepath):\n",
    "    # EarlyStopping callback configuration\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',        # monitor validation loss\n",
    "        patience=4,                # number of epochs with no improvement to stop training\n",
    "        mode = 'min',              # want to minimize what it being monitored \n",
    "        min_delta=0.0003,\n",
    "        restore_best_weights=False # don't restore in EarlyStopping, handled by ModelCheckpoint\n",
    "    )\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,   # path to save weights\n",
    "        save_weights_only=True,         # only save weights instead of full model\n",
    "        monitor='val_recall',        # monitor validation loss\n",
    "        mode='max',                     # want to maximize what is being monitored\n",
    "        save_best_only=True             # save the best weights\n",
    "    )            \n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',      # monitor validation loss \n",
    "        factor=0.5,              # factor by which the learning rate will be reduced \n",
    "        patience=2,              # number of epochs with no improvement to stop training \n",
    "        mode='min',              # want to minimize what it being monitored \n",
    "        min_delta=0.0003,\n",
    "        min_lr=1e-6              # lower bound on the learning rate \n",
    "    )            \n",
    "\n",
    "    return early_stopping, model_checkpoint, reduce_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, classification_report, roc_auc_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plot and save confusion matrix\n",
    "def save_confusion_matrix(true_labels, predicted_labels, class_names, save_path):\n",
    "    # Compute confusion matrix using sklearn\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "    # Plot with adjustments\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=12)\n",
    "    ax.set_ylabel(\"True label\", fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels for better readability and alignment\n",
    "    plt.xticks(rotation=45, ha='right', rotation_mode='anchor', fontsize=10)\n",
    "    plt.yticks(rotation=45, ha='right', rotation_mode='anchor', fontsize=10)\n",
    "\n",
    "    # Prevent labels from being cut off\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and close plot\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# plot and save loss curves\n",
    "def save_loss_curve(history, save_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# compute and plot evaluation metrics (accuracy, sensitivity, specificity, F1 score)\n",
    "def save_evaluation_metrics(true_labels, predicted_labels, cm, save_path): \n",
    "\n",
    "    accuracy = np.mean(predicted_labels == true_labels)  \n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')     \n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')   \n",
    "    f1 = f1_score(true_labels, predicted_labels, average='binary')                \n",
    "    roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "    # specificity = np.mean(np.diag(cm) / (np.diag(cm) + np.sum(cm, axis=0) - np.diag(cm)))   \n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Sensitivity (Recall)\": recall,\n",
    "        # \"Specificity: specificity,\n",
    "        \"F1-Score\": f1,\n",
    "        \"ROC AUC\": roc_auc\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot the metrics as bars\n",
    "    bars = plt.bar(metrics.keys(), metrics.values(), color=['darkturquoise', 'sandybrown', 'hotpink', 'limegreen', 'mediumpurple'])\n",
    "\n",
    "    # Annotate each bar with the corresponding value\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.4f}', ha='center', va='bottom')  # Add metric value at the top of the bar\n",
    "\n",
    "    plt.title(\"Model Evaluation Metrics\")\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    return metrics\n",
    "\n",
    "# save classification report\n",
    "def save_classification_report(true_labels, predicted_labels, class_names, save_path):\n",
    "    class_report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(class_report)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(true_labels, predictions):\n",
    "    # Apply threshold of 0.5 to convert probabilities to binary predictions\n",
    "    predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')  \n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')        \n",
    "    f1 = f1_score(true_labels, predicted_labels, average='binary')                \n",
    "    auc = roc_auc_score(true_labels, predictions)                                 \n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "# Function to save metrics, loss curve, and confusion matrix for the best model\n",
    "def save_best_model_visuals(history, model, val_ds, class_names, weights_path, fold):\n",
    "    # Generate predictions for the validation set\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    val_predicted_probs = val_predictions.flatten()  # Convert 2D predictions into 1D probabilities\n",
    "    val_predicted_ids = (val_predicted_probs > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "    true_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    confusion_matrix_path = os.path.join(weights_path, \"confusion_matrix.png\")\n",
    "    save_confusion_matrix(true_labels, val_predicted_ids, class_names, confusion_matrix_path)\n",
    "\n",
    "    # Loss Curve\n",
    "    loss_curve_path = os.path.join(weights_path, \"loss_curve.png\")\n",
    "    save_loss_curve(history.history, loss_curve_path)\n",
    "\n",
    "    # Evaluation Metrics (Accuracy, Sensitivity, Specificity, F1 Score)\n",
    "    cm = confusion_matrix(true_labels, val_predicted_ids)\n",
    "    metrics_bar_chart_path = os.path.join(weights_path, \"evaluation_metrics.png\")\n",
    "    save_evaluation_metrics(true_labels, val_predicted_ids, cm, metrics_bar_chart_path)\n",
    "\n",
    "    # Save classification report as a text file\n",
    "    classification_report_path = os.path.join(weights_path, \"classification_report.txt\")\n",
    "    save_classification_report(true_labels, val_predicted_ids, class_names, classification_report_path)\n",
    "\n",
    "def compute_cv_statistics(accuracies, precisions, recalls, f1_scores, use_std_error=False, output_filepath=None):\n",
    "    \"\"\"\n",
    "    Compute the mean and variation (std dev or standard error) for each metric and optionally save the results to a file.\n",
    "    \n",
    "    Parameters:\n",
    "        accuracies (list of float): Accuracy values for each fold.\n",
    "        precisions (list of float): Precision values for each fold.\n",
    "        recalls (list of float): Recall values for each fold.\n",
    "        f1_scores (list of float): F1 score values for each fold.\n",
    "        use_std_error (bool): If True, compute standard error (std / sqrt(n)); otherwise, compute standard deviation.\n",
    "        output_filepath (str): If provided, the path to a text file where the metrics will be saved.\n",
    "    \n",
    "    The function prints each metric in the format:\n",
    "        Metric: mean ± variation\n",
    "    (Metrics are multiplied by 100 to display percentages.)\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"Accuracy\": np.array(accuracies),\n",
    "        \"Precision\": np.array(precisions),\n",
    "        \"Recall\": np.array(recalls),\n",
    "        \"F1 Score\": np.array(f1_scores)\n",
    "    }\n",
    "    \n",
    "    output_lines = []\n",
    "    for metric_name, values in metrics.items():\n",
    "        mean_val = np.mean(values)\n",
    "        # Use ddof=1 for sample standard deviation\n",
    "        variation = np.std(values, ddof=1)\n",
    "        if use_std_error:\n",
    "            variation /= np.sqrt(len(values))\n",
    "        # Format the output as percentages; adjust if your metrics are already in percentage\n",
    "        output_lines.append(f\"{metric_name}: {mean_val*100:.2f} ± {variation*100:.2f}\\n\")\n",
    "    \n",
    "    metrics_str = \"\".join(output_lines)\n",
    "    \n",
    "    # Print the overall metrics to the console\n",
    "    print(\"\\nOverall Cross-Validation Metrics:\")\n",
    "    print(metrics_str)\n",
    "    \n",
    "    # Save the metrics to a text file if an output file path is provided\n",
    "    if output_filepath:\n",
    "        with open(output_filepath, \"w\") as f:\n",
    "            f.write(\"Overall Cross-Validation Metrics:\\n\")\n",
    "            f.write(metrics_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into training/validation set for hyperparameter tuning\n",
    "# train_images_tuning, val_images_tuning, train_labels_tuning, val_labels_tuning = train_test_split(\n",
    "#     image_paths, labels, test_size=0.1, random_state=42, stratify=labels\n",
    "# )\n",
    "\n",
    "# # Define the hypermodel for hyperparameter tuning\n",
    "# def build_model(hp):\n",
    "#     base_model = tf.keras.applications.MobileNetV2(\n",
    "#         input_shape=(img_height, img_width, 3),\n",
    "#         include_top=False,\n",
    "#         weights='imagenet'\n",
    "#     )\n",
    "#     base_model.trainable = False  # Freeze layers initially\n",
    "    \n",
    "#     model = Sequential([\n",
    "#         base_model,\n",
    "#         layers.GlobalAveragePooling2D(),\n",
    "#         layers.Dense(num_classes)\n",
    "#     ])\n",
    "\n",
    "#     # Tune hyperparameters\n",
    "#     learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "#     optimizer = hp.Choice('optimizer', values=['adam', 'sgd'])\n",
    "\n",
    "#     if optimizer == 'adam':\n",
    "#         opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#     else:\n",
    "#         opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=opt,\n",
    "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Set up the tuner for hyperparameter tuning\n",
    "# tuner = kt.RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',  # Optimize for validation accuracy\n",
    "#     max_trials=10,             # Try 10 different hyperparameter combinations\n",
    "#     executions_per_trial=1,    # Run each combination once\n",
    "#     directory='hyperparameter_tuning',\n",
    "#     project_name='best_hyperparams_tuning'\n",
    "# )\n",
    "\n",
    "# # Prepare TensorFlow datasets for training and validation\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((train_images_tuning, train_labels_tuning)).batch(batch_size)\n",
    "# val_ds = tf.data.Dataset.from_tensor_slices((val_images_tuning, val_labels_tuning)).batch(batch_size)\n",
    "\n",
    "# # Perform the hyperparameter search on the validation set\n",
    "# tuner.search(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "# # Get the best hyperparameters after the search\n",
    "# best_hyperparams = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# # Print the best hyperparameters\n",
    "# print(f\"Best Hyperparameters: {best_hyperparams.values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation and fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and compile the model\n",
    "def create_model(num_classes, config, fine_tune=None):\n",
    "    # if you are not fine tuning the model, instantiate a new model \n",
    "    if(fine_tune == False):         \n",
    "\n",
    "        model_name = config[\"model_name\"]\n",
    "\n",
    "        if model_name == \"mobilenet\":\n",
    "            base_model = tf.keras.applications.MobileNetV2\n",
    "        elif model_name == \"efficientnet\":\n",
    "            base_model = tf.keras.applications.EfficientNetB3\n",
    "        elif model_name == \"densenet\":\n",
    "            base_model = tf.keras.applications.DenseNet121\n",
    "        elif model_name == \"inceptionv3\":\n",
    "            base_model = tf.keras.applications.InceptionV3\n",
    "        elif model_name == \"resnet50\":\n",
    "            base_model = tf.keras.applications.ResNet50\n",
    "        elif model_name == \"vgg16\":\n",
    "            base_model = tf.keras.applications.VGG16\n",
    "        elif model_name == \"xception\":\n",
    "            base_model = tf.keras.applications.Xception\n",
    "        else:\n",
    "            raise ValueError(f\"Model name '{model_name}' is not supported.\")\n",
    "\n",
    "\n",
    "        # instantiate mobilenet (contains 154 layers)\n",
    "        base_model = base_model(\n",
    "            input_shape=(img_height, img_width, 3),     # set the input it will receive\n",
    "            include_top=False,                          # do not include top layer to perform transfer learning\n",
    "            weights='imagenet'                          # load weights from imagenet dataset\n",
    "        )\n",
    "        base_model.trainable = False                    # Freeze the base model\n",
    "        \n",
    "        # add a layer in order to perform classification on our dataset\n",
    "        model = Sequential([\n",
    "            base_model,                         # use base_model as the start of your model\n",
    "            layers.GlobalAveragePooling2D(),    # add a final layer to perform classification\n",
    "            layers.Dense(1)                     # set the number of possible prediction to the num of classes in dataset for multiclass classification and 1 for binary classification\n",
    "        ])\n",
    "        \n",
    "    # select optimizer and learning rate based on configuration\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    elif config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=config[\"learning_rate\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {config['optimizer']}\")\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# fine tune model by unfreezing the layers after the first fine_tune_at layers\n",
    "def fine_tune_model(base_model, fine_tune_at):\n",
    "    # Unfreeze the layers starting from fine_tune_at index\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/1 with config: {'model_name': 'mobilenet', 'learning_rate': 0.001, 'batch_size': 32, 'image_size': 224, 'optimizer': 'adam', 'epochs': 50, 'save_metrics': True, 'folds': 5, 'fine_tune': False, 'fine_tune_epochs': 25, 'fine_tune_at': 150}\n",
      "\n",
      "Fold 1/5...\n",
      "Training with frozen base layers for 50 epochs...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739468737.456672   26125 service.cc:146] XLA service 0x7bf4f40020b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739468737.456695   26125 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "I0000 00:00:1739468737.456697   26125 service.cc:154]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-02-13 13:45:37.549689: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-13 13:45:37.840431: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/72\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4464 - loss: 0.8728 - precision: 0.4563 - recall: 0.2647      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739468739.451104   26125 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.5649 - loss: 0.7007 - precision: 0.6324 - recall: 0.4400 - val_accuracy: 0.7461 - val_loss: 0.4886 - val_precision: 0.7792 - val_recall: 0.7547 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7876 - loss: 0.4380 - precision: 0.8527 - recall: 0.7460 - val_accuracy: 0.8104 - val_loss: 0.4229 - val_precision: 0.8215 - val_recall: 0.8396 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8418 - loss: 0.3696 - precision: 0.8935 - recall: 0.8119 - val_accuracy: 0.8365 - val_loss: 0.3861 - val_precision: 0.8436 - val_recall: 0.8648 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8660 - loss: 0.3283 - precision: 0.9047 - recall: 0.8485 - val_accuracy: 0.8643 - val_loss: 0.3599 - val_precision: 0.8636 - val_recall: 0.8962 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8863 - loss: 0.2984 - precision: 0.9180 - recall: 0.8735 - val_accuracy: 0.8713 - val_loss: 0.3399 - val_precision: 0.8742 - val_recall: 0.8962 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8891 - loss: 0.2755 - precision: 0.9201 - recall: 0.8768 - val_accuracy: 0.8800 - val_loss: 0.3240 - val_precision: 0.8784 - val_recall: 0.9088 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2573 - precision: 0.9274 - recall: 0.8984 - val_accuracy: 0.8835 - val_loss: 0.3111 - val_precision: 0.8838 - val_recall: 0.9088 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2424 - precision: 0.9350 - recall: 0.9067 - val_accuracy: 0.8852 - val_loss: 0.3004 - val_precision: 0.8841 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9170 - loss: 0.2299 - precision: 0.9381 - recall: 0.9106 - val_accuracy: 0.8974 - val_loss: 0.2914 - val_precision: 0.9034 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.2192 - precision: 0.9394 - recall: 0.9174 - val_accuracy: 0.9009 - val_loss: 0.2836 - val_precision: 0.9065 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9263 - loss: 0.2098 - precision: 0.9429 - recall: 0.9228 - val_accuracy: 0.9043 - val_loss: 0.2768 - val_precision: 0.9097 - val_recall: 0.9182 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9299 - loss: 0.2015 - precision: 0.9491 - recall: 0.9230 - val_accuracy: 0.9043 - val_loss: 0.2710 - val_precision: 0.9097 - val_recall: 0.9182 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9342 - loss: 0.1941 - precision: 0.9534 - recall: 0.9265 - val_accuracy: 0.9026 - val_loss: 0.2658 - val_precision: 0.9094 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9357 - loss: 0.1873 - precision: 0.9535 - recall: 0.9294 - val_accuracy: 0.9061 - val_loss: 0.2613 - val_precision: 0.9099 - val_recall: 0.9214 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9376 - loss: 0.1812 - precision: 0.9543 - recall: 0.9322 - val_accuracy: 0.9078 - val_loss: 0.2573 - val_precision: 0.9128 - val_recall: 0.9214 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.1757 - precision: 0.9548 - recall: 0.9393 - val_accuracy: 0.9078 - val_loss: 0.2537 - val_precision: 0.9154 - val_recall: 0.9182 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.1705 - precision: 0.9559 - recall: 0.9413 - val_accuracy: 0.9096 - val_loss: 0.2506 - val_precision: 0.9156 - val_recall: 0.9214 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.1657 - precision: 0.9578 - recall: 0.9424 - val_accuracy: 0.9078 - val_loss: 0.2477 - val_precision: 0.9154 - val_recall: 0.9182 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.1613 - precision: 0.9586 - recall: 0.9419 - val_accuracy: 0.9026 - val_loss: 0.2452 - val_precision: 0.9146 - val_recall: 0.9088 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9454 - loss: 0.1571 - precision: 0.9586 - recall: 0.9420 - val_accuracy: 0.9043 - val_loss: 0.2430 - val_precision: 0.9148 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.1532 - precision: 0.9605 - recall: 0.9428 - val_accuracy: 0.9043 - val_loss: 0.2410 - val_precision: 0.9148 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.1495 - precision: 0.9610 - recall: 0.9447 - val_accuracy: 0.9061 - val_loss: 0.2392 - val_precision: 0.9151 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.1460 - precision: 0.9620 - recall: 0.9456 - val_accuracy: 0.9061 - val_loss: 0.2376 - val_precision: 0.9177 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.1427 - precision: 0.9621 - recall: 0.9472 - val_accuracy: 0.9061 - val_loss: 0.2361 - val_precision: 0.9177 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.1396 - precision: 0.9622 - recall: 0.9470 - val_accuracy: 0.9043 - val_loss: 0.2349 - val_precision: 0.9148 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9514 - loss: 0.1366 - precision: 0.9625 - recall: 0.9497 - val_accuracy: 0.9061 - val_loss: 0.2337 - val_precision: 0.9151 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.1337 - precision: 0.9647 - recall: 0.9505 - val_accuracy: 0.9061 - val_loss: 0.2327 - val_precision: 0.9151 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9534 - loss: 0.1310 - precision: 0.9651 - recall: 0.9507 - val_accuracy: 0.9061 - val_loss: 0.2318 - val_precision: 0.9151 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9540 - loss: 0.1284 - precision: 0.9655 - recall: 0.9514 - val_accuracy: 0.9078 - val_loss: 0.2310 - val_precision: 0.9154 - val_recall: 0.9182 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9556 - loss: 0.1259 - precision: 0.9656 - recall: 0.9543 - val_accuracy: 0.9096 - val_loss: 0.2304 - val_precision: 0.9156 - val_recall: 0.9214 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.1236 - precision: 0.9669 - recall: 0.9551 - val_accuracy: 0.9113 - val_loss: 0.2298 - val_precision: 0.9185 - val_recall: 0.9214 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9609 - loss: 0.1213 - precision: 0.9704 - recall: 0.9589 - val_accuracy: 0.9130 - val_loss: 0.2293 - val_precision: 0.9187 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.1191 - precision: 0.9708 - recall: 0.9590 - val_accuracy: 0.9130 - val_loss: 0.2288 - val_precision: 0.9187 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9621 - loss: 0.1169 - precision: 0.9719 - recall: 0.9596 - val_accuracy: 0.9130 - val_loss: 0.2285 - val_precision: 0.9187 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.1149 - precision: 0.9746 - recall: 0.9599 - val_accuracy: 0.9130 - val_loss: 0.2282 - val_precision: 0.9187 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.1129 - precision: 0.9754 - recall: 0.9599 - val_accuracy: 0.9148 - val_loss: 0.2280 - val_precision: 0.9216 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.1110 - precision: 0.9762 - recall: 0.9606 - val_accuracy: 0.9148 - val_loss: 0.2278 - val_precision: 0.9216 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9659 - loss: 0.1092 - precision: 0.9777 - recall: 0.9606 - val_accuracy: 0.9130 - val_loss: 0.2277 - val_precision: 0.9187 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9644 - loss: 0.1063 - precision: 0.9768 - recall: 0.9588 - val_accuracy: 0.9130 - val_loss: 0.2268 - val_precision: 0.9187 - val_recall: 0.9245 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.1044 - precision: 0.9747 - recall: 0.9680 - val_accuracy: 0.9130 - val_loss: 0.2268 - val_precision: 0.9187 - val_recall: 0.9245 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.1034 - precision: 0.9747 - recall: 0.9680 - val_accuracy: 0.9113 - val_loss: 0.2268 - val_precision: 0.9159 - val_recall: 0.9245 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9693 - loss: 0.1022 - precision: 0.9751 - recall: 0.9693 - val_accuracy: 0.9113 - val_loss: 0.2273 - val_precision: 0.9159 - val_recall: 0.9245 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9688 - loss: 0.1016 - precision: 0.9739 - recall: 0.9696 - val_accuracy: 0.9113 - val_loss: 0.2275 - val_precision: 0.9159 - val_recall: 0.9245 - learning_rate: 2.5000e-04\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step\n",
      "\n",
      "Validation: Fold 1 - Loss: 0.2293, Accuracy: 0.9130, Precision: 0.9187, Recall: 0.9245, F1 Score: 0.9216, ROC AUC Score: 0.9680\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 13:46:07.478551: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/model1/best_f1score_fold/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_models/model1/best_f1score_fold/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '../saved_models/model1/best_f1score_fold'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_154')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  136305549386064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549386640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549385296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549387408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549385104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549385488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549386448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549387792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549387024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549384528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549387600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549389520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549388944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549389328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549388752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549391440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549392208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549392592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549393168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549392784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305549390096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538581520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538581136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538581328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538580944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538582864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538584208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538584400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538584016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538583248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538584784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538586128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538586320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538585936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538585168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538586704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538588048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538588240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538587856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538587088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538585552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538590160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538590352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538589968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538582480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538589008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538592272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538592464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538592080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538589584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538592848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538594192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538594384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538594000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538593232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538594768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538596112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538596304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538595920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538595152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538593616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538925392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538924624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538925584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538924816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538926352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538927696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538927888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538927504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538926736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538928272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538929616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538929808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538929424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538928656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538930192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538931536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538931728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538931344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538930576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538932112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538933456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538933648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538933264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538932496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538934032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538935376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538935568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538935184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538934416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538935952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538937296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538937488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538937104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538936336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538937872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538939216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538939408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538939024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538938256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538939792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538940176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539235920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538925968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305538938640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539236112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539238032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539238224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539237840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539237072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539238608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539239952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539240144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539239760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539238992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539240528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539241872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539242064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539241680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539240912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539242448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539243792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539243984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539243600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539242832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539244368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539245712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539245904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539245520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539244752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539246288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539247632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539247824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539247440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539246672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539248208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539249552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539249744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539249360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539248592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539250128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539251472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539251664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539251280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539250512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305539248976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528062800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528062032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528062992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528062224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528063760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528065104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528065296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528064912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528064144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528065680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528067024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528067216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528066832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528066064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528067600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528068944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528069136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528068752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528067984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528069520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528070864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528071056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528070672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528069904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528071440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528072784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528072976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528072592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528071824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528073360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528074704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528074896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528074512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528073744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528075280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528076624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528076816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528076432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528075664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528077200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528077584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528406672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528063376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528076048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528406864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528408208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528408400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528408016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528407248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528408784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528410128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528410320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528409936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528409168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528410704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528412048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528412240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528411856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528411088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528412624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528413968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528414160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528413776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528413008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528414544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528415888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528416080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528415696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528414928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528416464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528417808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528418000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528417616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528416848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528418384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528419728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528419920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528419536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528418768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528420304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528421648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528421840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528421456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528420688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305528419152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517298896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517298128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517298704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517299088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517299472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517300816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517301008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517300624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517299856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517301392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517302736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517302928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517302544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517301776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517303312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517304656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517304848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517304464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517303696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517305232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517306576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517306768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517306384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517305616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517307152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517308496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517308688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517308304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517307536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517306000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136305517310608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model with best F1 score during Validation saved at Fold 1 with F1 Score of 0.9239\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 13:46:09.675807: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2/5...\n",
      "Training with frozen base layers for 50 epochs...\n",
      "Epoch 1/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.6511 - loss: 0.5830 - precision: 0.7372 - recall: 0.5610 - val_accuracy: 0.8191 - val_loss: 0.4117 - val_precision: 0.8302 - val_recall: 0.8459 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8187 - loss: 0.4048 - precision: 0.8617 - recall: 0.7957 - val_accuracy: 0.8470 - val_loss: 0.3610 - val_precision: 0.8506 - val_recall: 0.8774 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8541 - loss: 0.3527 - precision: 0.8865 - recall: 0.8410 - val_accuracy: 0.8522 - val_loss: 0.3305 - val_precision: 0.8520 - val_recall: 0.8868 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8802 - loss: 0.3172 - precision: 0.9059 - recall: 0.8714 - val_accuracy: 0.8661 - val_loss: 0.3088 - val_precision: 0.8619 - val_recall: 0.9025 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.2910 - precision: 0.9160 - recall: 0.8822 - val_accuracy: 0.8783 - val_loss: 0.2924 - val_precision: 0.8851 - val_recall: 0.8962 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8986 - loss: 0.2706 - precision: 0.9199 - recall: 0.8921 - val_accuracy: 0.8904 - val_loss: 0.2795 - val_precision: 0.8972 - val_recall: 0.9057 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9131 - loss: 0.2543 - precision: 0.9312 - recall: 0.9079 - val_accuracy: 0.8957 - val_loss: 0.2692 - val_precision: 0.9006 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9161 - loss: 0.2407 - precision: 0.9324 - recall: 0.9124 - val_accuracy: 0.9009 - val_loss: 0.2606 - val_precision: 0.9065 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9253 - loss: 0.2292 - precision: 0.9395 - recall: 0.9226 - val_accuracy: 0.9026 - val_loss: 0.2535 - val_precision: 0.9119 - val_recall: 0.9119 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2192 - precision: 0.9400 - recall: 0.9214 - val_accuracy: 0.9113 - val_loss: 0.2474 - val_precision: 0.9238 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9265 - loss: 0.2104 - precision: 0.9426 - recall: 0.9215 - val_accuracy: 0.9183 - val_loss: 0.2421 - val_precision: 0.9274 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.2026 - precision: 0.9448 - recall: 0.9222 - val_accuracy: 0.9165 - val_loss: 0.2376 - val_precision: 0.9245 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9325 - loss: 0.1955 - precision: 0.9473 - recall: 0.9281 - val_accuracy: 0.9200 - val_loss: 0.2336 - val_precision: 0.9250 - val_recall: 0.9308 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9335 - loss: 0.1891 - precision: 0.9482 - recall: 0.9292 - val_accuracy: 0.9270 - val_loss: 0.2300 - val_precision: 0.9286 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9393 - loss: 0.1832 - precision: 0.9520 - recall: 0.9361 - val_accuracy: 0.9252 - val_loss: 0.2269 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.1778 - precision: 0.9522 - recall: 0.9401 - val_accuracy: 0.9252 - val_loss: 0.2241 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9441 - loss: 0.1728 - precision: 0.9543 - recall: 0.9427 - val_accuracy: 0.9252 - val_loss: 0.2215 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.1682 - precision: 0.9551 - recall: 0.9453 - val_accuracy: 0.9252 - val_loss: 0.2192 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.1638 - precision: 0.9552 - recall: 0.9468 - val_accuracy: 0.9252 - val_loss: 0.2171 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.1597 - precision: 0.9559 - recall: 0.9470 - val_accuracy: 0.9252 - val_loss: 0.2152 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.1558 - precision: 0.9566 - recall: 0.9467 - val_accuracy: 0.9252 - val_loss: 0.2135 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.1522 - precision: 0.9567 - recall: 0.9470 - val_accuracy: 0.9235 - val_loss: 0.2119 - val_precision: 0.9228 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.1487 - precision: 0.9568 - recall: 0.9492 - val_accuracy: 0.9235 - val_loss: 0.2105 - val_precision: 0.9228 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.1454 - precision: 0.9569 - recall: 0.9485 - val_accuracy: 0.9235 - val_loss: 0.2091 - val_precision: 0.9228 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.1423 - precision: 0.9579 - recall: 0.9477 - val_accuracy: 0.9217 - val_loss: 0.2079 - val_precision: 0.9200 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9503 - loss: 0.1393 - precision: 0.9581 - recall: 0.9506 - val_accuracy: 0.9217 - val_loss: 0.2068 - val_precision: 0.9200 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9508 - loss: 0.1365 - precision: 0.9589 - recall: 0.9508 - val_accuracy: 0.9217 - val_loss: 0.2058 - val_precision: 0.9200 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9544 - loss: 0.1338 - precision: 0.9596 - recall: 0.9567 - val_accuracy: 0.9252 - val_loss: 0.2048 - val_precision: 0.9257 - val_recall: 0.9403 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9557 - loss: 0.1312 - precision: 0.9597 - recall: 0.9589 - val_accuracy: 0.9252 - val_loss: 0.2040 - val_precision: 0.9231 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9575 - loss: 0.1287 - precision: 0.9624 - recall: 0.9597 - val_accuracy: 0.9235 - val_loss: 0.2032 - val_precision: 0.9202 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9582 - loss: 0.1263 - precision: 0.9625 - recall: 0.9608 - val_accuracy: 0.9235 - val_loss: 0.2025 - val_precision: 0.9202 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9588 - loss: 0.1239 - precision: 0.9632 - recall: 0.9612 - val_accuracy: 0.9235 - val_loss: 0.2018 - val_precision: 0.9202 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9588 - loss: 0.1217 - precision: 0.9632 - recall: 0.9612 - val_accuracy: 0.9217 - val_loss: 0.2012 - val_precision: 0.9174 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.1196 - precision: 0.9646 - recall: 0.9644 - val_accuracy: 0.9217 - val_loss: 0.2007 - val_precision: 0.9174 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9617 - loss: 0.1175 - precision: 0.9646 - recall: 0.9651 - val_accuracy: 0.9217 - val_loss: 0.2002 - val_precision: 0.9174 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9628 - loss: 0.1155 - precision: 0.9654 - recall: 0.9665 - val_accuracy: 0.9200 - val_loss: 0.1997 - val_precision: 0.9146 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.1136 - precision: 0.9654 - recall: 0.9682 - val_accuracy: 0.9200 - val_loss: 0.1993 - val_precision: 0.9146 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9649 - loss: 0.1117 - precision: 0.9674 - recall: 0.9682 - val_accuracy: 0.9217 - val_loss: 0.1989 - val_precision: 0.9174 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9644 - loss: 0.1099 - precision: 0.9674 - recall: 0.9673 - val_accuracy: 0.9217 - val_loss: 0.1986 - val_precision: 0.9174 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.1082 - precision: 0.9695 - recall: 0.9675 - val_accuracy: 0.9217 - val_loss: 0.1983 - val_precision: 0.9174 - val_recall: 0.9434 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1065 - precision: 0.9697 - recall: 0.9733 - val_accuracy: 0.9235 - val_loss: 0.1980 - val_precision: 0.9177 - val_recall: 0.9465 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9700 - loss: 0.1048 - precision: 0.9714 - recall: 0.9733 - val_accuracy: 0.9235 - val_loss: 0.1978 - val_precision: 0.9177 - val_recall: 0.9465 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 0.1032 - precision: 0.9718 - recall: 0.9737 - val_accuracy: 0.9235 - val_loss: 0.1976 - val_precision: 0.9177 - val_recall: 0.9465 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.1017 - precision: 0.9718 - recall: 0.9737 - val_accuracy: 0.9270 - val_loss: 0.1974 - val_precision: 0.9207 - val_recall: 0.9497 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.1002 - precision: 0.9731 - recall: 0.9748 - val_accuracy: 0.9270 - val_loss: 0.1973 - val_precision: 0.9207 - val_recall: 0.9497 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.0987 - precision: 0.9731 - recall: 0.9748 - val_accuracy: 0.9270 - val_loss: 0.1972 - val_precision: 0.9207 - val_recall: 0.9497 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.0972 - precision: 0.9731 - recall: 0.9771 - val_accuracy: 0.9270 - val_loss: 0.1971 - val_precision: 0.9207 - val_recall: 0.9497 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9741 - loss: 0.0958 - precision: 0.9733 - recall: 0.9791 - val_accuracy: 0.9322 - val_loss: 0.1887 - val_precision: 0.9401 - val_recall: 0.9371 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0951 - precision: 0.9723 - recall: 0.9800 - val_accuracy: 0.9322 - val_loss: 0.1886 - val_precision: 0.9401 - val_recall: 0.9371 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0941 - precision: 0.9723 - recall: 0.9800 - val_accuracy: 0.9304 - val_loss: 0.1885 - val_precision: 0.9371 - val_recall: 0.9371 - learning_rate: 5.0000e-04\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step\n",
      "\n",
      "Validation: Fold 2 - Loss: 0.1974, Accuracy: 0.9270, Precision: 0.9207, Recall: 0.9497, F1 Score: 0.9350, ROC AUC Score: 0.9768\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "Fold 3/5...\n",
      "Training with frozen base layers for 50 epochs...\n",
      "Epoch 1/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - accuracy: 0.6543 - loss: 0.5823 - precision: 0.7403 - recall: 0.5965 - val_accuracy: 0.7944 - val_loss: 0.4483 - val_precision: 0.8062 - val_recall: 0.8265 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8075 - loss: 0.4120 - precision: 0.8498 - recall: 0.7983 - val_accuracy: 0.8328 - val_loss: 0.3858 - val_precision: 0.8508 - val_recall: 0.8454 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8367 - loss: 0.3599 - precision: 0.8734 - recall: 0.8300 - val_accuracy: 0.8659 - val_loss: 0.3486 - val_precision: 0.8896 - val_recall: 0.8644 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8592 - loss: 0.3246 - precision: 0.8888 - recall: 0.8571 - val_accuracy: 0.8746 - val_loss: 0.3229 - val_precision: 0.8964 - val_recall: 0.8738 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8733 - loss: 0.2984 - precision: 0.8998 - recall: 0.8726 - val_accuracy: 0.8955 - val_loss: 0.3038 - val_precision: 0.9186 - val_recall: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 0.2782 - precision: 0.9143 - recall: 0.8824 - val_accuracy: 0.8920 - val_loss: 0.2890 - val_precision: 0.9100 - val_recall: 0.8927 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8952 - loss: 0.2619 - precision: 0.9195 - recall: 0.8924 - val_accuracy: 0.8902 - val_loss: 0.2770 - val_precision: 0.9097 - val_recall: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2485 - precision: 0.9317 - recall: 0.8979 - val_accuracy: 0.8868 - val_loss: 0.2672 - val_precision: 0.9091 - val_recall: 0.8833 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9099 - loss: 0.2370 - precision: 0.9346 - recall: 0.9038 - val_accuracy: 0.8902 - val_loss: 0.2589 - val_precision: 0.9097 - val_recall: 0.8896 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9182 - loss: 0.2271 - precision: 0.9386 - recall: 0.9149 - val_accuracy: 0.8990 - val_loss: 0.2518 - val_precision: 0.9164 - val_recall: 0.8991 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9216 - loss: 0.2184 - precision: 0.9413 - recall: 0.9185 - val_accuracy: 0.8990 - val_loss: 0.2456 - val_precision: 0.9164 - val_recall: 0.8991 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2106 - precision: 0.9431 - recall: 0.9226 - val_accuracy: 0.9007 - val_loss: 0.2403 - val_precision: 0.9221 - val_recall: 0.8959 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9289 - loss: 0.2035 - precision: 0.9464 - recall: 0.9267 - val_accuracy: 0.9094 - val_loss: 0.2355 - val_precision: 0.9260 - val_recall: 0.9085 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.1971 - precision: 0.9478 - recall: 0.9270 - val_accuracy: 0.9094 - val_loss: 0.2314 - val_precision: 0.9206 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 0.1912 - precision: 0.9490 - recall: 0.9281 - val_accuracy: 0.9094 - val_loss: 0.2276 - val_precision: 0.9206 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.1858 - precision: 0.9516 - recall: 0.9294 - val_accuracy: 0.9094 - val_loss: 0.2243 - val_precision: 0.9206 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.1808 - precision: 0.9537 - recall: 0.9306 - val_accuracy: 0.9129 - val_loss: 0.2213 - val_precision: 0.9211 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9365 - loss: 0.1761 - precision: 0.9540 - recall: 0.9330 - val_accuracy: 0.9146 - val_loss: 0.2186 - val_precision: 0.9241 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 0.1717 - precision: 0.9542 - recall: 0.9340 - val_accuracy: 0.9164 - val_loss: 0.2161 - val_precision: 0.9270 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.1675 - precision: 0.9544 - recall: 0.9387 - val_accuracy: 0.9129 - val_loss: 0.2138 - val_precision: 0.9238 - val_recall: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.1636 - precision: 0.9551 - recall: 0.9428 - val_accuracy: 0.9146 - val_loss: 0.2118 - val_precision: 0.9241 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9430 - loss: 0.1599 - precision: 0.9553 - recall: 0.9436 - val_accuracy: 0.9164 - val_loss: 0.2099 - val_precision: 0.9270 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9456 - loss: 0.1563 - precision: 0.9556 - recall: 0.9478 - val_accuracy: 0.9199 - val_loss: 0.2082 - val_precision: 0.9274 - val_recall: 0.9274 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9484 - loss: 0.1530 - precision: 0.9570 - recall: 0.9514 - val_accuracy: 0.9233 - val_loss: 0.2066 - val_precision: 0.9279 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.1498 - precision: 0.9571 - recall: 0.9525 - val_accuracy: 0.9216 - val_loss: 0.2052 - val_precision: 0.9277 - val_recall: 0.9306 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.1467 - precision: 0.9571 - recall: 0.9532 - val_accuracy: 0.9233 - val_loss: 0.2038 - val_precision: 0.9306 - val_recall: 0.9306 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9508 - loss: 0.1437 - precision: 0.9595 - recall: 0.9532 - val_accuracy: 0.9233 - val_loss: 0.2026 - val_precision: 0.9306 - val_recall: 0.9306 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1409 - precision: 0.9607 - recall: 0.9561 - val_accuracy: 0.9233 - val_loss: 0.2015 - val_precision: 0.9306 - val_recall: 0.9306 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9532 - loss: 0.1382 - precision: 0.9610 - recall: 0.9561 - val_accuracy: 0.9233 - val_loss: 0.2005 - val_precision: 0.9306 - val_recall: 0.9306 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9547 - loss: 0.1355 - precision: 0.9631 - recall: 0.9565 - val_accuracy: 0.9216 - val_loss: 0.1995 - val_precision: 0.9304 - val_recall: 0.9274 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9547 - loss: 0.1330 - precision: 0.9631 - recall: 0.9565 - val_accuracy: 0.9251 - val_loss: 0.1987 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9544 - loss: 0.1306 - precision: 0.9631 - recall: 0.9559 - val_accuracy: 0.9251 - val_loss: 0.1979 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1282 - precision: 0.9641 - recall: 0.9560 - val_accuracy: 0.9233 - val_loss: 0.1972 - val_precision: 0.9279 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.1260 - precision: 0.9642 - recall: 0.9565 - val_accuracy: 0.9251 - val_loss: 0.1965 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9543 - loss: 0.1238 - precision: 0.9641 - recall: 0.9546 - val_accuracy: 0.9251 - val_loss: 0.1959 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1216 - precision: 0.9642 - recall: 0.9559 - val_accuracy: 0.9251 - val_loss: 0.1954 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1196 - precision: 0.9642 - recall: 0.9559 - val_accuracy: 0.9251 - val_loss: 0.1949 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9560 - loss: 0.1176 - precision: 0.9650 - recall: 0.9569 - val_accuracy: 0.9251 - val_loss: 0.1945 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9576 - loss: 0.1156 - precision: 0.9654 - recall: 0.9595 - val_accuracy: 0.9251 - val_loss: 0.1941 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9594 - loss: 0.1137 - precision: 0.9680 - recall: 0.9601 - val_accuracy: 0.9251 - val_loss: 0.1937 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9615 - loss: 0.1119 - precision: 0.9681 - recall: 0.9635 - val_accuracy: 0.9251 - val_loss: 0.1934 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9616 - loss: 0.1101 - precision: 0.9681 - recall: 0.9637 - val_accuracy: 0.9251 - val_loss: 0.1931 - val_precision: 0.9308 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9619 - loss: 0.1084 - precision: 0.9686 - recall: 0.9637 - val_accuracy: 0.9199 - val_loss: 0.1929 - val_precision: 0.9221 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.1067 - precision: 0.9686 - recall: 0.9640 - val_accuracy: 0.9199 - val_loss: 0.1927 - val_precision: 0.9221 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.1051 - precision: 0.9686 - recall: 0.9640 - val_accuracy: 0.9199 - val_loss: 0.1925 - val_precision: 0.9221 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9629 - loss: 0.1035 - precision: 0.9693 - recall: 0.9649 - val_accuracy: 0.9216 - val_loss: 0.1924 - val_precision: 0.9250 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9631 - loss: 0.1020 - precision: 0.9696 - recall: 0.9649 - val_accuracy: 0.9216 - val_loss: 0.1923 - val_precision: 0.9250 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9644 - loss: 0.0996 - precision: 0.9678 - recall: 0.9692 - val_accuracy: 0.9181 - val_loss: 0.1875 - val_precision: 0.9299 - val_recall: 0.9211 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9614 - loss: 0.0985 - precision: 0.9666 - recall: 0.9653 - val_accuracy: 0.9181 - val_loss: 0.1876 - val_precision: 0.9299 - val_recall: 0.9211 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9657 - loss: 0.0976 - precision: 0.9691 - recall: 0.9704 - val_accuracy: 0.9181 - val_loss: 0.1877 - val_precision: 0.9299 - val_recall: 0.9211 - learning_rate: 5.0000e-04\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step\n",
      "\n",
      "Validation: Fold 3 - Loss: 0.2066, Accuracy: 0.9233, Precision: 0.9279, Recall: 0.9338, F1 Score: 0.9308, ROC AUC Score: 0.9764\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "Fold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 13:47:15.723183: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with frozen base layers for 50 epochs...\n",
      "Epoch 1/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.6317 - loss: 0.5959 - precision: 0.7243 - recall: 0.5412 - val_accuracy: 0.8258 - val_loss: 0.4085 - val_precision: 0.8511 - val_recall: 0.8297 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8277 - loss: 0.4007 - precision: 0.8628 - recall: 0.8161 - val_accuracy: 0.8589 - val_loss: 0.3577 - val_precision: 0.8758 - val_recall: 0.8675 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8514 - loss: 0.3464 - precision: 0.8906 - recall: 0.8327 - val_accuracy: 0.8728 - val_loss: 0.3276 - val_precision: 0.8885 - val_recall: 0.8801 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8746 - loss: 0.3106 - precision: 0.9083 - recall: 0.8597 - val_accuracy: 0.8798 - val_loss: 0.3071 - val_precision: 0.8899 - val_recall: 0.8927 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.2840 - precision: 0.9183 - recall: 0.8689 - val_accuracy: 0.8902 - val_loss: 0.2924 - val_precision: 0.8920 - val_recall: 0.9117 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8937 - loss: 0.2632 - precision: 0.9241 - recall: 0.8801 - val_accuracy: 0.8955 - val_loss: 0.2814 - val_precision: 0.8954 - val_recall: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8999 - loss: 0.2465 - precision: 0.9298 - recall: 0.8860 - val_accuracy: 0.8972 - val_loss: 0.2729 - val_precision: 0.8981 - val_recall: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9045 - loss: 0.2326 - precision: 0.9322 - recall: 0.8925 - val_accuracy: 0.8990 - val_loss: 0.2661 - val_precision: 0.8985 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 0.2209 - precision: 0.9396 - recall: 0.9001 - val_accuracy: 0.9024 - val_loss: 0.2606 - val_precision: 0.9040 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.2108 - precision: 0.9423 - recall: 0.9062 - val_accuracy: 0.9024 - val_loss: 0.2560 - val_precision: 0.9040 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2019 - precision: 0.9463 - recall: 0.9127 - val_accuracy: 0.9042 - val_loss: 0.2521 - val_precision: 0.9068 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9288 - loss: 0.1941 - precision: 0.9480 - recall: 0.9223 - val_accuracy: 0.9007 - val_loss: 0.2487 - val_precision: 0.9062 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.1871 - precision: 0.9536 - recall: 0.9294 - val_accuracy: 0.9007 - val_loss: 0.2458 - val_precision: 0.9037 - val_recall: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.1807 - precision: 0.9560 - recall: 0.9302 - val_accuracy: 0.9042 - val_loss: 0.2434 - val_precision: 0.9068 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9391 - loss: 0.1749 - precision: 0.9564 - recall: 0.9329 - val_accuracy: 0.9059 - val_loss: 0.2412 - val_precision: 0.9071 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.1696 - precision: 0.9606 - recall: 0.9333 - val_accuracy: 0.9077 - val_loss: 0.2393 - val_precision: 0.9074 - val_recall: 0.9274 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9436 - loss: 0.1647 - precision: 0.9610 - recall: 0.9363 - val_accuracy: 0.9111 - val_loss: 0.2376 - val_precision: 0.9080 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9461 - loss: 0.1601 - precision: 0.9635 - recall: 0.9384 - val_accuracy: 0.9129 - val_loss: 0.2362 - val_precision: 0.9083 - val_recall: 0.9369 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.1559 - precision: 0.9636 - recall: 0.9408 - val_accuracy: 0.9111 - val_loss: 0.2349 - val_precision: 0.9055 - val_recall: 0.9369 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.1519 - precision: 0.9636 - recall: 0.9421 - val_accuracy: 0.9111 - val_loss: 0.2338 - val_precision: 0.9055 - val_recall: 0.9369 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.1482 - precision: 0.9640 - recall: 0.9431 - val_accuracy: 0.9111 - val_loss: 0.2328 - val_precision: 0.9055 - val_recall: 0.9369 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.1447 - precision: 0.9645 - recall: 0.9440 - val_accuracy: 0.9094 - val_loss: 0.2319 - val_precision: 0.9052 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9523 - loss: 0.1414 - precision: 0.9654 - recall: 0.9478 - val_accuracy: 0.9077 - val_loss: 0.2312 - val_precision: 0.9049 - val_recall: 0.9306 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9524 - loss: 0.1382 - precision: 0.9654 - recall: 0.9480 - val_accuracy: 0.9111 - val_loss: 0.2305 - val_precision: 0.9055 - val_recall: 0.9369 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1352 - precision: 0.9655 - recall: 0.9489 - val_accuracy: 0.9129 - val_loss: 0.2300 - val_precision: 0.9058 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1324 - precision: 0.9676 - recall: 0.9506 - val_accuracy: 0.9129 - val_loss: 0.2295 - val_precision: 0.9058 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9564 - loss: 0.1296 - precision: 0.9683 - recall: 0.9526 - val_accuracy: 0.9129 - val_loss: 0.2291 - val_precision: 0.9058 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9564 - loss: 0.1270 - precision: 0.9683 - recall: 0.9526 - val_accuracy: 0.9129 - val_loss: 0.2287 - val_precision: 0.9058 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.1245 - precision: 0.9684 - recall: 0.9539 - val_accuracy: 0.9129 - val_loss: 0.2284 - val_precision: 0.9058 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9574 - loss: 0.1221 - precision: 0.9688 - recall: 0.9539 - val_accuracy: 0.9129 - val_loss: 0.2282 - val_precision: 0.9058 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9580 - loss: 0.1198 - precision: 0.9689 - recall: 0.9549 - val_accuracy: 0.9146 - val_loss: 0.2280 - val_precision: 0.9061 - val_recall: 0.9432 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9585 - loss: 0.1176 - precision: 0.9689 - recall: 0.9560 - val_accuracy: 0.9146 - val_loss: 0.2279 - val_precision: 0.9061 - val_recall: 0.9432 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9602 - loss: 0.1154 - precision: 0.9696 - recall: 0.9584 - val_accuracy: 0.9111 - val_loss: 0.2202 - val_precision: 0.9182 - val_recall: 0.9211 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9622 - loss: 0.1139 - precision: 0.9697 - recall: 0.9620 - val_accuracy: 0.9111 - val_loss: 0.2198 - val_precision: 0.9182 - val_recall: 0.9211 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.1127 - precision: 0.9698 - recall: 0.9629 - val_accuracy: 0.9129 - val_loss: 0.2197 - val_precision: 0.9211 - val_recall: 0.9211 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.1115 - precision: 0.9698 - recall: 0.9629 - val_accuracy: 0.9146 - val_loss: 0.2196 - val_precision: 0.9214 - val_recall: 0.9243 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.1100 - precision: 0.9692 - recall: 0.9635 - val_accuracy: 0.9077 - val_loss: 0.2183 - val_precision: 0.9231 - val_recall: 0.9085 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.1092 - precision: 0.9682 - recall: 0.9643 - val_accuracy: 0.9077 - val_loss: 0.2181 - val_precision: 0.9231 - val_recall: 0.9085 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.1086 - precision: 0.9682 - recall: 0.9643 - val_accuracy: 0.9077 - val_loss: 0.2180 - val_precision: 0.9231 - val_recall: 0.9085 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.1080 - precision: 0.9682 - recall: 0.9643 - val_accuracy: 0.9059 - val_loss: 0.2180 - val_precision: 0.9201 - val_recall: 0.9085 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.1075 - precision: 0.9682 - recall: 0.9643 - val_accuracy: 0.9059 - val_loss: 0.2179 - val_precision: 0.9201 - val_recall: 0.9085 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1067 - precision: 0.9683 - recall: 0.9659 - val_accuracy: 0.9077 - val_loss: 0.2172 - val_precision: 0.9258 - val_recall: 0.9054 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1064 - precision: 0.9683 - recall: 0.9659 - val_accuracy: 0.9059 - val_loss: 0.2171 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1061 - precision: 0.9683 - recall: 0.9659 - val_accuracy: 0.9059 - val_loss: 0.2171 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.1056 - precision: 0.9677 - recall: 0.9647 - val_accuracy: 0.9059 - val_loss: 0.2170 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 6.2500e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1055 - precision: 0.9694 - recall: 0.9647 - val_accuracy: 0.9059 - val_loss: 0.2169 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 6.2500e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1053 - precision: 0.9694 - recall: 0.9647 - val_accuracy: 0.9059 - val_loss: 0.2169 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 6.2500e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1052 - precision: 0.9694 - recall: 0.9647 - val_accuracy: 0.9059 - val_loss: 0.2168 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 6.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1049 - precision: 0.9694 - recall: 0.9647 - val_accuracy: 0.9059 - val_loss: 0.2168 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 3.1250e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1048 - precision: 0.9694 - recall: 0.9647 - val_accuracy: 0.9059 - val_loss: 0.2168 - val_precision: 0.9256 - val_recall: 0.9022 - learning_rate: 3.1250e-05\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step\n",
      "\n",
      "Validation: Fold 4 - Loss: 0.2280, Accuracy: 0.9146, Precision: 0.9061, Recall: 0.9432, F1 Score: 0.9243, ROC AUC Score: 0.9704\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      "Fold 5/5...\n",
      "Training with frozen base layers for 50 epochs...\n",
      "Epoch 1/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5639 - loss: 0.6603 - precision: 0.6540 - recall: 0.4540 - val_accuracy: 0.8031 - val_loss: 0.4614 - val_precision: 0.8110 - val_recall: 0.8391 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7982 - loss: 0.4346 - precision: 0.8417 - recall: 0.7850 - val_accuracy: 0.8397 - val_loss: 0.3973 - val_precision: 0.8505 - val_recall: 0.8612 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8264 - loss: 0.3755 - precision: 0.8675 - recall: 0.8126 - val_accuracy: 0.8606 - val_loss: 0.3574 - val_precision: 0.8738 - val_recall: 0.8738 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8565 - loss: 0.3362 - precision: 0.8945 - recall: 0.8418 - val_accuracy: 0.8606 - val_loss: 0.3289 - val_precision: 0.8762 - val_recall: 0.8707 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8702 - loss: 0.3070 - precision: 0.9054 - recall: 0.8563 - val_accuracy: 0.8746 - val_loss: 0.3076 - val_precision: 0.8889 - val_recall: 0.8833 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8933 - loss: 0.2843 - precision: 0.9236 - recall: 0.8808 - val_accuracy: 0.8798 - val_loss: 0.2911 - val_precision: 0.8949 - val_recall: 0.8864 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9012 - loss: 0.2663 - precision: 0.9240 - recall: 0.8959 - val_accuracy: 0.8920 - val_loss: 0.2779 - val_precision: 0.9048 - val_recall: 0.8991 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9041 - loss: 0.2514 - precision: 0.9273 - recall: 0.8982 - val_accuracy: 0.8902 - val_loss: 0.2672 - val_precision: 0.8994 - val_recall: 0.9022 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2388 - precision: 0.9399 - recall: 0.9017 - val_accuracy: 0.8920 - val_loss: 0.2582 - val_precision: 0.8997 - val_recall: 0.9054 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9163 - loss: 0.2281 - precision: 0.9440 - recall: 0.9031 - val_accuracy: 0.8937 - val_loss: 0.2507 - val_precision: 0.9000 - val_recall: 0.9085 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9180 - loss: 0.2186 - precision: 0.9438 - recall: 0.9065 - val_accuracy: 0.8972 - val_loss: 0.2443 - val_precision: 0.9031 - val_recall: 0.9117 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9192 - loss: 0.2103 - precision: 0.9440 - recall: 0.9087 - val_accuracy: 0.9007 - val_loss: 0.2387 - val_precision: 0.9062 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9210 - loss: 0.2029 - precision: 0.9463 - recall: 0.9097 - val_accuracy: 0.9024 - val_loss: 0.2338 - val_precision: 0.9091 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.1962 - precision: 0.9489 - recall: 0.9137 - val_accuracy: 0.9042 - val_loss: 0.2295 - val_precision: 0.9119 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9260 - loss: 0.1900 - precision: 0.9499 - recall: 0.9151 - val_accuracy: 0.9042 - val_loss: 0.2258 - val_precision: 0.9119 - val_recall: 0.9148 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9312 - loss: 0.1844 - precision: 0.9526 - recall: 0.9221 - val_accuracy: 0.9094 - val_loss: 0.2224 - val_precision: 0.9128 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9352 - loss: 0.1792 - precision: 0.9532 - recall: 0.9290 - val_accuracy: 0.9059 - val_loss: 0.2194 - val_precision: 0.9122 - val_recall: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 0.1744 - precision: 0.9547 - recall: 0.9314 - val_accuracy: 0.9059 - val_loss: 0.2167 - val_precision: 0.9122 - val_recall: 0.9180 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 0.1699 - precision: 0.9547 - recall: 0.9314 - val_accuracy: 0.9094 - val_loss: 0.2143 - val_precision: 0.9128 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9384 - loss: 0.1657 - precision: 0.9548 - recall: 0.9334 - val_accuracy: 0.9059 - val_loss: 0.2122 - val_precision: 0.9097 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9391 - loss: 0.1618 - precision: 0.9553 - recall: 0.9344 - val_accuracy: 0.9077 - val_loss: 0.2103 - val_precision: 0.9099 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9426 - loss: 0.1581 - precision: 0.9573 - recall: 0.9385 - val_accuracy: 0.9077 - val_loss: 0.2085 - val_precision: 0.9099 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.1545 - precision: 0.9586 - recall: 0.9420 - val_accuracy: 0.9059 - val_loss: 0.2070 - val_precision: 0.9097 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.1512 - precision: 0.9596 - recall: 0.9432 - val_accuracy: 0.9059 - val_loss: 0.2055 - val_precision: 0.9097 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.1480 - precision: 0.9600 - recall: 0.9435 - val_accuracy: 0.9077 - val_loss: 0.2043 - val_precision: 0.9125 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.1450 - precision: 0.9601 - recall: 0.9441 - val_accuracy: 0.9077 - val_loss: 0.2031 - val_precision: 0.9125 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.1421 - precision: 0.9604 - recall: 0.9441 - val_accuracy: 0.9111 - val_loss: 0.2021 - val_precision: 0.9156 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.1393 - precision: 0.9605 - recall: 0.9468 - val_accuracy: 0.9111 - val_loss: 0.2012 - val_precision: 0.9156 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.1366 - precision: 0.9606 - recall: 0.9480 - val_accuracy: 0.9146 - val_loss: 0.2003 - val_precision: 0.9214 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.1341 - precision: 0.9611 - recall: 0.9482 - val_accuracy: 0.9129 - val_loss: 0.1996 - val_precision: 0.9211 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9508 - loss: 0.1316 - precision: 0.9616 - recall: 0.9495 - val_accuracy: 0.9129 - val_loss: 0.1989 - val_precision: 0.9211 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9532 - loss: 0.1293 - precision: 0.9654 - recall: 0.9500 - val_accuracy: 0.9146 - val_loss: 0.1983 - val_precision: 0.9214 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9537 - loss: 0.1270 - precision: 0.9655 - recall: 0.9507 - val_accuracy: 0.9146 - val_loss: 0.1978 - val_precision: 0.9214 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9563 - loss: 0.1248 - precision: 0.9671 - recall: 0.9540 - val_accuracy: 0.9146 - val_loss: 0.1973 - val_precision: 0.9214 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.1227 - precision: 0.9675 - recall: 0.9544 - val_accuracy: 0.9146 - val_loss: 0.1969 - val_precision: 0.9214 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.1206 - precision: 0.9675 - recall: 0.9547 - val_accuracy: 0.9146 - val_loss: 0.1965 - val_precision: 0.9214 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9571 - loss: 0.1186 - precision: 0.9675 - recall: 0.9551 - val_accuracy: 0.9164 - val_loss: 0.1962 - val_precision: 0.9243 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9573 - loss: 0.1167 - precision: 0.9675 - recall: 0.9554 - val_accuracy: 0.9181 - val_loss: 0.1959 - val_precision: 0.9245 - val_recall: 0.9274 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9576 - loss: 0.1148 - precision: 0.9676 - recall: 0.9559 - val_accuracy: 0.9181 - val_loss: 0.1957 - val_precision: 0.9245 - val_recall: 0.9274 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9584 - loss: 0.1130 - precision: 0.9676 - recall: 0.9574 - val_accuracy: 0.9181 - val_loss: 0.1955 - val_precision: 0.9272 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9589 - loss: 0.1113 - precision: 0.9682 - recall: 0.9578 - val_accuracy: 0.9181 - val_loss: 0.1954 - val_precision: 0.9272 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.1096 - precision: 0.9682 - recall: 0.9580 - val_accuracy: 0.9164 - val_loss: 0.1953 - val_precision: 0.9243 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9602 - loss: 0.1079 - precision: 0.9701 - recall: 0.9580 - val_accuracy: 0.9164 - val_loss: 0.1952 - val_precision: 0.9243 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9599 - loss: 0.1058 - precision: 0.9645 - recall: 0.9635 - val_accuracy: 0.9164 - val_loss: 0.1927 - val_precision: 0.9410 - val_recall: 0.9054 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9646 - loss: 0.1043 - precision: 0.9683 - recall: 0.9683 - val_accuracy: 0.9181 - val_loss: 0.1925 - val_precision: 0.9441 - val_recall: 0.9054 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.1032 - precision: 0.9675 - recall: 0.9683 - val_accuracy: 0.9181 - val_loss: 0.1924 - val_precision: 0.9441 - val_recall: 0.9054 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9645 - loss: 0.1014 - precision: 0.9678 - recall: 0.9685 - val_accuracy: 0.9181 - val_loss: 0.1933 - val_precision: 0.9470 - val_recall: 0.9022 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9625 - loss: 0.1006 - precision: 0.9667 - recall: 0.9661 - val_accuracy: 0.9181 - val_loss: 0.1933 - val_precision: 0.9470 - val_recall: 0.9022 - learning_rate: 2.5000e-04\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step\n",
      "\n",
      "Validation: Fold 5 - Loss: 0.1959, Accuracy: 0.9181, Precision: 0.9245, Recall: 0.9274, F1 Score: 0.9260, ROC AUC Score: 0.9777\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "Overall Cross-Validation Metrics:\n",
      "Accuracy: 91.19 ± 0.26\n",
      "Precision: 91.52 ± 0.64\n",
      "Recall: 92.66 ± 0.40\n",
      "F1 Score: 92.08 ± 0.21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1s = []\n",
    "\n",
    "normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).batch(32)\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    print(f\"Training model {i + 1}/{len(configs)} with config: {config}\")\n",
    "\n",
    "    # K-fold Cross Validation\n",
    "    kfold = StratifiedKFold(n_splits=config['folds'], shuffle=True, random_state=42)\n",
    "    best_val_f1score = -float('inf')            # Initialize best F1 score with a very low value\n",
    "\n",
    "    # Define the base path for saving models\n",
    "    model_subdir = os.path.join(save_dir, f'model{i + 1}')\n",
    "    os.makedirs(model_subdir, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving checkpoints for model\n",
    "    checkpoint_folder = os.path.join(model_subdir, 'checkpoints')\n",
    "    os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "    # Define the base path for saving cthe model with the best f1-score\n",
    "    best_f1_dir = os.path.join(model_subdir, 'best_f1score_fold')\n",
    "    os.makedirs(best_f1_dir, exist_ok=True)\n",
    "    \n",
    "    # Training and validation loop for each fold\n",
    "    fold = 1\n",
    "    for train_idx, val_idx in kfold.split(train_val_images, train_val_labels):\n",
    "        print(f\"\\nFold {fold}/{config['folds']}...\")\n",
    "\n",
    "        checkpoint_filepath = os.path.join(checkpoint_folder, f'checkpoint_fold{fold}.weights.h5')\n",
    "\n",
    "        # Create subset datasets for training and validation\n",
    "        train_images, train_labels = train_val_images[train_idx], train_val_labels[train_idx]\n",
    "        val_images, val_labels = train_val_images[val_idx], train_val_labels[val_idx]\n",
    "\n",
    "        # Convert NumPy arrays back to TensorFlow datasets\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "        val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "\n",
    "        # Normalize datasets \n",
    "        normalization_layer = layers.Rescaling(1./255)\n",
    "        train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "        val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "        # prefetch data to improve performance by overlapping data preprocessing and model execution and cache the dataset in memory and batch\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        train_ds = train_ds.batch(batch_size).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "        val_ds = val_ds.batch(batch_size).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        # Step 1: Train model with frozen layers\n",
    "        print(f\"Training with frozen base layers for {config['epochs']} epochs...\")\n",
    "\n",
    "        # Create and compile model for each fold\n",
    "        model = create_model(num_classes, config, fine_tune=False) \n",
    "\n",
    "        # setup callbacks \n",
    "        early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "\n",
    "        # train the model on the training set until the epochs specified\n",
    "        history_frozen = model.fit(\n",
    "            train_ds,                                       # dataset used for training\n",
    "            validation_data=val_ds,                         # dataset used for validation\n",
    "            epochs=config['epochs'],                        # epochs used for training\n",
    "            callbacks=[early_stopping, model_checkpoint, reduce_lr],   # set early stopping to avoid overfitting\n",
    "            verbose=1\n",
    "        ) \n",
    "\n",
    "        # load the best weights from ModelCheckpoint after training\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        if(config[\"fine_tune\"] == True):\n",
    "            # Step 2: Unfreeze layers and fine-tune\n",
    "            print(f\"Unfreezing layers starting from layer {config['fine_tune_at']} for fine-tuning...\")\n",
    "            fine_tune_model(model.layers[0], config['fine_tune_at'])      # fine tune model\n",
    "\n",
    "            # re-compile the model with a lower learning rate for fine-tuning\n",
    "            fine_tune_lr = config['learning_rate'] * 0.01\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy', tf.keras.metrics.Precision(name='precision')]\n",
    "            )\n",
    "                \n",
    "            print(f\"Fine-tuning for {config['fine_tune_epochs']} epochs...\")\n",
    "\n",
    "            # setup callbacks again for fine-tuning phase with a unique checkpoint\n",
    "            early_stopping, model_checkpoint, reduce_lr = callbacks_setup(checkpoint_filepath)\n",
    "            \n",
    "            history_fine_tune = model.fit(\n",
    "                train_ds,                                       # dataset used for training\n",
    "                validation_data=val_ds,                         # dataset used for validation\n",
    "                epochs=config['fine_tune_epochs'],                        # epochs used for training\n",
    "                callbacks=[early_stopping, model_checkpoint, reduce_lr],   # set early stopping to avoid overfitting\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # load weights after fine-tuning\n",
    "            model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        # evaluate on validation set after training\n",
    "        val_predictions = model.predict(val_ds)\n",
    "        avg_val_loss = model.evaluate(val_ds, verbose=0)[0]\n",
    "        avg_val_accuracy, avg_val_precision, avg_val_recall, avg_val_f1, avg_val_auc = calculate_metrics(\n",
    "            np.concatenate([y for _, y in val_ds]), val_predictions\n",
    "        )\n",
    "\n",
    "        print(f\"\\nValidation: Fold {fold} - Loss: {avg_val_loss:.4f}, Accuracy: {avg_val_accuracy:.4f}, \"\n",
    "              f\"Precision: {avg_val_precision:.4f}, Recall: {avg_val_recall:.4f}, \"\n",
    "              f\"F1 Score: {avg_val_f1:.4f}, ROC AUC Score: {avg_val_auc:.4f}\")\n",
    "\n",
    "        test_predictions = model.predict(test_ds)\n",
    "        avg_test_accuracy, avg_test_precision, avg_test_recall, avg_test_f1, _ = calculate_metrics(\n",
    "        np.concatenate([y for _, y in test_ds]), test_predictions\n",
    "        )\n",
    "\n",
    "        # Append the fold metrics to the lists\n",
    "        fold_accuracies.append(avg_test_accuracy)\n",
    "        fold_precisions.append(avg_test_precision)\n",
    "        fold_recalls.append(avg_test_recall)\n",
    "        fold_f1s.append(avg_test_f1)\n",
    "\n",
    "        # save the best model based on validation F1 score\n",
    "        if avg_test_f1 > best_val_f1score:\n",
    "            best_val_f1score = avg_test_f1\n",
    "\n",
    "            # Save model in TensorFlow SavedModel format (for TensorRT compatibility)\n",
    "            # model.save(best_f1_dir)\n",
    "            # tf.saved_model.save(model, best_f1_dir)\n",
    "            model.export(best_f1_dir)\n",
    "            print(f\"Model with best F1 score during Validation saved at Fold {fold} with F1 Score of {best_val_f1score:.4f}\")\n",
    "\n",
    "            if (config['save_metrics'] == True):\n",
    "                #save confusion matrix, loss curve, evaluation metrics for the best model\n",
    "                history = history_frozen\n",
    "                save_best_model_visuals(history, model, test_ds, class_names, model_subdir, fold)\n",
    "\n",
    "        fold += 1       # Move to the next fold\n",
    "\n",
    "    output_file_path = os.path.join(model_subdir, \"cv_metrics.txt\")\n",
    "    compute_cv_statistics(fold_accuracies, fold_precisions, fold_recalls, fold_f1s,\n",
    "                        use_std_error=False, output_filepath=output_file_path)\n",
    "\n",
    "# save metrics after training\n",
    "# np.save(os.path.join(save_dir, 'train_metrics.npy'), train_metrics)\n",
    "# np.save(os.path.join(save_dir, 'val_metrics.npy'), val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, config in enumerate(configs):\n",
    "    # model = tf.keras.models.load_model(f'../saved_models/model{i+1}/best_f1score_fold')\n",
    "\n",
    "    # Load the SavedModel using TFSMLayer, treating it as a Keras layer\n",
    "    model_layer = tf.keras.layers.TFSMLayer(f'../saved_models/model{i+1}/best_f1score_fold', call_endpoint='serving_default')\n",
    "    \n",
    "    # Wrap the TFSMLayer in a Sequential model for inference\n",
    "    model = tf.keras.Sequential([model_layer])\n",
    "\n",
    "    # once training is complete, evaluate on the held-out test set\n",
    "    print(f\"Evaluating the best model for model{i+1} on the held-out test set...\")\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "    test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).batch(batch_size)\n",
    "\n",
    "    test_predictions = model.predict(test_ds)\n",
    "\n",
    "    # Print the shape and type of predictions for debugging\n",
    "    # print(f\"Predictions shape: {len(test_predictions['output_0'])}, type: {type(test_predictions)}\")\n",
    "    # print(f\"First few predictions: {test_predictions[:5]}\")  # Check the first few predictions\n",
    "\n",
    "    # avg_test_loss = model.evaluate(test_ds, verbose=0)[0]\n",
    "    avg_test_accuracy, avg_test_precision, avg_test_recall, avg_test_f1, avg_test_auc = calculate_metrics(\n",
    "        np.concatenate([y for x, y in test_ds]), test_predictions['output_0']\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTest Set Evaluation - Accuracy: {avg_test_accuracy:.4f}, Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1 Score: {avg_test_f1:.4f}, AUC Score: {avg_test_auc:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
